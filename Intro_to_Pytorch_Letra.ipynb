{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intro_to_Pytorch_Letra.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yLeDXUNk0zCH"},"source":["# Pytorch\n","\n","https://pytorch.org/\n","https://pytorch.org/tutorials/\n","https://pytorch.org/docs/stable/index.html\n","\n","Pytorch es un framework de machine learning que nos permite rápidamente diseñar, entrenar y testear modelos de machine learning (en particular, redes neuronales). \n","\n","Vamos a utilizar este framework para implementar el obligatorio del curso, por eso, en la clase de hoy vamos a ver una breve introduccion al framework y las redes neuronales. Vamos a prestar detallada atencion a dos tipos de modelos: las redes FeedForward (neuronas que se conectan entre sí en una modalidad de \"cascada secuencial\")."]},{"cell_type":"code","metadata":{"id":"qjmmJdVbXzzF"},"source":["import torch\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"labMfKXmoh_N"},"source":["torch.tensor([[1., -1.], [1., -1.]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j3sjdOL4oiBf"},"source":["torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBCKc9UDoiDk"},"source":["torch.zeros([2, 4], dtype=torch.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKC9U6iYXzzJ"},"source":["### Manipulación de tensores.\n","Los tensores pueden accederse mediante las directivas de slicing y e indexación de python"]},{"cell_type":"code","metadata":{"id":"6M6qZub6XzzK"},"source":["x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(x[1][2])\n","x[0][1] = 8\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"piQzuUZjXzzK"},"source":["### Operaciones sobre tensores."]},{"cell_type":"code","metadata":{"id":"Vhe_Z-teXzzL"},"source":["x = torch.tensor([1., 2., 3.])\n","y = torch.tensor(2)\n","z = torch.randn(1, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8CUaY7TXzzM"},"source":["# Suma tensor y un escalar\n","x + y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyyElr2CXzzM"},"source":["# Tensor por escalar\n","x * y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sA3e7sl5XzzM"},"source":["# Tensor por escalar\n","x / y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zN5zyvyRXzzN"},"source":["r = torch.mv(z, x)\n","r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"STTRwIRiXzzN"},"source":["mat1 = torch.randn(2, 3)\n","mat2 = torch.randn(3, 4)\n","r = torch.mm(mat1, mat2)\n","r"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WP2pHPyvXzzO"},"source":["### Metadata"]},{"cell_type":"code","metadata":{"id":"ZffGyQs8XzzO"},"source":["w = torch.tensor([[1,2,3],[4,5,6]])\n","print(w.size())                      \n","print(torch.numel(w))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zc3j0RjaXzzO"},"source":["### Resizing (reshaping)"]},{"cell_type":"code","metadata":{"id":"pOMdLjRnXzzO"},"source":["x = torch.randn(2, 3)   \n","print('Size of x:', x.size())\n","y = x.view(6) \n","print('Size of y:', y.size())\n","z = x.view(-1, 2) \n","print('Size of z:', z.size())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nQeJ8QWKXzzO"},"source":["### Cálculo de gradientes\n","Pytorch habilita al cálculo automático de gradientes (autograd)"]},{"cell_type":"code","metadata":{"id":"Bm_BQ-2VXzzP"},"source":["x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n","print(x.grad)\n","out = x.pow(2).mean()\n","print(out)\n","out.backward()\n","\n","print(x.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hur5OGlgj-Ct"},"source":["## Uso automático de GPU\n","\n","En Colab tenemos 12 Horas de GPU gratis para usar (cambiando el runtime type), esto nos permite entrenar modelos de DL mucho mas rápido. La celda de código abajo detecta si tenemos una GPU disponible o no y nos va a permitir escribir código genérico para cualquier dispositivo.\n","\n","***\n","Recomendamos fuertemente utilizar CPU lo más posible mientras probamos código y usar la GPU solo para cuando sabemos que todo funciona y queremos obtener resultados. "]},{"cell_type":"code","metadata":{"id":"dpnJwoJPjiOE"},"source":["DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(DEVICE)\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbvuXJQAosTl"},"source":["x = torch.rand(2, 900000).cpu()            # Initialize with random number (uniform distribution)\n","y = torch.randn(900000,200).cpu()           # With normal distribution (SD=1, mean=0)\n","z = torch.randperm(200).cpu()           # Size 200. Random permutation of integers from 0 to 200\n","\n","print('CPU time:')\n","%timeit torch.mm(x,y)+z\n","\n","x = torch.rand(2, 900000).cuda()            \n","y = torch.randn(900000,200).cuda()          \n","z = torch.randperm(200).to(DEVICE)  # Manda al tensor al dispositivo que le pasamos (en este caso cuda:0)\n","\n","print(' ')\n","print('GPU time:')\n","%timeit torch.mm(x,y)+z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nl8qO_Sf2WZ1"},"source":["## FeedForward networks\n","\n","Son la unidad más simple de red neuronal, con su origen en el perceptron de muchas capas. La idea es crear una secuencia lineal de neuronas (capa) que reciben nuestro input. \n","\n","![Image](https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png)\n","\n","De esta manera la primera capa de neuronas (input layer) recibe los datos y las capas subsiguientes reciben el resultados de capas anteriores. La última capa (output layer) es la encargada de generar una predicción a partir de nuestros inputs.\n","\n","***\n","\n","En este notebook vamos a usar un dataset muy simple y conocido de imágenes, Fashion-MNIST. Se trata de un dataset de ropa y calzado, la idea es usar redes neuronales para clasificar cada una de las imágenes el tipo de ropa que representa. \n","\n","Para trabajar con imagenes vamos a hacer uso de una librería complementaria a Pytorch: **torchvision** (https://pytorch.org/docs/stable/torchvision/index.html) que incluye varios datasets precargados, modelos preentrenados y algunas utilidades para trabajar con imágenes que nos van a resultar útiles.\n","\n","*** \n","\n","En la celda de abajo vamos a carga nuestro dataset y mostrar algunas imagenes de ejemplo.\n"]},{"cell_type":"code","metadata":{"id":"JpVIgjO52Uou"},"source":["import matplotlib.pyplot as plt\n","import torchvision.datasets as datasets\n","\n","mnist_dataset = datasets.FashionMNIST(\"ruta_donde_guardar_datos\", download=True)\n","\n","print(f\"Tamaño del dataset {len(mnist_dataset)} imagenes.\")\n","print(f\"Clases posibles: {mnist_dataset.classes}\")\n","\n","data_idx = 0  # Indice (0-59999) de la imagen que queremos ver\n","image, label = mnist_dataset[0] \n","\n","print(f\"Objeto imagen: {image} - Clase {label}\")\n","print(f\"Detalles de la imagen {image.size} pixeles\")\n","\n","plt.imshow(image, cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"peWiTvQq2Uua"},"source":["### Clasificador\n","\n","Ahora que tenemos una idea de como es nuestro dataset, vamos a crear un modelo FeedForward para predecir la clase de la imagen que usemos como input. \n","\n","Antes que nada, vamos a necesitar dividir el dataset total en conjuntos de **entrenamiento**, **validacion** y **test**. Vamos a usar un ratio de 80 y 20% respectivamente. El set de test se puede descargar por separado con torchvision. Además, vamos a necesitar una manera de cargar **batches** de datos a la vez, para entrenar nuestra red. Pytorch nos proporciona varias ayudas para esto.\n","\n","***\n","\n","Finalmente, queda aclarar el uso de **tranformaciones** sobre las imágenes. Por lo pronto, tenemos objetos de tipo PIL Image, necesitamos (al menos) convertirlos en Tensores, para que Pytorch los pueda manejar.\n","\n","Hay un numero inmenso de transformaciones posibles que podemos usar en nustras imagenes, en este caso basta con tranformarlas a tensores, pero dejamos este link para otros casos: https://pytorch.org/docs/stable/torchvision/transforms.html\n"]},{"cell_type":"code","metadata":{"id":"YBR5ID9UXzzQ"},"source":["#Esto nos permite cambiarle la forma a un tensor aplicandole una transformacion. \n","\n","class ReshapeTransform:\n","    def __init__(self, new_size):\n","        self.new_size = new_size\n","\n","    def __call__(self, img):\n","        return torch.reshape(img, self.new_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVBOfbYX2UzC"},"source":["import torchvision.transforms as transforms\n","\n","img_transforms = transforms.Compose([transforms.ToTensor(), ReshapeTransform((-1,))])\n","\n","# Descargamos los datasets\n","mnist_train_dataset = dsets.FashionMNIST(\n","    \"ruta_donde_guardar_datos\", download=True, train=True, transform=img_transforms\n",")\n","\n","# Separamos el train set en train y validation\n","train_set, val_set = torch.utils.data.random_split(\n","    mnist_train_dataset,\n","    [int(0.8 * len(mnist_train_dataset)), int(0.2 * len(mnist_train_dataset))],\n",")\n","\n","mnist_test_dataset = dsets.FashionMNIST(\n","    \"ruta_donde_guardar_datos\", download=True, train=False, transform=img_transforms\n",")\n","\n","# Creamos objetos DataLoader (https://pytorch.org/docs/stable/data.html) que nos va a permitir crear batches de data automaticamente.\n","\n","# Cuantas imagenes obtener en cada iteracion!\n","BATCH_SIZE = 64\n","\n","# Creamos los loaders\n","train_loader = torch.utils.data.DataLoader(\n","    train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",")\n","val_loader = torch.utils.data.DataLoader(\n","    val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    mnist_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKgtfpeArQPd"},"source":["### Modelo\n","\n","Vamos a considerar cada imagen como un tensor de una sola dimensión, de largo 28*28 = 784. Cada uno de esos valores representa el valor de un pixel de nuestra imagen original.\n","\n","Nuestra red va a recibir ese tensor como input (en realidad, un batch de tensores de largo 784) que va a ser trabajado por varias capas ocultas con diferente número de neuronas hasta llegar a una capa de salida con 10 outputs, 1 por cada clase posible.\n","\n","***\n","\n","Vamos utilizar capas conectadas totalmente, tambien conocidas como Fully Connected, Dense, o Linear en Pytorch (https://pytorch.org/docs/stable/nn.html). Para crearlas necesitamos especificar las dimensiones del tensor de entrada, y el de salida; luego internamente Pytorch genera la matriz de pesos por los cuales multiplicar la entrada para generar la salida. Luego de cada una de estas operaciones necesitamos usar una funcion de activacion no linear, en este caso, vamos a usar ReLU: https://pytorch.org/docs/stable/nn.html#relu. \n","\n","***\n","\n","Para implementar un modelo **cualquiera** alcanza con definir un metodo **init** donde especificamos la arquitectura del mismo, y un método **forward** donde especificamos cómo interactúan nuestras capas frente a un nuevo input.\n","\n","***\n","\n"]},{"cell_type":"code","metadata":{"id":"h-SZey-Qqj1P"},"source":["# Definicion del modelo que vamos a usar. En Pytorch los modelos se definen como clases, que heredan de nn.Module\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class FeedForwardModel(nn.Module):\n","\n","    def __init__(self, number_classes=10):\n","        # ??\n","  \n","    def forward(self, new_input):\n","        # ??\n","\n","\n","model = FeedForwardModel(number_classes=10)\n","model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYv_kROa0o54"},"source":["### Entrenando el modelo\n","\n","Para entrenar un modelo necesitamos una funcion de costo o pérdida (normalmente referida como loss function: https://pytorch.org/docs/stable/nn.html#loss-functions). En este curso no nos vamos a meter en mucho detalle sobre las funciones de costo, para este ejercicio y el siguiente vamos a usar la CrossEntropyLoss, y cuando necesiten otra la vamos a especificar.\n","\n","El objetivo de esta funcion es darnos un valor de que tan malas fueron las predicciones del modelo respecto a los valores de verdad. Haciendo uso de backpropagation y del gradiente de esta funcion podemos optimizar los pesos de nuestra red tal que \"aprenda\" a hacer mejores predicciones. De nuevo, la lógica detras de toda esta optimización no nos compete en este curso y lo dejamos para la disciplina de Deep Learning.\n","\n","***\n","Como mencionamos arriba, el costo de computa usando las predicciones del modelo y las etiquetas verdaderas de nuestros datos y, el trabajo de actualizar los pesos usando los gradientes lo realiza un optimizador de Pytorch: https://pytorch.org/docs/stable/optim.html."]},{"cell_type":"code","metadata":{"id":"kYtCjd9cqj3x"},"source":["import torch.optim as optim\n","\n","LEARNING_RATE = 0.003\n","\n","ff_model = FeedForwardModel(number_classes=10).to(DEVICE)\n","criterion = nn.CrossEntropyLoss().to(DEVICE)\n","ff_optimizer = optim.SGD(ff_model.parameters(), lr=LEARNING_RATE, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBEV-LNsqj6o","scrolled":true},"source":["def train_model(model, train_loader, val_loader, loss_func, optimizer, epochs):\n","  # ??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leKy45f4N0q8"},"source":["def test_model(model, test_loader):\n","    # Reportamos la performance en el test set:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pn1NWxrXzzS"},"source":["# Usando las funciones definidas arriba entrenar un modelo es trivial\n","\n","ff_model = train_model(ff_model, train_loader, val_loader, loss_func=criterion, optimizer=ff_optimizer, epochs=15)\n","test_model(ff_model, test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JVa__W9XzzS"},"source":["## Tarea 1\n","\n","Cree y entrene un modelo de red FeedForward que funcione mejor que el visto en clase. Puede usar lo que considere necesario (siempre dentro del mundo de redes feed forward - nada de convoluciones)"]},{"cell_type":"code","metadata":{"id":"sQwPSj2cXzzS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7o0idM08XzzS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecPW82CIgEgn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZIpGxPEgEia"},"source":[""],"execution_count":null,"outputs":[]}]}