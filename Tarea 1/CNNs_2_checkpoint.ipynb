{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kM-aVQsV0Ie"
   },
   "source": [
    "# Imports globales y funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NpqMPo4nV4UB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YGyynDexV60_"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_transf, test_transf, batch_size):\n",
    "    train_dataset = CIFAR10(\"data\", train=True, download=True, transform=train_transf)\n",
    "    test_dataset = CIFAR10(\"data\", train=False, download=True, transform=test_transf)\n",
    "\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "    train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hZyH1P8Velv"
   },
   "source": [
    "# Image Augmentation\n",
    "\n",
    "La primera parte de este laboratorio consiste en expandir un poco el modelo de LeNet para tener más parámetros y luego explorar algunas técnicas de Image Augmentation (https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "El modelo a implementar es el siguiente:\n",
    "\n",
    "\n",
    "![Image](https://i.ibb.co/WxGgbmL/Capture.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "chgl8-GKTyfV"
   },
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "  def __init__(self, in_channels, number_classes):\n",
    "    # in_channels: int, cantidad de canales de la imagen original\n",
    "    super(CustomCNN, self).__init__()\n",
    "    # Su implementacion\n",
    "    self.conv1 = nn.Conv2d(in_channels, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "    self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "    self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 120, kernel_size = 3, padding = 1)\n",
    "    \n",
    "    self.linear1 = nn.Linear(in_features = 120*4*4, out_features = 512)\n",
    "    self.linear2 = nn.Linear(in_features = 512, out_features = number_classes)\n",
    "    \n",
    "    self.max_pooling = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Su implementacion\n",
    "    out = F.relu(self.conv1(x))\n",
    "    out = F.relu(self.conv2(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = F.relu(self.conv3(out))\n",
    "    out = F.relu(self.conv4(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = F.relu(self.conv5(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = self.dropout(out.flatten(1))\n",
    "    \n",
    "    out = F.relu(self.linear1(out))\n",
    "    out = self.dropout(out)\n",
    "    out = self.linear2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGisRfZ8bYXW"
   },
   "source": [
    "## Funciones genericas para entrenar nuestros modelos\n",
    "\n",
    "Vamos a utilizar las mismas funciones que implementamos en los laboratorios anteriores para entrenar y testear nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6Gp496cWTyh-"
   },
   "outputs": [],
   "source": [
    "def train_epoch(training_model, loader, criterion, optim):\n",
    "    training_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "      all_labels.extend(labels.numpy())  \n",
    "\n",
    "      optim.zero_grad()\n",
    "\n",
    "      predictions = training_model(images.to(device))\n",
    "      all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "\n",
    "      loss = criterion(predictions, labels.to(device))\n",
    "      \n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n",
    "\n",
    "\n",
    "def validation_epoch(val_model, loader, criterion):\n",
    "    val_model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for images, labels in loader:\n",
    "        all_labels.extend(labels.numpy())  \n",
    "\n",
    "        predictions = val_model(images.to(device))\n",
    "        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "\n",
    "        loss = criterion(predictions, labels.to(device))\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n",
    "  \n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optim, number_epochs):\n",
    "  train_history = []\n",
    "  test_history = []\n",
    "  accuracy_history = []\n",
    "\n",
    "  for epoch in range(number_epochs):\n",
    "      start_time = time.time()\n",
    "\n",
    "      train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "      train_history.append(train_loss)\n",
    "      print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
    "            .format(epoch + 1, train_loss, train_acc, time.time() - start_time))\n",
    "\n",
    "      start_time = time.time()\n",
    "      test_loss, acc = validation_epoch(model, test_loader, criterion)\n",
    "      test_history.append(test_loss)\n",
    "      accuracy_history.append(acc)\n",
    "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
    "            .format(epoch + 1, test_loss, acc, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrGeplg5bmKm"
   },
   "source": [
    "## Entrenando modelos \n",
    "\n",
    "Comenzamos definiendo una seccion de código con valores por defecto de hiperparámetros que vamos a utilizar y luego entrenamos un modelo de la CNN definida anteriormente sin usar augmentation en los datos y otro haciendo uso del mismo.\n",
    "\n",
    "https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rj_T5Fza6efw"
   },
   "outputs": [],
   "source": [
    "# Global models config\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "NUMBER_EPOCHS = 15\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "137kQNukTyoI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1c9670e0f84898a0900f6182217c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n",
      "Training epoch 1 | Loss 1.833582 | Accuracy 30.68% | Time 12.57 seconds\n",
      "Validation epoch 1 | Loss 1.413233 | Accuracy 48.77% | Time 0.92 seconds\n",
      "Training epoch 2 | Loss 1.367879 | Accuracy 50.41% | Time 9.75 seconds\n",
      "Validation epoch 2 | Loss 1.250740 | Accuracy 55.31% | Time 0.74 seconds\n",
      "Training epoch 3 | Loss 1.199229 | Accuracy 57.18% | Time 8.60 seconds\n",
      "Validation epoch 3 | Loss 1.074248 | Accuracy 61.46% | Time 0.80 seconds\n",
      "Training epoch 4 | Loss 1.102544 | Accuracy 60.98% | Time 8.57 seconds\n",
      "Validation epoch 4 | Loss 0.963749 | Accuracy 66.06% | Time 0.73 seconds\n",
      "Training epoch 5 | Loss 1.024269 | Accuracy 63.68% | Time 8.61 seconds\n",
      "Validation epoch 5 | Loss 0.968082 | Accuracy 65.50% | Time 0.83 seconds\n",
      "Training epoch 6 | Loss 0.967637 | Accuracy 65.65% | Time 8.03 seconds\n",
      "Validation epoch 6 | Loss 0.878411 | Accuracy 68.97% | Time 0.80 seconds\n",
      "Training epoch 7 | Loss 0.921454 | Accuracy 67.49% | Time 9.09 seconds\n",
      "Validation epoch 7 | Loss 0.839164 | Accuracy 70.30% | Time 0.76 seconds\n",
      "Training epoch 8 | Loss 0.883384 | Accuracy 68.89% | Time 9.22 seconds\n",
      "Validation epoch 8 | Loss 0.810961 | Accuracy 71.22% | Time 0.77 seconds\n",
      "Training epoch 9 | Loss 0.852830 | Accuracy 70.16% | Time 10.19 seconds\n",
      "Validation epoch 9 | Loss 0.827310 | Accuracy 70.85% | Time 0.70 seconds\n",
      "Training epoch 10 | Loss 0.829105 | Accuracy 70.67% | Time 9.06 seconds\n",
      "Validation epoch 10 | Loss 0.789601 | Accuracy 72.46% | Time 0.74 seconds\n",
      "Training epoch 11 | Loss 0.808364 | Accuracy 71.77% | Time 11.46 seconds\n",
      "Validation epoch 11 | Loss 0.787227 | Accuracy 72.25% | Time 0.92 seconds\n",
      "Training epoch 12 | Loss 0.776720 | Accuracy 72.64% | Time 13.30 seconds\n",
      "Validation epoch 12 | Loss 0.745373 | Accuracy 73.57% | Time 0.85 seconds\n",
      "Training epoch 13 | Loss 0.771298 | Accuracy 72.71% | Time 12.83 seconds\n",
      "Validation epoch 13 | Loss 0.748099 | Accuracy 73.89% | Time 0.75 seconds\n",
      "Training epoch 14 | Loss 0.744538 | Accuracy 73.83% | Time 13.29 seconds\n",
      "Validation epoch 14 | Loss 0.736235 | Accuracy 74.54% | Time 0.83 seconds\n",
      "Training epoch 15 | Loss 0.728688 | Accuracy 74.41% | Time 12.87 seconds\n",
      "Validation epoch 15 | Loss 0.763974 | Accuracy 73.40% | Time 0.82 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fijamos las semillas siempre para poder comparar.\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los dataloaders\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Definimos el modelo y el optimizador\n",
    "modelo_sin_aug = CustomCNN(3,10).to(device)\n",
    "optimizer = torch.optim.Adam(modelo_sin_aug.parameters(), lr=LR)\n",
    "\n",
    "# Entrenamos\n",
    "train_model(modelo_sin_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h_c-x46dYUyk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training epoch 1 | Loss 1.868144 | Accuracy 28.34% | Time 12.48 seconds\n",
      "Validation epoch 1 | Loss 1.575820 | Accuracy 40.58% | Time 0.73 seconds\n",
      "Training epoch 2 | Loss 1.577137 | Accuracy 40.97% | Time 12.50 seconds\n",
      "Validation epoch 2 | Loss 1.423760 | Accuracy 48.15% | Time 0.87 seconds\n",
      "Training epoch 3 | Loss 1.440973 | Accuracy 46.92% | Time 12.32 seconds\n",
      "Validation epoch 3 | Loss 1.279700 | Accuracy 53.49% | Time 0.87 seconds\n",
      "Training epoch 4 | Loss 1.352444 | Accuracy 50.95% | Time 12.49 seconds\n",
      "Validation epoch 4 | Loss 1.225220 | Accuracy 55.86% | Time 0.90 seconds\n",
      "Training epoch 5 | Loss 1.287378 | Accuracy 53.40% | Time 12.56 seconds\n",
      "Validation epoch 5 | Loss 1.202295 | Accuracy 56.84% | Time 0.86 seconds\n",
      "Training epoch 6 | Loss 1.236828 | Accuracy 55.47% | Time 12.62 seconds\n",
      "Validation epoch 6 | Loss 1.100359 | Accuracy 60.60% | Time 0.82 seconds\n",
      "Training epoch 7 | Loss 1.195269 | Accuracy 56.79% | Time 12.57 seconds\n",
      "Validation epoch 7 | Loss 1.080989 | Accuracy 61.38% | Time 0.94 seconds\n",
      "Training epoch 8 | Loss 1.163437 | Accuracy 58.23% | Time 13.10 seconds\n",
      "Validation epoch 8 | Loss 1.025995 | Accuracy 63.66% | Time 0.86 seconds\n",
      "Training epoch 9 | Loss 1.135150 | Accuracy 59.23% | Time 12.23 seconds\n",
      "Validation epoch 9 | Loss 1.003090 | Accuracy 64.22% | Time 0.76 seconds\n",
      "Training epoch 10 | Loss 1.107423 | Accuracy 60.46% | Time 12.79 seconds\n",
      "Validation epoch 10 | Loss 1.019883 | Accuracy 64.55% | Time 0.80 seconds\n",
      "Training epoch 11 | Loss 1.090234 | Accuracy 61.22% | Time 12.21 seconds\n",
      "Validation epoch 11 | Loss 1.004186 | Accuracy 64.29% | Time 1.08 seconds\n",
      "Training epoch 12 | Loss 1.069004 | Accuracy 61.68% | Time 12.24 seconds\n",
      "Validation epoch 12 | Loss 0.986284 | Accuracy 65.78% | Time 0.82 seconds\n",
      "Training epoch 13 | Loss 1.053266 | Accuracy 62.34% | Time 12.79 seconds\n",
      "Validation epoch 13 | Loss 0.956644 | Accuracy 65.83% | Time 0.84 seconds\n",
      "Training epoch 14 | Loss 1.033334 | Accuracy 62.89% | Time 12.68 seconds\n",
      "Validation epoch 14 | Loss 0.928922 | Accuracy 67.34% | Time 0.86 seconds\n",
      "Training epoch 15 | Loss 1.025925 | Accuracy 63.48% | Time 12.70 seconds\n",
      "Validation epoch 15 | Loss 0.978017 | Accuracy 65.75% | Time 0.90 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los datasets\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Definir transormaciones que vamos a aplicar al set de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.2), \n",
    "    transforms.RandomVerticalFlip(p=0.5), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Crear el modelo, optimizador y entrenarlo\n",
    "modelo_con_aug = CustomCNN(3,10).to(device)\n",
    "optimizer = torch.optim.Adam(modelo_con_aug.parameters(), lr=LR)\n",
    "\n",
    "# Entrenamos\n",
    "train_model(modelo_con_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pduauAlXcqZt"
   },
   "source": [
    "## Evaluando los modelos en los datos de test\n",
    "\n",
    "Vamos a comenzar evaluando en los datos de test normales y luego vamos a aplicar distintas transformaciones (para simular entornos más reales de datos) y vamos a ver la performance y robustez de los modelos que entrenamos anteriormente.\n",
    "\n",
    "Primero agregar horizontal flip y luego vertical flip, qué pasa con los modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tNp0-FmEFH16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Test Loss: 0.9976618448004555 - Test Acc: 64.9\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R8XEXFoo8jfG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Test Loss: 0.9954660395844676 - Test Acc: 64.83\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  # Flip Horizontal y volver a testear\n",
    "  transforms.RandomHorizontalFlip(p=1), \n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X3DMvkFf9EQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Test Loss: 0.9866581569654873 - Test Acc: 65.35\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.RandomVerticalFlip(p=1), \n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OPa2WNqgXyy"
   },
   "outputs": [],
   "source": [
    "# Otros tests que quieran probar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsQVBuQKwOvX"
   },
   "source": [
    "# DenseNet\n",
    "\n",
    "\n",
    "![Image](https://miro.medium.com/max/5164/1*_Y7-f9GpV7F93siM1js0cg.jpeg)\n",
    "\n",
    "Link al paper original: [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
    "\n",
    "Algunas consideraciones del paper a tener en cuenta:\n",
    "\n",
    "1. Batch normalization en los inputs de los bloques densos y las capas de transición.\n",
    "2. ReLU en todos lados como funcion de activación.\n",
    "3. El MLP al final de la red cuenta con una capa oculta de 512 neuronas\n",
    "4. Las activaciones luego del tercer bloque denso tienen tamaño 4*4 (ejercicio, calcular a mano!)\n",
    "\n",
    "\n",
    "Implementamos DenseNet para resolver el problema de CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeyVzE9bLUTA"
   },
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "  def __init__(self, in_channels):\n",
    "    super(DenseBlock, self).__init__()\n",
    "    # Su implementacion\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # Su implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTjRTakNLVGm"
   },
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(TransitionLayer, self).__init__()\n",
    "    self.bn = nn.BatchNorm2d(num_features = in_channels)\n",
    "    self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1)\n",
    "    self.pooling = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.bn(x)\n",
    "    out = F.relu(self.conv(out))\n",
    "    out = self.pooling(out)\n",
    "    return out\n",
    "    # Su implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0rglwp_wWEF"
   },
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "\tdef __init__(self, n_classes):\n",
    "\t\tsuper(DenseNet, self).__init__()\n",
    "    # Su implementacion\n",
    "\n",
    "\tdef forward(self, x):\n",
    "    # Su implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7vhkbNiwWIU"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los datasets\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "densenet = DenseNet(10).to(device)\n",
    "optimizer = torch.optim.Adam(densenet.parameters(), lr=LR)\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "train_model(densenet, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7G9PbgeDdD_s"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "test_loss, accuracy = validation_epoch(densenet, test_loader, criterion)\n",
    "print(f\"DenseNet Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNNs_2_Letra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
