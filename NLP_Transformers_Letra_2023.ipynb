{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf1xDb60Rn-O"
   },
   "source": [
    "# Transformer\n",
    "\n",
    "En este laboratorio vamos a implementar una arquitectura de transformer desde cero. Recuerden usar la GPU de colab para acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!pip install typing_extensions==4.7.1\n",
    "#!pip install torch==1.8.0 torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKeC3ZzoY-cs"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Download English and French data from Spacy\n",
    "spacy.cli.download(\"en\")\n",
    "spacy.cli.download(\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZzQANhYZIkb"
   },
   "source": [
    "# Datos\n",
    "\n",
    "Vamos a seguir trabajando con los datos de parejas de oraciones en Frances-w Inglés.\n",
    "\n",
    "    I am cold.    J'ai froid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxV7Rk_mZNas"
   },
   "outputs": [],
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIp1UOFPZYuy"
   },
   "outputs": [],
   "source": [
    "# Take a peek at the dataset\n",
    "dataset = pd.read_csv(\"data/eng-fra.txt\", sep=\"\\t\", header=None)\n",
    "dataset.columns = [\"English\", \"French\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScPj8X66po4c"
   },
   "outputs": [],
   "source": [
    "# dataset = dataset.sample(int(len(dataset)*0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQdP-OPws-82"
   },
   "outputs": [],
   "source": [
    "# Remove very long sentences\n",
    "\n",
    "MAX_SEQ_LEN = 50\n",
    "\n",
    "dataset['en_len'] = dataset['English'].str.count(' ')\n",
    "dataset['fr_len'] = dataset['French'].str.count(' ')\n",
    "dataset = dataset[\n",
    "    (dataset['fr_len'] < MAX_SEQ_LEN) & \n",
    "    (dataset['en_len'] < MAX_SEQ_LEN)\n",
    "][['English', 'French']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb0hfkkpulUK"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, val and test\n",
    "train, val_test = train_test_split(dataset, test_size=0.2, random_state=RANDOM_SEED)\n",
    "val, test = train_test_split(val_test, test_size=0.5)\n",
    "\n",
    "# Save splits to CSV files\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aX1sIWsFq7rB"
   },
   "outputs": [],
   "source": [
    "# Load English and French models\n",
    "en = spacy.load('en_core_web_sm')\n",
    "fr = spacy.load('fr_core_news_sm')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "  \n",
    "def tokenize_fr(sentence):\n",
    "    return [tok.text for tok in fr.tokenizer(sentence)]\n",
    "\n",
    "EN_TEXT = Field(tokenize=tokenize_en, fix_length=MAX_SEQ_LEN)\n",
    "FR_TEXT = Field(tokenize=tokenize_fr, init_token = \"<sos>\", eos_token = \"<eos>\", fix_length=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOh05JVfydM9"
   },
   "outputs": [],
   "source": [
    "# Associate the text in the 'English' column with the EN_TEXT field,\n",
    "# and 'French' with FR_TEXT\n",
    "data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n",
    "\n",
    "train, val = TabularDataset.splits(\n",
    "    path='./',\n",
    "    train='train.csv',\n",
    "    validation='val.csv',\n",
    "    format='csv',\n",
    "    fields=data_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mAjoiHS4BH7"
   },
   "outputs": [],
   "source": [
    "# Build vocabularies\n",
    "FR_TEXT.build_vocab(train, val)\n",
    "EN_TEXT.build_vocab(train, val)\n",
    "\n",
    "# Construct a train iterator\n",
    "train_iter = BucketIterator(\n",
    "    train,\n",
    "    batch_size=32,\n",
    "    sort_key=lambda x: len(x.French),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TO8tpkFPbdpN"
   },
   "source": [
    "# Armando el transformer paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lur0pJDoW8Hh"
   },
   "source": [
    "![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n",
    "\n",
    "El diagrama ilustra el modelo que vamos a implementar. Los inputs al encoder son las oraciones en Frances, y los \"Outputs\" que entran al decoder son las sentencias en Inglés.\n",
    "\n",
    "Necesitamos entender 5 procesos para implementar el modelo:\n",
    "- Embedding de los inputs\n",
    "- Encoding Posicional\n",
    "- Creación de máscaras\n",
    "- La capa de Multi-Head Attention\n",
    "- La capa Feed-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6ULN-z2W8DJ"
   },
   "source": [
    "## Encoding Posicional\n",
    "----\n",
    "El embedding de cada palabra aprende su significado, ahora necesitamos una manera de que la red aprenda sobre la posicion de cada palabra en la sentencia.\n",
    "\n",
    "[Vaswani *et al.*](https://arxiv.org/abs/1706.03762) respondió esta pregunta usando las siguientes funciones para crear valores constantes relacionados a cada posición:\n",
    "\n",
    "$$ PE_{(pos, 2i)} = sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n",
    "$$ PE_{(pos, 2i+1)} = cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n",
    "\n",
    "Esta constante es una matriz en 2D con una de las dimensiones de igual tamaño que los embeddings y la otra igual a la cantidad de palabras en la sentencia.\n",
    "\n",
    "![Positional encoding matrix](https://miro.medium.com/max/1359/1*B-VR6R5vJl3Y7jbMNf5Fpw.png)\n",
    "\n",
    "![Positional encoding example](http://jalammar.github.io/images/t/transformer_positional_encoding_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7aRi6k5f-dk"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN, dropout=0.1):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Create constant 'pe' matrix with values dependant on pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = 1.0 / torch.pow(10000, torch.arange(0, d_model, 2).float() / d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # We register them as a buffer so the optimzer doesn't see this as parameters of the model to optimize!\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        # Add constant to embedding\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv2ZLhMqW79c"
   },
   "source": [
    "## Máscaras para los inputs\n",
    "----\n",
    "Las máscaras de ceros cumplen dos propósitos:\n",
    "\n",
    "- En **ambos** encoder y decoder: Para obtener 0s en la atención sobre el padding.\n",
    "- En el **decoder**: Prevenir que el decoder \"espíe\" a los siguientes inputs de la secuencia traducida, el futuro que no debería conocer para predecir la siguiente palabra. Evita que el decoder \"vea\" lo que tiene que predecir antes de predecirlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqDBxGZg5xOq"
   },
   "outputs": [],
   "source": [
    "def build_attn_pad_mask(seq, pad_index):\n",
    "    # Creates mask with 0s wherever there is padding in the input\n",
    "    return (seq != pad_index).unsqueeze(1).type(torch.uint8)\n",
    "\n",
    "\n",
    "def build_nopeak_mask(size):\n",
    "    # Creates mask with 1s up until the the index of the word being predicted\n",
    "    nopeak_mask = torch.triu(torch.ones(size, size)).transpose(0, 1)\n",
    "    return nopeak_mask.unsqueeze(0).type(torch.uint8)\n",
    "\n",
    "def create_masks(src, src_pad, trg=None, trg_pad=None):\n",
    "    src_mask = build_attn_pad_mask(src, src_pad)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = build_attn_pad_mask(trg, trg_pad)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = build_nopeak_mask(size)\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else: \n",
    "        trg_mask = None\n",
    "\n",
    "    return src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dulPyzCqW74v"
   },
   "source": [
    "## Multi-Head Attention\n",
    "----\n",
    "\n",
    "![Multihead attention schema](https://miro.medium.com/max/1254/1*1tsRtfaY9z6HxmERYhw8XQ.png)\n",
    "\n",
    "$V$, $K$ y $Q$ reprensentan ‘key’, ‘value’ and ‘query’. En el caso del Encoder, $V$, $K$ and $Q$ serán simplemente copias idénticas del vector de embedding (junto con el encoding posicional). Tendrán las siguientes dimensiones $\\text{batch_size} \\times \\text{seq_len} \\times d_\\text{model}$.\n",
    "\n",
    "En multi-head attention repartimos el vector de embedding en $N$ cabezas, por lo que tendrán las dimensiones: $\\text{batch_size} \\times N \\times \\text{seq_len} \\times (d_{\\text{model}} / N)$.\n",
    "\n",
    "La dimensión final: ($d_{\\text{model}} / N$) es a lo que llamaremos $d_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-_fobf8E7pD"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, attn_pdrop = 0.1, resid_pdrop = 0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        # Q, K, V\n",
    "\n",
    "        # Regularization\n",
    "\n",
    "        # Output projection\n",
    "\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Get batch size\n",
    "        bs = q.size(0)\n",
    "        \n",
    "        # Perform linear operation and split into h heads\n",
    "\n",
    "        # Transpose to get dimensions bs * h * sl * d_model\n",
    "\n",
    "        # Calculate attention scores using function we will define next\n",
    "\n",
    "        # Re-assemble all head outputs side by side\n",
    "        # Need to use contigous here to get correspondence\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        \n",
    "        # Output projection\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W28fJmT9HXGk"
   },
   "source": [
    "### Mecanismo de Atención\n",
    "----\n",
    "\n",
    "![Attention diagram](https://miro.medium.com/max/336/1*15E9qKg9bKnWdSRWCyY2iA.png)\n",
    "![Attention equation](https://miro.medium.com/max/1068/1*evdACdTOBT5j1g1nXialBg.png)\n",
    "\n",
    "Inicialmente, multiplicamos $Q$ por la transpuesta de $K$. Esto es luego dividipo por $\\sqrt{d_k}$ (normalización).\n",
    "\n",
    "Algo que aún no vimos es qué hacer con atención y las máscaras. Antes de hacer el Softmax, aplicamos nuestra máscara de ceros para reducir los valores donde el input es padding (o futuro).\n",
    "\n",
    "Finalmente, el último paso es hacer el producto (dot product) entre el resultado hasta ahora y $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQTmzZ35Je5W"
   },
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97KT06QVcELb"
   },
   "source": [
    "## Capa Feed-Forward\n",
    "----\n",
    "Esta capa solo consiste en dos opeaciones lineales (nn.Linear) con ReLU y dropout entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXXhptZ3JvhC"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  # ??\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q4nextzKJFO"
   },
   "source": [
    "# Combinando todo\n",
    "\n",
    "Vamos a crear una capa EncoderLayer y DecoderLayer que agrupan los componentes necesarios para crear un solo encoder (o decoder).\n",
    "\n",
    "Luego, creamos el Encoder de nuestra arquitectura, conteniendo N de estos bloques anteriores. Repetimos para el decoder.\n",
    "\n",
    "![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD-7Yks3K31b"
   },
   "outputs": [],
   "source": [
    "# Build an encoder layer with one multi-head attention layer and one\n",
    "# feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attn = MultiHeadAttention(heads, d_model, dropout, dropout)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # ??\n",
    "        return x\n",
    "    \n",
    "# Build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        # ??\n",
    "        return x\n",
    "\n",
    "# Convenient cloning function that can generate multiple layers:\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QMVOFpaKK2z"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        # ??\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.N = N\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        # ??\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUxlnAGv-AMu"
   },
   "source": [
    "Finalmente usando los dos bloques anteriores y una capa linear creamos el transformer con $N$ encoders/decoders!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58aNa611MsK_"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super(Transformer, self).__init__()\n",
    "        # ??\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        # ??\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSYVGuqCM-Hn"
   },
   "source": [
    "# Entrenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Wun9klgM9AN"
   },
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "heads = 4\n",
    "N = 3\n",
    "src_vocab = len(EN_TEXT.vocab)\n",
    "trg_vocab = len(FR_TEXT.vocab)\n",
    "\n",
    "model = Transformer(src_vocab, trg_vocab, d_model, N, heads).to(DEVICE)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# This code is very important! It initialises the parameters with a\n",
    "# range of values that stops the signal fading or getting too big.\n",
    "# See this blog for a mathematical explanation:\n",
    "# https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNKzh6dLNYVR"
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, print_every=100):\n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    total_loss = 0\n",
    "\n",
    "    src_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "    trg_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0       \n",
    "        for i, batch in enumerate(train_iter):\n",
    "            src = batch.English.transpose(0, 1)\n",
    "            trg = batch.French.transpose(0, 1)\n",
    "            # the French sentence we input has all words except\n",
    "            # the last, as it is using each word to predict the next\n",
    "            trg_input = trg[:, :-1]\n",
    "            \n",
    "            # the words we are trying to predict\n",
    "            targets = trg[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # create function to make masks using mask code above\n",
    "            src_mask, trg_mask = create_masks(src, src_pad, trg_input, trg_pad)\n",
    "\n",
    "            preds = model(src.to(DEVICE), trg_input.to(DEVICE), src_mask.to(DEVICE), trg_mask.to(DEVICE))\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                preds.view(-1, preds.size(-1)),\n",
    "                targets.to(DEVICE),\n",
    "                ignore_index=trg_pad\n",
    "            )\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total_loss += loss.item()\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters\" % (\n",
    "                    (time.time() - start) // 60, epoch + 1, i + 1, loss_avg, time.time() - temp, print_every)\n",
    "                )\n",
    "                total_loss = 0\n",
    "                temp = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGfw-ZZffh5P"
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "train_model(1) # Train for 10 epochs (~60min)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiaAAFHrb-Fl"
   },
   "outputs": [],
   "source": [
    "def translate(model, src, max_len=80):\n",
    "  model.eval()\n",
    "\n",
    "  input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "\n",
    "  src = tokenize_en(src)\n",
    "  src = (torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in src]])).cuda()\n",
    "\n",
    "  src_mask = (src != input_pad).unsqueeze(-2).cuda()\n",
    "  e_outputs = model.encoder(src, src_mask)\n",
    "      \n",
    "  outputs = torch.zeros(max_len).type_as(src.data)\n",
    "  outputs[0] = torch.LongTensor([FR_TEXT.vocab.stoi['<sos>']])\n",
    "\n",
    "  for i in range(1, max_len):    \n",
    "    trg_mask = torch.triu(torch.ones((1, i, i))).type(torch.uint8)\n",
    "    trg_mask = ((trg_mask) == 0).cuda()\n",
    "          \n",
    "    out = model.out(model.decoder(outputs[:i].unsqueeze(0), e_outputs, src_mask, trg_mask))\n",
    "    out = F.softmax(out, dim=-1)\n",
    "    val, ix = out[:, -1].data.topk(1)\n",
    "    \n",
    "    outputs[i] = ix[0][0]\n",
    "\n",
    "    if ix[0][0] == FR_TEXT.vocab.stoi['<eos>']:\n",
    "        break\n",
    "\n",
    "  return ' '.join([FR_TEXT.vocab.itos[ix] for ix in outputs[:i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FALTQeiJdXQQ",
    "outputId": "1421a8be-25e0-4477-92aa-673d86bacb83"
   },
   "outputs": [],
   "source": [
    "translate(model, \"How are you ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbHnAGr1WGeO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ky-OfrkNWGhZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kL5UiQeaWGkS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Transformers_Letra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
