{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf1xDb60Rn-O"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "En este laboratorio vamos a implementar una arquitectura de transformer desde cero. Recuerden usar la GPU de colab para acelerar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tz4wYpGG8hQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XZvV_rap8EL_",
        "outputId": "48f148a1-f233-4f39-976a-f85efd6bda3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.10/dist-packages (1.11.0)\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install spacy\n",
        "# !pip install typing_extensions==4.7.1\n",
        "!pip install torch==1.11.0 torchtext==0.6.0 #-f https://download.pytorch.org/whl/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wKeC3ZzoY-cs",
        "outputId": "ae780d3b-9585-4845-af0b-2bfcb7d316e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Download English and French data from Spacy\n",
        "spacy.cli.download(\"en\")\n",
        "spacy.cli.download(\"fr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZzQANhYZIkb"
      },
      "source": [
        "# Datos\n",
        "\n",
        "Vamos a seguir trabajando con los datos de parejas de oraciones en Frances-w Inglés.\n",
        "\n",
        "    I am cold.    J'ai froid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qxV7Rk_mZNas",
        "outputId": "d40db52f-9b38-4345-fec7-3134be3a994d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-07 23:09:29--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.38.106, 99.86.38.72, 99.86.38.37, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.38.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-11-07 23:09:29 (47.5 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xIp1UOFPZYuy",
        "outputId": "a3e32ff4-ae24-4952-ad3d-04e6ca070536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  English  \\\n",
              "0                                                     Go.   \n",
              "1                                                    Run!   \n",
              "2                                                    Run!   \n",
              "3                                                    Wow!   \n",
              "4                                                   Fire!   \n",
              "...                                                   ...   \n",
              "135837  A carbon footprint is the amount of carbon dio...   \n",
              "135838  Death is something that we're often discourage...   \n",
              "135839  Since there are usually multiple websites on a...   \n",
              "135840  If someone who doesn't know your background sa...   \n",
              "135841  It may be impossible to get a completely error...   \n",
              "\n",
              "                                                   French  \n",
              "0                                                    Va !  \n",
              "1                                                 Cours !  \n",
              "2                                                Courez !  \n",
              "3                                              Ça alors !  \n",
              "4                                                Au feu !  \n",
              "...                                                   ...  \n",
              "135837  Une empreinte carbone est la somme de pollutio...  \n",
              "135838  La mort est une chose qu'on nous décourage sou...  \n",
              "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
              "135841  Il est peut-être impossible d'obtenir un Corpu...  \n",
              "\n",
              "[135842 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-addaed62-6852-4fc3-bb99-599ade25bcaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Au feu !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135837</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135838</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135839</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135840</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135841</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135842 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-addaed62-6852-4fc3-bb99-599ade25bcaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-addaed62-6852-4fc3-bb99-599ade25bcaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-addaed62-6852-4fc3-bb99-599ade25bcaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a639b7d2-1a66-47fe-a210-cff05cf11df0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a639b7d2-1a66-47fe-a210-cff05cf11df0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a639b7d2-1a66-47fe-a210-cff05cf11df0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Take a peek at the dataset\n",
        "dataset = pd.read_csv(\"data/eng-fra.txt\", sep=\"\\t\", header=None)\n",
        "dataset.columns = [\"English\", \"French\"]\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ScPj8X66po4c"
      },
      "outputs": [],
      "source": [
        "# dataset = dataset.sample(int(len(dataset)*0.4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VQdP-OPws-82"
      },
      "outputs": [],
      "source": [
        "# Remove very long sentences\n",
        "\n",
        "MAX_SEQ_LEN = 50\n",
        "\n",
        "dataset['en_len'] = dataset['English'].str.count(' ')\n",
        "dataset['fr_len'] = dataset['French'].str.count(' ')\n",
        "dataset = dataset[\n",
        "    (dataset['fr_len'] < MAX_SEQ_LEN) &\n",
        "    (dataset['en_len'] < MAX_SEQ_LEN)\n",
        "][['English', 'French']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cb0hfkkpulUK"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train, val and test\n",
        "train, val_test = train_test_split(dataset, test_size=0.2, random_state=RANDOM_SEED)\n",
        "val, test = train_test_split(val_test, test_size=0.5)\n",
        "\n",
        "# Save splits to CSV files\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "val.to_csv(\"val.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aX1sIWsFq7rB"
      },
      "outputs": [],
      "source": [
        "# Load English and French models\n",
        "en = spacy.load('en_core_web_sm')\n",
        "fr = spacy.load('fr_core_news_sm')\n",
        "\n",
        "def tokenize_en(sentence):\n",
        "    return [tok.text for tok in en.tokenizer(sentence)]\n",
        "\n",
        "def tokenize_fr(sentence):\n",
        "    return [tok.text for tok in fr.tokenizer(sentence)]\n",
        "\n",
        "EN_TEXT = Field(tokenize=tokenize_en, fix_length=MAX_SEQ_LEN)\n",
        "FR_TEXT = Field(tokenize=tokenize_fr, init_token = \"<sos>\", eos_token = \"<eos>\", fix_length=MAX_SEQ_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HOh05JVfydM9"
      },
      "outputs": [],
      "source": [
        "# Associate the text in the 'English' column with the EN_TEXT field,\n",
        "# and 'French' with FR_TEXT\n",
        "data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n",
        "\n",
        "train, val = TabularDataset.splits(\n",
        "    path='./',\n",
        "    train='train.csv',\n",
        "    validation='val.csv',\n",
        "    format='csv',\n",
        "    fields=data_fields\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_mAjoiHS4BH7"
      },
      "outputs": [],
      "source": [
        "# Build vocabularies\n",
        "FR_TEXT.build_vocab(train, val)\n",
        "EN_TEXT.build_vocab(train, val)\n",
        "\n",
        "# Construct a train iterator\n",
        "train_iter = BucketIterator(\n",
        "    train,\n",
        "    batch_size=32,\n",
        "    sort_key=lambda x: len(x.French),\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO8tpkFPbdpN"
      },
      "source": [
        "# Armando el transformer paso a paso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lur0pJDoW8Hh"
      },
      "source": [
        "![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n",
        "\n",
        "El diagrama ilustra el modelo que vamos a implementar. Los inputs al encoder son las oraciones en Frances, y los \"Outputs\" que entran al decoder son las sentencias en Inglés.\n",
        "\n",
        "Necesitamos entender 5 procesos para implementar el modelo:\n",
        "- Embedding de los inputs\n",
        "- Encoding Posicional\n",
        "- Creación de máscaras\n",
        "- La capa de Multi-Head Attention\n",
        "- La capa Feed-Forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ULN-z2W8DJ"
      },
      "source": [
        "## Encoding Posicional\n",
        "----\n",
        "El embedding de cada palabra aprende su significado, ahora necesitamos una manera de que la red aprenda sobre la posicion de cada palabra en la sentencia.\n",
        "\n",
        "[Vaswani *et al.*](https://arxiv.org/abs/1706.03762) respondió esta pregunta usando las siguientes funciones para crear valores constantes relacionados a cada posición:\n",
        "\n",
        "$$ PE_{(pos, 2i)} = sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n",
        "$$ PE_{(pos, 2i+1)} = cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right) $$\n",
        "\n",
        "Esta constante es una matriz en 2D con una de las dimensiones de igual tamaño que los embeddings y la otra igual a la cantidad de palabras en la sentencia.\n",
        "\n",
        "![Positional encoding matrix](https://miro.medium.com/max/1359/1*B-VR6R5vJl3Y7jbMNf5Fpw.png)\n",
        "\n",
        "![Positional encoding example](http://jalammar.github.io/images/t/transformer_positional_encoding_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POsitional encoding le da al modelo una sensacion de temporalidad (por eso introduce seno y coseno) [Parecido a electronica]"
      ],
      "metadata": {
        "id": "6s19rJdmKia5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G7aRi6k5f-dk"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len=MAX_SEQ_LEN, dropout=0.1):\n",
        "        super(PositionalEncoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Create constant 'pe' matrix with values dependant on pos and i\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = 1.0 / torch.pow(10000, torch.arange(0, d_model, 2).float() / d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # We register them as a buffer so the optimzer doesn't see this as parameters of the model to optimize!\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Make embeddings relatively larger\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        # Add constant to embedding\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 100\n",
        "d_model = 4\n",
        "pos_enc = PositionalEncoder(d_model, MAX_SEQ_LEN , 0) # d_model es el largo de embeddings, max_seq_len largo maximo de la secuencia\n",
        "example = torch.zeros(1,MAX_SEQ_LEN,d_model)"
      ],
      "metadata": {
        "id": "u-6_ZveCHsiK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_enc(example)"
      ],
      "metadata": {
        "id": "gYC-dejbII5N",
        "outputId": "454c06ba-8934-4285-c616-62fb8a01b62d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
              "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
              "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
              "         [-0.7568, -0.6536,  0.0400,  0.9992],\n",
              "         [-0.9589,  0.2837,  0.0500,  0.9988],\n",
              "         [-0.2794,  0.9602,  0.0600,  0.9982],\n",
              "         [ 0.6570,  0.7539,  0.0699,  0.9976],\n",
              "         [ 0.9894, -0.1455,  0.0799,  0.9968],\n",
              "         [ 0.4121, -0.9111,  0.0899,  0.9960],\n",
              "         [-0.5440, -0.8391,  0.0998,  0.9950],\n",
              "         [-1.0000,  0.0044,  0.1098,  0.9940],\n",
              "         [-0.5366,  0.8439,  0.1197,  0.9928],\n",
              "         [ 0.4202,  0.9074,  0.1296,  0.9916],\n",
              "         [ 0.9906,  0.1367,  0.1395,  0.9902],\n",
              "         [ 0.6503, -0.7597,  0.1494,  0.9888],\n",
              "         [-0.2879, -0.9577,  0.1593,  0.9872],\n",
              "         [-0.9614, -0.2752,  0.1692,  0.9856],\n",
              "         [-0.7510,  0.6603,  0.1790,  0.9838],\n",
              "         [ 0.1499,  0.9887,  0.1889,  0.9820],\n",
              "         [ 0.9129,  0.4081,  0.1987,  0.9801],\n",
              "         [ 0.8367, -0.5477,  0.2085,  0.9780],\n",
              "         [-0.0089, -1.0000,  0.2182,  0.9759],\n",
              "         [-0.8462, -0.5328,  0.2280,  0.9737],\n",
              "         [-0.9056,  0.4242,  0.2377,  0.9713],\n",
              "         [-0.1324,  0.9912,  0.2474,  0.9689],\n",
              "         [ 0.7626,  0.6469,  0.2571,  0.9664],\n",
              "         [ 0.9564, -0.2921,  0.2667,  0.9638],\n",
              "         [ 0.2709, -0.9626,  0.2764,  0.9611],\n",
              "         [-0.6636, -0.7481,  0.2860,  0.9582],\n",
              "         [-0.9880,  0.1543,  0.2955,  0.9553],\n",
              "         [-0.4040,  0.9147,  0.3051,  0.9523],\n",
              "         [ 0.5514,  0.8342,  0.3146,  0.9492],\n",
              "         [ 0.9999, -0.0133,  0.3240,  0.9460],\n",
              "         [ 0.5291, -0.8486,  0.3335,  0.9428],\n",
              "         [-0.4282, -0.9037,  0.3429,  0.9394],\n",
              "         [-0.9918, -0.1280,  0.3523,  0.9359],\n",
              "         [-0.6435,  0.7654,  0.3616,  0.9323],\n",
              "         [ 0.2964,  0.9551,  0.3709,  0.9287],\n",
              "         [ 0.9638,  0.2666,  0.3802,  0.9249],\n",
              "         [ 0.7451, -0.6669,  0.3894,  0.9211],\n",
              "         [-0.1586, -0.9873,  0.3986,  0.9171],\n",
              "         [-0.9165, -0.4000,  0.4078,  0.9131],\n",
              "         [-0.8318,  0.5551,  0.4169,  0.9090],\n",
              "         [ 0.0177,  0.9998,  0.4259,  0.9048],\n",
              "         [ 0.8509,  0.5253,  0.4350,  0.9004],\n",
              "         [ 0.9018, -0.4322,  0.4439,  0.8961],\n",
              "         [ 0.1236, -0.9923,  0.4529,  0.8916],\n",
              "         [-0.7683, -0.6401,  0.4618,  0.8870],\n",
              "         [-0.9538,  0.3006,  0.4706,  0.8823],\n",
              "         [-0.2624,  0.9650,  0.4794,  0.8776],\n",
              "         [ 0.6702,  0.7422,  0.4882,  0.8727],\n",
              "         [ 0.9866, -0.1630,  0.4969,  0.8678],\n",
              "         [ 0.3959, -0.9183,  0.5055,  0.8628],\n",
              "         [-0.5588, -0.8293,  0.5141,  0.8577],\n",
              "         [-0.9998,  0.0221,  0.5227,  0.8525],\n",
              "         [-0.5216,  0.8532,  0.5312,  0.8473],\n",
              "         [ 0.4362,  0.8999,  0.5396,  0.8419],\n",
              "         [ 0.9929,  0.1192,  0.5480,  0.8365],\n",
              "         [ 0.6367, -0.7711,  0.5564,  0.8309],\n",
              "         [-0.3048, -0.9524,  0.5646,  0.8253],\n",
              "         [-0.9661, -0.2581,  0.5729,  0.8196],\n",
              "         [-0.7392,  0.6735,  0.5810,  0.8139],\n",
              "         [ 0.1674,  0.9859,  0.5891,  0.8080],\n",
              "         [ 0.9200,  0.3919,  0.5972,  0.8021],\n",
              "         [ 0.8268, -0.5625,  0.6052,  0.7961],\n",
              "         [-0.0266, -0.9996,  0.6131,  0.7900],\n",
              "         [-0.8555, -0.5178,  0.6210,  0.7838],\n",
              "         [-0.8979,  0.4401,  0.6288,  0.7776],\n",
              "         [-0.1148,  0.9934,  0.6365,  0.7712],\n",
              "         [ 0.7739,  0.6333,  0.6442,  0.7648],\n",
              "         [ 0.9511, -0.3090,  0.6518,  0.7584],\n",
              "         [ 0.2538, -0.9673,  0.6594,  0.7518],\n",
              "         [-0.6768, -0.7362,  0.6669,  0.7452],\n",
              "         [-0.9851,  0.1717,  0.6743,  0.7385],\n",
              "         [-0.3878,  0.9218,  0.6816,  0.7317],\n",
              "         [ 0.5661,  0.8243,  0.6889,  0.7248],\n",
              "         [ 0.9995, -0.0310,  0.6961,  0.7179],\n",
              "         [ 0.5140, -0.8578,  0.7033,  0.7109],\n",
              "         [-0.4441, -0.8960,  0.7104,  0.7038],\n",
              "         [-0.9939, -0.1104,  0.7174,  0.6967],\n",
              "         [-0.6299,  0.7767,  0.7243,  0.6895],\n",
              "         [ 0.3132,  0.9497,  0.7311,  0.6822],\n",
              "         [ 0.9684,  0.2495,  0.7379,  0.6749],\n",
              "         [ 0.7332, -0.6800,  0.7446,  0.6675],\n",
              "         [-0.1761, -0.9844,  0.7513,  0.6600],\n",
              "         [-0.9235, -0.3837,  0.7578,  0.6524],\n",
              "         [-0.8218,  0.5698,  0.7643,  0.6448],\n",
              "         [ 0.0354,  0.9994,  0.7707,  0.6372],\n",
              "         [ 0.8601,  0.5102,  0.7771,  0.6294],\n",
              "         [ 0.8940, -0.4481,  0.7833,  0.6216],\n",
              "         [ 0.1060, -0.9944,  0.7895,  0.6137],\n",
              "         [-0.7795, -0.6264,  0.7956,  0.6058],\n",
              "         [-0.9483,  0.3174,  0.8016,  0.5978],\n",
              "         [-0.2453,  0.9695,  0.8076,  0.5898],\n",
              "         [ 0.6833,  0.7302,  0.8134,  0.5817],\n",
              "         [ 0.9836, -0.1804,  0.8192,  0.5735],\n",
              "         [ 0.3796, -0.9251,  0.8249,  0.5653],\n",
              "         [-0.5734, -0.8193,  0.8305,  0.5570],\n",
              "         [-0.9992,  0.0398,  0.8360,  0.5487]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv2ZLhMqW79c"
      },
      "source": [
        "## Máscaras para los inputs\n",
        "----\n",
        "Las máscaras de ceros cumplen dos propósitos:\n",
        "\n",
        "- En **ambos** encoder y decoder: Para obtener 0s en la atención sobre el padding.\n",
        "- En el **decoder**: Prevenir que el decoder \"espíe\" a los siguientes inputs de la secuencia traducida, el futuro que no debería conocer para predecir la siguiente palabra. Evita que el decoder \"vea\" lo que tiene que predecir antes de predecirlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nqDBxGZg5xOq"
      },
      "outputs": [],
      "source": [
        "def build_attn_pad_mask(seq, pad_index): # Dado un valor de padding va a chequear si la secuencia es igual o no al tamaño de la matriz. Paddings = 0\n",
        "    # Creates mask with 0s wherever there is padding in the input\n",
        "    return (seq != pad_index).unsqueeze(1).type(torch.uint8)\n",
        "\n",
        "\n",
        "def build_nopeak_mask(size):\n",
        "    # Creates mask with 1s up until the the index of the word being predicted\n",
        "    nopeak_mask = torch.triu(torch.ones(size, size)).transpose(0, 1)\n",
        "    return nopeak_mask.unsqueeze(0).type(torch.uint8)\n",
        "\n",
        "def create_masks(src, src_pad, trg=None, trg_pad=None):\n",
        "    src_mask = build_attn_pad_mask(src, src_pad)\n",
        "\n",
        "    if trg is not None:\n",
        "        trg_mask = build_attn_pad_mask(trg, trg_pad)\n",
        "        size = trg.size(1) # get seq_len for matrix\n",
        "        np_mask = build_nopeak_mask(size)\n",
        "        trg_mask = trg_mask & np_mask\n",
        "    else:\n",
        "        trg_mask = None\n",
        "\n",
        "    return src_mask, trg_mask"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tensor = torch.tensor([[4,5,3,666,666,666,666]])\n",
        "build_attn_pad_mask(example_tensor,666)"
      ],
      "metadata": {
        "id": "TemOH04wLHXu",
        "outputId": "9fa81a3a-bd78-4864-f1e5-e29d013a5b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 1, 1, 0, 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_nopeak_mask(len(example_tensor[0]))"
      ],
      "metadata": {
        "id": "l41gIzSyLX2_",
        "outputId": "2c0ee0bc-e918-4cb1-d050-7f2fc55e8fbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_target_tensor = torch.tensor([[1,2,3,28,28,28,28]])"
      ],
      "metadata": {
        "id": "jSx5_nGoL31-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = create_masks(example_tensor, 666,example_target_tensor,28)"
      ],
      "metadata": {
        "id": "Hm-y2fdOMBhm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_target_tensor * masks[1] # esto es lo que hace el transformer, tiene todo de una para poder procesarlo"
      ],
      "metadata": {
        "id": "e8XAVwgHMmYd",
        "outputId": "88de5b70-61f2-4dc2-bd4f-faa92ad3b052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 2, 0, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 0, 0, 0, 0]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dulPyzCqW74v"
      },
      "source": [
        "## Multi-Head Attention\n",
        "----\n",
        "\n",
        "![Multihead attention schema](https://miro.medium.com/max/1254/1*1tsRtfaY9z6HxmERYhw8XQ.png)\n",
        "\n",
        "$V$, $K$ y $Q$ reprensentan ‘key’, ‘value’ and ‘query’. En el caso del Encoder, $V$, $K$ and $Q$ serán simplemente copias idénticas del vector de embedding (junto con el encoding posicional). Tendrán las siguientes dimensiones $\\text{batch_size} \\times \\text{seq_len} \\times d_\\text{model}$.\n",
        "\n",
        "En multi-head attention repartimos el vector de embedding en $N$ cabezas, por lo que tendrán las dimensiones: $\\text{batch_size} \\times N \\times \\text{seq_len} \\times (d_{\\text{model}} / N)$.\n",
        "\n",
        "La dimensión final: ($d_{\\text{model}} / N$) es a lo que llamaremos $d_k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-_fobf8E7pD"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, attn_pdrop = 0.1, resid_pdrop = 0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // heads\n",
        "        self.h = heads\n",
        "\n",
        "        # Q, K, V\n",
        "\n",
        "        # Regularization\n",
        "\n",
        "        # Output projection\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        # Get batch size\n",
        "        bs = q.size(0)\n",
        "\n",
        "        # Perform linear operation and split into h heads\n",
        "\n",
        "        # Transpose to get dimensions bs * h * sl * d_model\n",
        "\n",
        "        # Calculate attention scores using function we will define next\n",
        "\n",
        "        # Re-assemble all head outputs side by side\n",
        "        # Need to use contigous here to get correspondence\n",
        "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
        "\n",
        "        # Output projection\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W28fJmT9HXGk"
      },
      "source": [
        "### Mecanismo de Atención\n",
        "----\n",
        "\n",
        "![Attention diagram](https://miro.medium.com/max/336/1*15E9qKg9bKnWdSRWCyY2iA.png)\n",
        "![Attention equation](https://miro.medium.com/max/1068/1*evdACdTOBT5j1g1nXialBg.png)\n",
        "\n",
        "Inicialmente, multiplicamos $Q$ por la transpuesta de $K$. Esto es luego dividipo por $\\sqrt{d_k}$ (normalización).\n",
        "\n",
        "Algo que aún no vimos es qué hacer con atención y las máscaras. Antes de hacer el Softmax, aplicamos nuestra máscara de ceros para reducir los valores donde el input es padding (o futuro).\n",
        "\n",
        "Finalmente, el último paso es hacer el producto (dot product) entre el resultado hasta ahora y $V$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQTmzZ35Je5W"
      },
      "outputs": [],
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "\n",
        "    output = torch.matmul(scores, v)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97KT06QVcELb"
      },
      "source": [
        "## Capa Feed-Forward\n",
        "----\n",
        "Esta capa solo consiste en dos opeaciones lineales (nn.Linear) con ReLU y dropout entre ellas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXXhptZ3JvhC"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  # ??\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q4nextzKJFO"
      },
      "source": [
        "# Combinando todo\n",
        "\n",
        "Vamos a crear una capa EncoderLayer y DecoderLayer que agrupan los componentes necesarios para crear un solo encoder (o decoder).\n",
        "\n",
        "Luego, creamos el Encoder de nuestra arquitectura, conteniendo N de estos bloques anteriores. Repetimos para el decoder.\n",
        "\n",
        "![Transformer architecture](https://miro.medium.com/max/1140/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD-7Yks3K31b"
      },
      "outputs": [],
      "source": [
        "# Build an encoder layer with one multi-head attention layer and one\n",
        "# feed-forward layer\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout = 0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attn = MultiHeadAttention(heads, d_model, dropout, dropout)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # ??\n",
        "        return x\n",
        "\n",
        "# Build a decoder layer with two multi-head attention layers and\n",
        "# one feed-forward layer\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
        "        # ??\n",
        "        return x\n",
        "\n",
        "# Convenient cloning function that can generate multiple layers:\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QMVOFpaKK2z"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.N = N\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "\n",
        "    def forward(self, src, mask):\n",
        "        # ??\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.N = N\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "\n",
        "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "        # ??\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUxlnAGv-AMu"
      },
      "source": [
        "Finalmente usando los dos bloques anteriores y una capa linear creamos el transformer con $N$ encoders/decoders!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58aNa611MsK_"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
        "        super(Transformer, self).__init__()\n",
        "        # ??\n",
        "\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        # ??\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSYVGuqCM-Hn"
      },
      "source": [
        "# Entrenando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wun9klgM9AN"
      },
      "outputs": [],
      "source": [
        "d_model = 128\n",
        "heads = 4\n",
        "N = 3\n",
        "src_vocab = len(EN_TEXT.vocab)\n",
        "trg_vocab = len(FR_TEXT.vocab)\n",
        "\n",
        "model = Transformer(src_vocab, trg_vocab, d_model, N, heads).to(DEVICE)\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "# This code is very important! It initialises the parameters with a\n",
        "# range of values that stops the signal fading or getting too big.\n",
        "# See this blog for a mathematical explanation:\n",
        "# https://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNKzh6dLNYVR"
      },
      "outputs": [],
      "source": [
        "def train_model(epochs, print_every=100):\n",
        "    model.train()\n",
        "\n",
        "    start = time.time()\n",
        "    temp = start\n",
        "    total_loss = 0\n",
        "\n",
        "    src_pad = EN_TEXT.vocab.stoi['<pad>']\n",
        "    trg_pad = FR_TEXT.vocab.stoi['<pad>']\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            src = batch.English.transpose(0, 1)\n",
        "            trg = batch.French.transpose(0, 1)\n",
        "            # the French sentence we input has all words except\n",
        "            # the last, as it is using each word to predict the next\n",
        "            trg_input = trg[:, :-1]\n",
        "\n",
        "            # the words we are trying to predict\n",
        "            targets = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            # create function to make masks using mask code above\n",
        "            src_mask, trg_mask = create_masks(src, src_pad, trg_input, trg_pad)\n",
        "\n",
        "            preds = model(src.to(DEVICE), trg_input.to(DEVICE), src_mask.to(DEVICE), trg_mask.to(DEVICE))\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            loss = F.cross_entropy(\n",
        "                preds.view(-1, preds.size(-1)),\n",
        "                targets.to(DEVICE),\n",
        "                ignore_index=trg_pad\n",
        "            )\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.item()\n",
        "            if (i + 1) % print_every == 0:\n",
        "                loss_avg = total_loss / print_every\n",
        "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f, %ds per %d iters\" % (\n",
        "                    (time.time() - start) // 60, epoch + 1, i + 1, loss_avg, time.time() - temp, print_every)\n",
        "                )\n",
        "                total_loss = 0\n",
        "                temp = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGfw-ZZffh5P"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
        "\n",
        "train_model(1) # Train for 10 epochs (~60min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiaAAFHrb-Fl"
      },
      "outputs": [],
      "source": [
        "def translate(model, src, max_len=80):\n",
        "  model.eval()\n",
        "\n",
        "  input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
        "\n",
        "  src = tokenize_en(src)\n",
        "  src = (torch.LongTensor([[EN_TEXT.vocab.stoi[tok] for tok in src]])).cuda()\n",
        "\n",
        "  src_mask = (src != input_pad).unsqueeze(-2).cuda()\n",
        "  e_outputs = model.encoder(src, src_mask)\n",
        "\n",
        "  outputs = torch.zeros(max_len).type_as(src.data)\n",
        "  outputs[0] = torch.LongTensor([FR_TEXT.vocab.stoi['<sos>']])\n",
        "\n",
        "  for i in range(1, max_len):\n",
        "    trg_mask = torch.triu(torch.ones((1, i, i))).type(torch.uint8)\n",
        "    trg_mask = ((trg_mask) == 0).cuda()\n",
        "\n",
        "    out = model.out(model.decoder(outputs[:i].unsqueeze(0), e_outputs, src_mask, trg_mask))\n",
        "    out = F.softmax(out, dim=-1)\n",
        "    val, ix = out[:, -1].data.topk(1)\n",
        "\n",
        "    outputs[i] = ix[0][0]\n",
        "\n",
        "    if ix[0][0] == FR_TEXT.vocab.stoi['<eos>']:\n",
        "        break\n",
        "\n",
        "  return ' '.join([FR_TEXT.vocab.itos[ix] for ix in outputs[:i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FALTQeiJdXQQ"
      },
      "outputs": [],
      "source": [
        "translate(model, \"How are you ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHnAGr1WGeO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky-OfrkNWGhZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL5UiQeaWGkS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Transformers_Letra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}