{"cells":[{"cell_type":"markdown","metadata":{"id":"7VMtkNDwxZ0m"},"source":["# Datos y Preprocesamiento\n","\n","Vamos a usar el dataset de IMDB para clasificación de reseñas de películas, el objetivo del mismo es detectar si una reseña tiene sentimiento **positivo** o **negativo**.\n","\n","Descarguen el dataset de este [link](https://drive.google.com/file/d/1i0bBI4p80AxsLgnWcXkxVT65AahIzePu/view?usp=sharing) y subanlo a una carpeta **data** en la raiz de su drive personal.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zh7A9mjs3cfU"},"outputs":[],"source":["import pandas as pd\n","# from google.colab import drive\n","# drive.mount(\"/content/drive\")\n","\n","# ! cp \"/content/drive/My Drive/data/IMDB_Dataset.zip\" .\n","# ! unzip -q IMDB_Dataset.zip\n","# ! rm IMDB_Dataset.zip\n","# ! ls"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sJYwO9zbvCLh"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["import re\n","import time\n","from itertools import chain\n","from bs4 import BeautifulSoup\n","from collections import Counter\n","\n","import nltk\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","from sklearn.metrics import accuracy_score\n","# from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(DEVICE)\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BBaFc6ZZzp2T"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['review', 'sentiment'], dtype='object')\n"]}],"source":["imdb_data = pd.read_csv(\"IMDB Dataset.csv\")\n","\n","#sentiment count\n","print(imdb_data.columns)\n","imdb_data['sentiment'].value_counts()\n","\n","# Convert positive and negative into binary classes (1-0)\n","from sklearn.preprocessing import LabelBinarizer\n","lb = LabelBinarizer()\n","\n","sentiment_data = lb.fit_transform(imdb_data[\"sentiment\"])\n","imdb_data['sentiment'] = sentiment_data"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>one reviewer mentioned watching oz episode you...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wonderful little production filming technique ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  one reviewer mentioned watching oz episode you...          1\n","1  wonderful little production filming technique ...          1"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["imdb_data.head(2)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jKV_HYQCvEFv"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_38040\\2568498145.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text, \"html.parser\")\n"]}],"source":["def strip_html(text):\n","  soup = BeautifulSoup(text, \"html.parser\")\n","  return soup.get_text()\n","\n","\n","def remove_between_square_brackets(text):\n","  return re.sub('\\[[^]]*\\]', '', text)\n","\n","\n","def remove_special_characters(text):\n","  pattern = r'[^a-zA-z\\s]'\n","  text = re.sub(pattern,'',text)\n","  return text\n","\n","\n","def low_level_preproc(text):\n","  text = strip_html(text)\n","  text = remove_between_square_brackets(text)\n","  text = remove_special_characters(text)\n","  return text\n","\n","#Apply function on review column\n","imdb_data['review'] = imdb_data['review'].apply(low_level_preproc)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"orEVYliBvEmq"},"outputs":[],"source":["all_stopwords = set(stopwords.words(\"english\"))\n","\n","def remove_stop_words(full_text_line):\n","  tokens = full_text_line.split()\n","  tokens = [tok for tok in tokens if tok not in all_stopwords]\n","\n","  return \" \".join(tokens)\n","\n","\n","def lemmatize(text):\n","  wnl= WordNetLemmatizer()\n","  lemas = [wnl.lemmatize(word) for word in text.split()]\n","\n","  return \" \".join(lemas)\n","\n","\n","def high_level_preproc(text):\n","  text = remove_stop_words(text)\n","  return lemmatize(text)\n","\n","\n","#Apply function on review column\n","imdb_data['review'] = imdb_data['review'].str.lower()\n","imdb_data['review'] = imdb_data['review'].apply(high_level_preproc)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zgyBKqd6uhLz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set: (40000,) (40000,)\n","Test set: (10000,) (10000,)\n"]}],"source":["#split the dataset  \n","#train dataset\n","train_reviews = imdb_data.review[:40000]\n","train_sentiments = imdb_data.sentiment[:40000]\n","\n","#test dataset\n","test_reviews = imdb_data.review[40000:]\n","test_sentiments = imdb_data.sentiment[40000:]\n","\n","\n","print(\"Train set:\", train_reviews.shape, train_sentiments.shape)\n","print(\"Test set:\", test_reviews.shape, test_sentiments.shape)"]},{"cell_type":"markdown","metadata":{"id":"6QZ6OiUBrzbM"},"source":["# Vocabulario y Encoding\n","\n","Vamos a crear un volcabulario para el problema, de este modo podemos representar cada palabra con un entero único. Esto nos va a permitir representar una review como una lista de ints (que luego el modelo va a mapear a word embeddings!).\n","\n","Una cosa a tener en cuenta es que vamos a querer agregar padding a nuestros inputs (para que todas las reviews tengan el mismo largo), para esto vamos a usar el 0, por lo que las palabras de nuestro vocabulario deben empezar en 1.\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["Counter({'movie': 79356,\n","         'film': 71546,\n","         'one': 41970,\n","         'like': 31753,\n","         'time': 23465,\n","         'good': 23088,\n","         'character': 21910,\n","         'get': 19516,\n","         'even': 19479,\n","         'story': 19330,\n","         'would': 19320,\n","         'make': 18857,\n","         'see': 18704,\n","         'really': 18250,\n","         'scene': 16515,\n","         'much': 15126,\n","         'well': 14957,\n","         'people': 14384,\n","         'great': 14185,\n","         'bad': 14153,\n","         'also': 13909,\n","         'show': 13493,\n","         'first': 13325,\n","         'dont': 13272,\n","         'way': 13153,\n","         'thing': 12811,\n","         'made': 12389,\n","         'could': 12103,\n","         'think': 12044,\n","         'life': 11456,\n","         'go': 11415,\n","         'know': 11219,\n","         'watch': 10932,\n","         'love': 10731,\n","         'many': 10612,\n","         'seen': 10454,\n","         'actor': 10439,\n","         'plot': 10427,\n","         'two': 10390,\n","         'never': 10322,\n","         'say': 10221,\n","         'look': 10098,\n","         'acting': 10001,\n","         'little': 9842,\n","         'end': 9833,\n","         'best': 9816,\n","         'year': 9793,\n","         'ever': 9353,\n","         'take': 8865,\n","         'better': 8851,\n","         'man': 8768,\n","         'come': 8701,\n","         'still': 8581,\n","         'work': 8267,\n","         'part': 7944,\n","         'find': 7885,\n","         'something': 7861,\n","         'want': 7781,\n","         'give': 7731,\n","         'lot': 7640,\n","         'back': 7393,\n","         'director': 7236,\n","         'im': 7226,\n","         'guy': 7196,\n","         'real': 7185,\n","         'watching': 7138,\n","         'doesnt': 7020,\n","         'performance': 7018,\n","         'didnt': 6982,\n","         'play': 6921,\n","         'woman': 6921,\n","         'funny': 6731,\n","         'actually': 6707,\n","         'though': 6681,\n","         'another': 6503,\n","         'nothing': 6491,\n","         'going': 6440,\n","         'u': 6437,\n","         'new': 6391,\n","         'role': 6339,\n","         'every': 6314,\n","         'old': 6273,\n","         'girl': 6037,\n","         'cant': 5980,\n","         'point': 5903,\n","         'feel': 5843,\n","         'thats': 5823,\n","         'day': 5802,\n","         'world': 5794,\n","         'quite': 5793,\n","         'cast': 5785,\n","         'fact': 5777,\n","         'minute': 5773,\n","         'pretty': 5712,\n","         'seems': 5635,\n","         'thought': 5623,\n","         'young': 5558,\n","         'comedy': 5555,\n","         'around': 5550,\n","         'horror': 5494,\n","         'got': 5492,\n","         'big': 5344,\n","         'enough': 5316,\n","         'action': 5299,\n","         'right': 5277,\n","         'bit': 5232,\n","         'may': 5204,\n","         'ive': 5184,\n","         'star': 5147,\n","         'however': 5138,\n","         'without': 5133,\n","         'fan': 5106,\n","         'friend': 5099,\n","         'line': 5057,\n","         'always': 5031,\n","         'long': 5025,\n","         'saw': 5012,\n","         'music': 4966,\n","         'must': 4960,\n","         'isnt': 4954,\n","         'original': 4951,\n","         'almost': 4938,\n","         'family': 4930,\n","         'series': 4844,\n","         'interesting': 4836,\n","         'whole': 4816,\n","         'set': 4775,\n","         'script': 4772,\n","         'least': 4735,\n","         'try': 4732,\n","         'done': 4714,\n","         'kid': 4626,\n","         'kind': 4616,\n","         'last': 4599,\n","         'might': 4588,\n","         'there': 4577,\n","         'shot': 4567,\n","         'far': 4523,\n","         'anything': 4513,\n","         'since': 4480,\n","         'he': 4479,\n","         'start': 4457,\n","         'probably': 4455,\n","         'reason': 4450,\n","         'effect': 4425,\n","         'tv': 4398,\n","         'put': 4365,\n","         'book': 4338,\n","         'away': 4260,\n","         'rather': 4229,\n","         'moment': 4216,\n","         'place': 4202,\n","         'yet': 4173,\n","         'worst': 4172,\n","         'fun': 4105,\n","         'anyone': 4102,\n","         'idea': 4096,\n","         'found': 4087,\n","         'need': 4086,\n","         'sure': 4077,\n","         'let': 4073,\n","         'played': 4053,\n","         'audience': 4037,\n","         'turn': 4012,\n","         'tell': 3972,\n","         'making': 3954,\n","         'believe': 3935,\n","         'child': 3912,\n","         'american': 3907,\n","         'trying': 3898,\n","         'course': 3889,\n","         'dvd': 3866,\n","         'hard': 3825,\n","         'especially': 3789,\n","         'ending': 3771,\n","         'job': 3712,\n","         'episode': 3710,\n","         'everything': 3700,\n","         'looking': 3690,\n","         'worth': 3687,\n","         'mean': 3683,\n","         'war': 3679,\n","         'although': 3667,\n","         'different': 3650,\n","         'someone': 3648,\n","         'main': 3630,\n","         'screen': 3597,\n","         'wasnt': 3578,\n","         'maybe': 3570,\n","         'keep': 3557,\n","         'watched': 3552,\n","         'sense': 3541,\n","         'problem': 3518,\n","         'version': 3515,\n","         'three': 3503,\n","         'money': 3460,\n","         'help': 3442,\n","         'true': 3419,\n","         'together': 3399,\n","         'said': 3399,\n","         'night': 3398,\n","         'seem': 3369,\n","         'second': 3365,\n","         'boy': 3326,\n","         'instead': 3296,\n","         'beautiful': 3294,\n","         'special': 3288,\n","         'john': 3284,\n","         'everyone': 3284,\n","         'later': 3278,\n","         'death': 3270,\n","         'black': 3270,\n","         'hour': 3269,\n","         'seeing': 3263,\n","         'left': 3230,\n","         'lead': 3218,\n","         'excellent': 3178,\n","         'wife': 3177,\n","         'short': 3170,\n","         'le': 3168,\n","         'laugh': 3152,\n","         'mind': 3151,\n","         'sound': 3135,\n","         'house': 3134,\n","         'classic': 3108,\n","         'read': 3097,\n","         'simply': 3090,\n","         'viewer': 3068,\n","         'name': 3053,\n","         'youre': 3043,\n","         'high': 3039,\n","         'piece': 3026,\n","         'used': 3016,\n","         'father': 3010,\n","         'completely': 3005,\n","         'production': 2993,\n","         'nice': 2978,\n","         'face': 2972,\n","         'else': 2956,\n","         'men': 2950,\n","         'poor': 2947,\n","         'human': 2932,\n","         'along': 2928,\n","         'eye': 2926,\n","         'couple': 2925,\n","         'half': 2888,\n","         'home': 2880,\n","         'picture': 2866,\n","         'song': 2857,\n","         'hollywood': 2842,\n","         'word': 2834,\n","         'use': 2827,\n","         'rest': 2809,\n","         'given': 2785,\n","         'boring': 2781,\n","         'enjoy': 2776,\n","         'wrong': 2745,\n","         'head': 2733,\n","         'truly': 2727,\n","         'either': 2726,\n","         'camera': 2725,\n","         'recommend': 2721,\n","         'dead': 2691,\n","         'kill': 2679,\n","         'school': 2675,\n","         'video': 2669,\n","         'hope': 2669,\n","         'stupid': 2667,\n","         'came': 2665,\n","         'game': 2643,\n","         'hand': 2639,\n","         'person': 2638,\n","         'next': 2637,\n","         'getting': 2609,\n","         'understand': 2607,\n","         'remember': 2605,\n","         'full': 2592,\n","         'budget': 2574,\n","         'awful': 2570,\n","         'run': 2566,\n","         'act': 2565,\n","         'case': 2559,\n","         'sex': 2555,\n","         'dialogue': 2548,\n","         'terrible': 2544,\n","         'sort': 2533,\n","         'fall': 2522,\n","         'wonderful': 2520,\n","         'others': 2520,\n","         'attempt': 2519,\n","         'playing': 2511,\n","         'mr': 2509,\n","         'mother': 2508,\n","         'top': 2506,\n","         'often': 2470,\n","         'title': 2465,\n","         'perhaps': 2463,\n","         'joke': 2457,\n","         'flick': 2454,\n","         'review': 2439,\n","         'perfect': 2437,\n","         'small': 2435,\n","         'care': 2433,\n","         'definitely': 2432,\n","         'absolutely': 2404,\n","         'couldnt': 2393,\n","         'went': 2393,\n","         'sequence': 2387,\n","         'feeling': 2382,\n","         'example': 2374,\n","         'early': 2372,\n","         'style': 2369,\n","         'killer': 2335,\n","         'certainly': 2329,\n","         'liked': 2320,\n","         'lost': 2311,\n","         'supposed': 2310,\n","         'become': 2306,\n","         'brother': 2295,\n","         'car': 2292,\n","         'cinema': 2277,\n","         'drama': 2275,\n","         'actress': 2269,\n","         'entertaining': 2267,\n","         'waste': 2266,\n","         'loved': 2266,\n","         'quality': 2257,\n","         'lack': 2255,\n","         'entire': 2250,\n","         'felt': 2242,\n","         'live': 2225,\n","         'several': 2225,\n","         'worse': 2224,\n","         'finally': 2216,\n","         'art': 2215,\n","         'direction': 2214,\n","         'beginning': 2207,\n","         'written': 2203,\n","         'totally': 2195,\n","         'matter': 2187,\n","         'writer': 2187,\n","         'favorite': 2181,\n","         'comment': 2179,\n","         'feature': 2178,\n","         'begin': 2172,\n","         'yes': 2169,\n","         'shes': 2156,\n","         'dark': 2153,\n","         'based': 2150,\n","         'side': 2149,\n","         'fight': 2147,\n","         'evil': 2140,\n","         'wanted': 2136,\n","         'son': 2135,\n","         'youll': 2133,\n","         'seemed': 2127,\n","         'white': 2117,\n","         'change': 2105,\n","         'becomes': 2094,\n","         'humor': 2094,\n","         'low': 2093,\n","         'final': 2092,\n","         'already': 2091,\n","         'wont': 2087,\n","         'murder': 2078,\n","         'able': 2077,\n","         'called': 2068,\n","         'relationship': 2056,\n","         'guess': 2056,\n","         'id': 2052,\n","         'meet': 2038,\n","         'hero': 2024,\n","         'heart': 2024,\n","         'throughout': 2018,\n","         'despite': 2016,\n","         'oh': 2012,\n","         'type': 2008,\n","         'fine': 2004,\n","         'number': 1999,\n","         'writing': 1994,\n","         'history': 1993,\n","         'experience': 1990,\n","         'today': 1972,\n","         'group': 1972,\n","         'move': 1971,\n","         'michael': 1964,\n","         'town': 1964,\n","         'theyre': 1960,\n","         'gave': 1959,\n","         'genre': 1955,\n","         'city': 1944,\n","         'amazing': 1944,\n","         'call': 1941,\n","         'enjoyed': 1939,\n","         'daughter': 1932,\n","         'horrible': 1926,\n","         'past': 1925,\n","         'cut': 1914,\n","         'hit': 1909,\n","         'behind': 1892,\n","         'talent': 1882,\n","         'power': 1873,\n","         'unfortunately': 1873,\n","         'age': 1867,\n","         'voice': 1862,\n","         'theme': 1853,\n","         'save': 1848,\n","         'expect': 1845,\n","         'credit': 1844,\n","         'situation': 1843,\n","         'event': 1843,\n","         'overall': 1843,\n","         'stop': 1841,\n","         'robert': 1839,\n","         'brilliant': 1838,\n","         'add': 1837,\n","         'body': 1833,\n","         'wonder': 1832,\n","         'god': 1828,\n","         'obviously': 1824,\n","         'sometimes': 1820,\n","         'stuff': 1809,\n","         'chance': 1802,\n","         'killed': 1798,\n","         'decent': 1798,\n","         'soon': 1788,\n","         'question': 1776,\n","         'directed': 1764,\n","         'late': 1764,\n","         'score': 1757,\n","         'thinking': 1756,\n","         'heard': 1747,\n","         'level': 1739,\n","         'took': 1737,\n","         'happens': 1736,\n","         'element': 1732,\n","         'hell': 1731,\n","         'view': 1719,\n","         'close': 1710,\n","         'highly': 1698,\n","         'extremely': 1697,\n","         'except': 1697,\n","         'leave': 1691,\n","         'wish': 1690,\n","         'cannot': 1689,\n","         'stand': 1687,\n","         'talk': 1680,\n","         'police': 1678,\n","         'told': 1678,\n","         'novel': 1674,\n","         'order': 1672,\n","         'ill': 1672,\n","         'coming': 1666,\n","         'interest': 1658,\n","         'wouldnt': 1653,\n","         'monster': 1650,\n","         'deal': 1650,\n","         'blood': 1649,\n","         'looked': 1647,\n","         'living': 1647,\n","         'particularly': 1642,\n","         'country': 1630,\n","         'involved': 1630,\n","         'strong': 1627,\n","         'happen': 1625,\n","         'including': 1622,\n","         'career': 1620,\n","         'serious': 1615,\n","         'husband': 1615,\n","         'taken': 1614,\n","         'etc': 1612,\n","         'reality': 1609,\n","         'simple': 1609,\n","         'complete': 1605,\n","         'musical': 1603,\n","         'violence': 1599,\n","         'across': 1598,\n","         'theater': 1596,\n","         'exactly': 1591,\n","         'effort': 1586,\n","         'obvious': 1585,\n","         'james': 1582,\n","         'opinion': 1582,\n","         'shown': 1582,\n","         'documentary': 1578,\n","         'happened': 1575,\n","         'light': 1575,\n","         'opening': 1565,\n","         'lady': 1565,\n","         'cool': 1563,\n","         'hilarious': 1562,\n","         'david': 1562,\n","         'twist': 1555,\n","         'female': 1551,\n","         'rating': 1549,\n","         'released': 1546,\n","         'sister': 1539,\n","         'ago': 1538,\n","         'known': 1537,\n","         'value': 1537,\n","         'saying': 1536,\n","         'slow': 1533,\n","         'whose': 1532,\n","         'ok': 1532,\n","         'english': 1531,\n","         'gore': 1516,\n","         'miss': 1515,\n","         'sequel': 1514,\n","         'huge': 1512,\n","         'running': 1512,\n","         'zombie': 1508,\n","         'room': 1502,\n","         'usually': 1501,\n","         'started': 1497,\n","         'alone': 1497,\n","         'cop': 1493,\n","         'local': 1491,\n","         'please': 1489,\n","         'dog': 1489,\n","         'possible': 1485,\n","         'annoying': 1483,\n","         'sad': 1483,\n","         'cinematography': 1482,\n","         'filmmaker': 1479,\n","         'crap': 1478,\n","         'major': 1476,\n","         'usual': 1475,\n","         'taking': 1473,\n","         'seriously': 1469,\n","         'dialog': 1468,\n","         'important': 1464,\n","         'somewhat': 1463,\n","         'none': 1461,\n","         'message': 1460,\n","         'beyond': 1459,\n","         'stay': 1451,\n","         'ridiculous': 1451,\n","         'knew': 1445,\n","         'open': 1440,\n","         'mostly': 1437,\n","         'turned': 1430,\n","         'dream': 1424,\n","         'thriller': 1423,\n","         'king': 1421,\n","         'silly': 1421,\n","         'due': 1420,\n","         'four': 1415,\n","         'apparently': 1410,\n","         'tale': 1409,\n","         'arent': 1409,\n","         'strange': 1407,\n","         'comic': 1402,\n","         'jack': 1401,\n","         'return': 1400,\n","         'street': 1399,\n","         'scary': 1399,\n","         'attention': 1399,\n","         'anyway': 1396,\n","         'team': 1395,\n","         'image': 1392,\n","         'parent': 1391,\n","         'surprise': 1391,\n","         'mention': 1391,\n","         'talking': 1389,\n","         'television': 1386,\n","         'upon': 1385,\n","         'hate': 1385,\n","         'clearly': 1379,\n","         'result': 1379,\n","         'rock': 1376,\n","         'producer': 1374,\n","         'happy': 1373,\n","         'disappointed': 1371,\n","         'subject': 1371,\n","         'member': 1370,\n","         'british': 1369,\n","         'single': 1367,\n","         'modern': 1362,\n","         'figure': 1361,\n","         'basically': 1357,\n","         'cheap': 1347,\n","         'hold': 1344,\n","         'george': 1338,\n","         'french': 1335,\n","         'whats': 1327,\n","         'season': 1325,\n","         'predictable': 1324,\n","         'crime': 1321,\n","         'whether': 1317,\n","         'doubt': 1313,\n","         'ten': 1313,\n","         'form': 1308,\n","         'state': 1305,\n","         'class': 1302,\n","         'easily': 1302,\n","         'havent': 1301,\n","         'western': 1299,\n","         'soundtrack': 1298,\n","         'entertainment': 1298,\n","         'supporting': 1297,\n","         'earth': 1295,\n","         'killing': 1293,\n","         'similar': 1289,\n","         'giving': 1287,\n","         'release': 1286,\n","         'certain': 1285,\n","         'aspect': 1285,\n","         'bring': 1283,\n","         'romantic': 1283,\n","         'appears': 1283,\n","         'enjoyable': 1280,\n","         'villain': 1280,\n","         'buy': 1278,\n","         'future': 1275,\n","         'viewing': 1275,\n","         'surprised': 1273,\n","         'peter': 1266,\n","         'tried': 1263,\n","         'clear': 1263,\n","         'storyline': 1261,\n","         'gun': 1260,\n","         'adult': 1258,\n","         'break': 1256,\n","         'emotion': 1256,\n","         'space': 1256,\n","         'drug': 1255,\n","         'showing': 1254,\n","         'five': 1251,\n","         'doctor': 1250,\n","         'among': 1245,\n","         'oscar': 1244,\n","         'bunch': 1242,\n","         'moving': 1241,\n","         'within': 1239,\n","         'filmed': 1238,\n","         'named': 1228,\n","         'easy': 1224,\n","         'using': 1218,\n","         'dull': 1217,\n","         'working': 1217,\n","         'middle': 1216,\n","         'kept': 1216,\n","         'gone': 1213,\n","         'dance': 1212,\n","         'mystery': 1207,\n","         'greatest': 1204,\n","         'present': 1202,\n","         'soldier': 1199,\n","         'near': 1199,\n","         'sorry': 1194,\n","         'student': 1190,\n","         'nearly': 1188,\n","         'typical': 1187,\n","         'material': 1184,\n","         'setting': 1183,\n","         'cartoon': 1182,\n","         'brought': 1181,\n","         'force': 1179,\n","         'actual': 1177,\n","         'battle': 1177,\n","         'suspense': 1171,\n","         'premise': 1171,\n","         'realistic': 1169,\n","         'detail': 1165,\n","         'standard': 1161,\n","         'period': 1160,\n","         'editing': 1159,\n","         'straight': 1158,\n","         'famous': 1157,\n","         'victim': 1156,\n","         'check': 1154,\n","         'somehow': 1151,\n","         'fantastic': 1148,\n","         'general': 1148,\n","         'mark': 1146,\n","         'note': 1145,\n","         'die': 1144,\n","         'issue': 1143,\n","         'alien': 1140,\n","         'imagine': 1140,\n","         'copy': 1137,\n","         'richard': 1135,\n","         'th': 1134,\n","         'spoiler': 1130,\n","         'paul': 1129,\n","         'rent': 1129,\n","         'york': 1127,\n","         'learn': 1127,\n","         'youve': 1125,\n","         'expected': 1122,\n","         'crew': 1117,\n","         'water': 1115,\n","         'dr': 1114,\n","         'hear': 1114,\n","         'offer': 1113,\n","         'animation': 1113,\n","         'particular': 1113,\n","         'male': 1113,\n","         'truth': 1113,\n","         'wait': 1113,\n","         'forget': 1110,\n","         'fit': 1105,\n","         'believable': 1104,\n","         'romance': 1104,\n","         'cause': 1101,\n","         'decided': 1101,\n","         'average': 1100,\n","         'eventually': 1100,\n","         'avoid': 1100,\n","         'escape': 1094,\n","         'german': 1092,\n","         'baby': 1089,\n","         'tom': 1089,\n","         'fast': 1087,\n","         'leaf': 1087,\n","         'weak': 1087,\n","         'america': 1086,\n","         'difficult': 1083,\n","         'who': 1082,\n","         'red': 1082,\n","         'sit': 1081,\n","         'vampire': 1081,\n","         'secret': 1079,\n","         'okay': 1077,\n","         'cover': 1077,\n","         'pay': 1077,\n","         'background': 1076,\n","         'masterpiece': 1074,\n","         'island': 1072,\n","         'deep': 1072,\n","         'society': 1070,\n","         'indeed': 1068,\n","         'stage': 1067,\n","         'atmosphere': 1067,\n","         'possibly': 1066,\n","         'poorly': 1065,\n","         'b': 1062,\n","         'gay': 1062,\n","         'studio': 1060,\n","         'walk': 1059,\n","         'lame': 1057,\n","         'follow': 1052,\n","         'whatever': 1052,\n","         'wood': 1051,\n","         'footage': 1050,\n","         'forced': 1048,\n","         'lee': 1048,\n","         'shame': 1046,\n","         'needed': 1043,\n","         'beauty': 1042,\n","         'emotional': 1041,\n","         'de': 1039,\n","         'choice': 1039,\n","         'memorable': 1038,\n","         'reading': 1038,\n","         'focus': 1036,\n","         'third': 1033,\n","         'screenplay': 1030,\n","         'imdb': 1027,\n","         'touch': 1026,\n","         'total': 1026,\n","         'remake': 1026,\n","         'interested': 1026,\n","         'became': 1026,\n","         'accent': 1024,\n","         'personal': 1022,\n","         'write': 1020,\n","         'la': 1020,\n","         'hot': 1019,\n","         'nature': 1018,\n","         'fire': 1018,\n","         'location': 1018,\n","         'cheesy': 1015,\n","         'scifi': 1013,\n","         'previous': 1012,\n","         'week': 1010,\n","         'party': 1010,\n","         'bill': 1009,\n","         'otherwise': 1006,\n","         'plus': 1005,\n","         'inside': 1005,\n","         'sexual': 1005,\n","         'weird': 999,\n","         'box': 998,\n","         'unless': 997,\n","         'development': 995,\n","         'japanese': 995,\n","         'business': 994,\n","         'girlfriend': 993,\n","         'towards': 992,\n","         'match': 990,\n","         'perfectly': 990,\n","         'air': 988,\n","         'crazy': 988,\n","         'animal': 988,\n","         'disney': 988,\n","         'lover': 986,\n","         'worked': 985,\n","         'incredibly': 984,\n","         'quickly': 984,\n","         'unique': 981,\n","         'superb': 981,\n","         'brings': 980,\n","         'adventure': 978,\n","         'various': 977,\n","         'realize': 976,\n","         'band': 976,\n","         'plan': 973,\n","         'cry': 971,\n","         'rich': 971,\n","         'win': 968,\n","         'joe': 968,\n","         'project': 963,\n","         'badly': 963,\n","         'free': 962,\n","         'amount': 961,\n","         'fear': 961,\n","         'earlier': 960,\n","         'older': 959,\n","         'appear': 958,\n","         'ask': 955,\n","         'pick': 953,\n","         'front': 952,\n","         'success': 952,\n","         'costume': 950,\n","         'creepy': 949,\n","         'forward': 948,\n","         'portrayed': 948,\n","         'company': 947,\n","         'term': 945,\n","         'leading': 943,\n","         'memory': 942,\n","         'directing': 942,\n","         'dumb': 941,\n","         'admit': 941,\n","         'plenty': 939,\n","         'deserves': 938,\n","         'mess': 937,\n","         'acted': 937,\n","         'award': 936,\n","         'fairly': 936,\n","         'master': 932,\n","         'manages': 930,\n","         'dramatic': 930,\n","         'outside': 927,\n","         'powerful': 927,\n","         'following': 926,\n","         'meant': 926,\n","         'trouble': 925,\n","         'wasted': 924,\n","         'spent': 924,\n","         'plain': 924,\n","         'fantasy': 921,\n","         'apart': 919,\n","         'store': 915,\n","         'expecting': 914,\n","         'chase': 913,\n","         'cat': 913,\n","         'ghost': 912,\n","         'spirit': 912,\n","         'caught': 912,\n","         'rate': 911,\n","         'missing': 906,\n","         'large': 905,\n","         'portrayal': 905,\n","         'brain': 903,\n","         'italian': 902,\n","         'pace': 900,\n","         'create': 899,\n","         'appearance': 897,\n","         'hardly': 896,\n","         'ability': 896,\n","         'political': 894,\n","         'cute': 891,\n","         'throw': 891,\n","         'teen': 888,\n","         'recently': 888,\n","         'fighting': 884,\n","         'fails': 883,\n","         'train': 883,\n","         'era': 882,\n","         'mistake': 881,\n","         'attack': 881,\n","         'shoot': 880,\n","         'agree': 879,\n","         'creature': 879,\n","         'william': 878,\n","         'list': 876,\n","         'telling': 872,\n","         'potential': 872,\n","         'van': 871,\n","         'channel': 871,\n","         'talented': 869,\n","         'stick': 868,\n","         'concept': 867,\n","         'pull': 865,\n","         'soul': 863,\n","         'ended': 863,\n","         'depth': 862,\n","         'public': 861,\n","         'pure': 860,\n","         'married': 859,\n","         'player': 857,\n","         'color': 857,\n","         'clever': 856,\n","         'missed': 852,\n","         'century': 851,\n","         'language': 850,\n","         'odd': 846,\n","         'casting': 845,\n","         'us': 844,\n","         'slightly': 844,\n","         'extra': 843,\n","         'visual': 842,\n","         'waiting': 841,\n","         'incredible': 840,\n","         'blue': 840,\n","         'indian': 837,\n","         'unlike': 836,\n","         'scott': 836,\n","         'former': 834,\n","         'entirely': 834,\n","         'laughing': 834,\n","         'died': 831,\n","         'familiar': 831,\n","         'popular': 831,\n","         'million': 830,\n","         'basic': 830,\n","         'door': 828,\n","         'nudity': 828,\n","         'gang': 827,\n","         'hole': 827,\n","         'created': 825,\n","         'produced': 825,\n","         'follows': 824,\n","         'purpose': 822,\n","         'considering': 822,\n","         'mentioned': 821,\n","         'speak': 821,\n","         'catch': 820,\n","         'answer': 819,\n","         'tension': 818,\n","         'wrote': 818,\n","         'neither': 816,\n","         'flat': 815,\n","         'carry': 815,\n","         'bored': 814,\n","         'convincing': 814,\n","         'respect': 813,\n","         'culture': 813,\n","         'college': 810,\n","         'dancing': 808,\n","         'suddenly': 807,\n","         'common': 805,\n","         'office': 805,\n","         'violent': 803,\n","         'drive': 802,\n","         'appreciate': 801,\n","         'sweet': 801,\n","         'control': 799,\n","         'spend': 798,\n","         'track': 797,\n","         'maker': 797,\n","         'critic': 796,\n","         'lie': 795,\n","         'sadly': 794,\n","         'positive': 793,\n","         'compared': 793,\n","         'decides': 792,\n","         'younger': 792,\n","         'longer': 792,\n","         'biggest': 792,\n","         'belief': 791,\n","         'meaning': 785,\n","         'intelligent': 784,\n","         'hair': 784,\n","         'taste': 783,\n","         'social': 781,\n","         'camp': 780,\n","         'flaw': 779,\n","         'tone': 778,\n","         'bizarre': 777,\n","         'successful': 777,\n","         'pointless': 775,\n","         'filled': 774,\n","         'adaptation': 773,\n","         'park': 770,\n","         'suck': 768,\n","         'road': 768,\n","         'werent': 767,\n","         'sick': 767,\n","         'cold': 766,\n","         'barely': 765,\n","         'decide': 764,\n","         'science': 763,\n","         'building': 762,\n","         'exciting': 762,\n","         'date': 760,\n","         'alive': 759,\n","         'recent': 759,\n","         ...})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["count = Counter(chain(*(train_reviews.str.split())))\n","count"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Nu2ZDb1Ury0b"},"outputs":[],"source":["import operator\n","def make_vocab(all_texts, max_vocab_size,ignore_top=0, oov_token=\"<OOV>\"):\n","  # Count the number of occurrences of each word\n","  count = Counter(chain(*(all_texts.str.split())))\n","\n","  # Create vocab containing max_vocab_size tokens\n","  sorted_values = sorted(count.items(),key = operator.itemgetter(1),reverse = True)[ignore_top:max_vocab_size+ignore_top]\n","  # Add the out of vocabulary at the end\n","  words = [word for word, count in sorted_values]\n","  words.append(oov_token)\n","  \n","  # Map from word to int index in vocab\n","  vocab_to_int = {word: i for i, word in enumerate(words)}\n","\n","  return vocab_to_int"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"7ALBSYzBx6ag"},"outputs":[],"source":["VOCAB_SIZE = 50_000\n","vocab_mapping = make_vocab(train_reviews,VOCAB_SIZE,0)"]},{"cell_type":"markdown","metadata":{"id":"gnQOZt1PyNYW"},"source":["Ahora vamos a implementar una funcion que transforma un string con la review en una lista de enteros con la posiscion de cada una de nuestras palabras en el vocabulario. Si una palabra no está en el vocabulario usamos el indice para`\"<OOV>\"`"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"XfoHxQwExN8W"},"outputs":[],"source":["def get_review_features(text, word_to_idx):\n","  default_value = word_to_idx[\"<OOV>\"]\n","  indices = [word_to_idx.get(word,default_value) for word in text.split()]\n","  return indices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["[50000, 50000, 50000, 1730]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["res = get_review_features(\"this is a test\", vocab_mapping)\n","res"]},{"cell_type":"markdown","metadata":{"id":"2mQZ0dRi0A3t"},"source":["Lo siguiente es implementar padding de las sentencias, si bien los modelos son capaces de trabajar con secuencias de cualquier largo queremos que el tiempo de entrenamiento e inferencia esté controlado y no dependa del largo de los inputs. Como una pequeña optimizacion vamos a hacer **left padding**, es decir, agregar 0s a la izquierda de una secuencia hasta alcanzar `max_sequence_length` elementos.\n","\n","Agregar ceros a la izquierda ayuda a los modelos a aprender de los datos ya que la informacion valiosa aparece al final de la secuencia y no tiene que recordar 3 palabras en luego de haber visto 100 ceros..\n","\n","Ejemplo, la secuencia\n","\n","`[117, 18, 128]`\n","\n"," Quedaría:\n","\n","`[0, 0, 0, 0, 0, 0, 0, 117, 18, 128]`\n","\n","En lugar de \n","\n","`[117, 18, 128, 0, 0, 0, 0, 0, 0, 0] ` Forzando al modelo a recordar los 3 primeros inputs para poder predecir algo.\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"8DY_mllOqOvX"},"outputs":[],"source":["def pad_features(review_ints, sequence_length):\n","  if len(review_ints)> sequence_length:\n","    review_ints = review_ints[-sequence_length:]\n","  else:\n","    while len(review_ints)<sequence_length:\n","      review_ints.insert(0,0)\n","  return review_ints"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"pz43OMIV2ejT"},"outputs":[],"source":["def get_review_representation(review_text, word_to_idx, max_sequence_length):\n","  return pad_features(get_review_features(review_text, word_to_idx), max_sequence_length)"]},{"cell_type":"markdown","metadata":{"id":"lXrRSrbX2AqF"},"source":["# Transformando los textos a vectores"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"JaSoT9Vu2RAX"},"outputs":[],"source":["MAX_SEQUENCE_LENGTH = 100\n","\n","train_vectors = train_reviews.apply(lambda x: get_review_representation(x, vocab_mapping, MAX_SEQUENCE_LENGTH))\n","test_vectors = test_reviews.apply(lambda x: get_review_representation(x, vocab_mapping, MAX_SEQUENCE_LENGTH))\n","\n","train_vectors = np.array([vec for vec in train_vectors])\n","test_vectors = np.array([vec for vec in test_vectors])"]},{"cell_type":"markdown","metadata":{"id":"m6uOvDvL43-L"},"source":["# Codigo de entrenamiento e inferencia \n","\n","Same old..\n"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"Bc8LaIv149Hg"},"outputs":[],"source":["def train_epoch(training_model, loader, criterion, optim):\n","    training_model.train()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    for data, labels in loader:\n","      all_labels.extend(labels.numpy())  \n","\n","      optim.zero_grad()\n","\n","      predictions = training_model(data.to(DEVICE))\n","      all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","      loss = criterion(predictions, labels.to(DEVICE))\n","      \n","      loss.backward()\n","      optim.step()\n","\n","      epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","\n","\n","def validation_epoch(val_model, loader, criterion):\n","    val_model.eval()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    with torch.no_grad():\n","      for data, labels in loader:\n","        all_labels.extend(labels.numpy())  \n","\n","        predictions = val_model(data.to(DEVICE))\n","        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","        loss = criterion(predictions, labels.to(DEVICE))\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","  \n","\n","def train_model(model, train_loader, test_loader, criterion, optim, number_epochs):\n","  train_history = []\n","  test_history = []\n","  accuracy_history = []\n","\n","  for epoch in range(number_epochs):\n","      start_time = time.time()\n","\n","      train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n","      train_history.append(train_loss)\n","      print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, train_loss, train_acc, time.time() - start_time))\n","\n","      start_time = time.time()\n","      test_loss, acc = validation_epoch(model, test_loader, criterion)\n","      test_history.append(test_loss)\n","      accuracy_history.append(acc)\n","      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, test_loss, acc, time.time() - start_time))"]},{"cell_type":"markdown","metadata":{"id":"vkFS0KDj5AKp"},"source":["# Modelo\n"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image.png)"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-1.png)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"VmHNNvSfHLq_"},"outputs":[],"source":["class SentimentRNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(SentimentRNN, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n","        self.perceptron = nn.Linear(in_features = hidden_dim, out_features = 2)\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, _ = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"sahj6WEl5Tii"},"source":["# Entrenamiento"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"iw76sUmhyxAw"},"outputs":[],"source":["BATCH_SIZE = 10\n","train_targets = torch.Tensor(train_sentiments.to_numpy()).long()\n","train_dataset = TensorDataset(torch.LongTensor(train_vectors), train_targets) \n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)\n","\n","test_targets = torch.Tensor(test_sentiments.to_numpy()).long()\n","test_dataset = TensorDataset(torch.LongTensor(test_vectors), test_targets) \n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"JqW4_B46HZTt"},"outputs":[],"source":["loss_function = nn.CrossEntropyLoss().to(DEVICE)\n","BATCH_SIZE = 32"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-2.png)"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"ssVUQ3CL-V6-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.595995 | Accuracy 68.07% | Time 68.71 seconds\n","Validation epoch 1 | Loss 0.536517 | Accuracy 75.17% | Time 6.55 seconds\n","Training epoch 2 | Loss 0.477146 | Accuracy 78.62% | Time 65.78 seconds\n","Validation epoch 2 | Loss 0.489867 | Accuracy 78.88% | Time 6.64 seconds\n","Training epoch 3 | Loss 0.411018 | Accuracy 82.51% | Time 65.78 seconds\n","Validation epoch 3 | Loss 0.501884 | Accuracy 78.17% | Time 6.23 seconds\n","Training epoch 4 | Loss 0.367547 | Accuracy 84.86% | Time 66.64 seconds\n","Validation epoch 4 | Loss 0.515024 | Accuracy 76.02% | Time 6.69 seconds\n","Training epoch 5 | Loss 0.335022 | Accuracy 86.49% | Time 77.51 seconds\n","Validation epoch 5 | Loss 0.522353 | Accuracy 75.43% | Time 14.87 seconds\n","Training epoch 6 | Loss 0.297850 | Accuracy 88.30% | Time 84.71 seconds\n","Validation epoch 6 | Loss 0.505308 | Accuracy 78.08% | Time 10.97 seconds\n","Training epoch 7 | Loss 0.267434 | Accuracy 89.75% | Time 80.66 seconds\n","Validation epoch 7 | Loss 0.506495 | Accuracy 78.32% | Time 9.28 seconds\n","Training epoch 8 | Loss 0.241339 | Accuracy 90.97% | Time 73.95 seconds\n","Validation epoch 8 | Loss 0.520417 | Accuracy 78.32% | Time 18.46 seconds\n","Training epoch 9 | Loss 0.209325 | Accuracy 92.33% | Time 76.65 seconds\n","Validation epoch 9 | Loss 0.556241 | Accuracy 77.35% | Time 6.62 seconds\n","Training epoch 10 | Loss 0.200506 | Accuracy 92.69% | Time 67.95 seconds\n","Validation epoch 10 | Loss 0.595647 | Accuracy 77.17% | Time 8.96 seconds\n"]}],"source":["# Instanciar un modelo\n","# Crear optimizador\n","# Entrenar (Una RNN normal debería poder superar 60% de accuracy)\n","import math \n","embedding_dim = math.ceil(math.sqrt(VOCAB_SIZE))\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = SentimentRNN(vocab_size=VOCAB_SIZE+2, embedding_dim=embedding_dim, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"markdown","metadata":{"id":"h-Dw-KmYDAjF"},"source":["# Mejoras en el modelo\n","\n","\n","\n","1. Podemos mejorar la performance si usamos una GRU o una LSTM ?\n","2. Que pasa si usamos celdas **bidireccionales** ?\n","3. Que pasa si aumentamos el numero de **capas** de nuestras celdas recurrentes \n","?\n","4. Y si usamos vectores preentrenados (W2V, GloVe) ?\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Respuestas\n","1 Sí, es muy probable que la performance mejore al utilizar GRU o LSTM en lugar de una RNN simple. Las RNN tradicionales tienen problemas con las dependencias a largo plazo debido al fenómeno llamado \"vanishing gradient\", lo que dificulta su entrenamiento. Tanto las celdas GRU como LSTM están diseñadas para abordar este problema y, por lo general, funcionan mejor en tareas secuenciales.\n","\n","LSTM: Introduce una celda de memoria y tres puertas (entrada, olvido y salida) que regulan el flujo de información en la celda. Esto permite que las LSTM mantengan la información a lo largo de secuencias más largas y sean menos susceptibles al problema del \"vanishing gradient\".\n","\n","GRU: Es una variante simplificada de LSTM con dos puertas (restablecer y actualizar). Aunque tiene menos parámetros que LSTM, ha demostrado ser efectiva en varias tareas y, en algunos casos, puede superar a las LSTM.\n","\n","2. Las celdas bidireccionales pueden mejorar la performance al procesar la secuencia en ambas direcciones (de principio a fin y de fin a principio). Esto permite que la red tenga información sobre el contexto pasado y futuro de un punto específico en la secuencia, lo cual puede ser útil para comprender mejor el significado. Sin embargo, las celdas bidireccionales también duplican el número de parámetros, lo que puede aumentar el tiempo de entrenamiento y el riesgo de sobreajuste si no se cuenta con suficientes datos.\n","\n","3. Aumentar el número de capas (apilando múltiples RNNs, LSTMs o GRUs) puede permitir que la red capture patrones más complejos en los datos. Sin embargo, también puede aumentar el riesgo de sobreajuste y hacer que el entrenamiento sea más lento. Es importante encontrar un equilibrio y capaz utilizar técnicas de regularización (como dropout) al aumentar el número de capas.\n","\n","4. Usar vectores preentrenados como Word2Vec o GloVe puede mejorar significativamente la performance, especialmente si el conjunto de datos es pequeño. Estos vectores capturan información semántica y relaciones entre palabras basadas en grandes volúmenes de texto. Al utilizar estos embeddings preentrenados, estamos introduciendo un conocimiento previo sobre el lenguaje en nuestro modelo, lo que puede ayudar a obtener mejores resultados más rápidamente y con menos datos."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.475825 | Accuracy 76.81% | Time 68.19 seconds\n","Validation epoch 1 | Loss 0.376184 | Accuracy 83.79% | Time 6.08 seconds\n","Training epoch 2 | Loss 0.266361 | Accuracy 89.45% | Time 65.88 seconds\n","Validation epoch 2 | Loss 0.347870 | Accuracy 85.42% | Time 7.82 seconds\n","Training epoch 3 | Loss 0.152545 | Accuracy 94.57% | Time 71.90 seconds\n","Validation epoch 3 | Loss 0.416668 | Accuracy 84.45% | Time 6.81 seconds\n","Training epoch 4 | Loss 0.090434 | Accuracy 96.88% | Time 66.08 seconds\n","Validation epoch 4 | Loss 0.483416 | Accuracy 85.56% | Time 4.74 seconds\n","Training epoch 5 | Loss 0.060602 | Accuracy 98.02% | Time 60.61 seconds\n","Validation epoch 5 | Loss 0.536048 | Accuracy 85.49% | Time 4.62 seconds\n","Training epoch 6 | Loss 0.033737 | Accuracy 98.95% | Time 67.55 seconds\n","Validation epoch 6 | Loss 0.672954 | Accuracy 85.11% | Time 9.46 seconds\n","Training epoch 7 | Loss 0.028840 | Accuracy 99.07% | Time 66.45 seconds\n","Validation epoch 7 | Loss 0.654796 | Accuracy 84.54% | Time 6.29 seconds\n","Training epoch 8 | Loss 0.024799 | Accuracy 99.21% | Time 68.08 seconds\n","Validation epoch 8 | Loss 0.734571 | Accuracy 84.79% | Time 8.13 seconds\n","Training epoch 9 | Loss 0.019986 | Accuracy 99.38% | Time 67.56 seconds\n","Validation epoch 9 | Loss 0.846157 | Accuracy 84.16% | Time 6.68 seconds\n","Training epoch 10 | Loss 0.019403 | Accuracy 99.42% | Time 66.50 seconds\n","Validation epoch 10 | Loss 0.795136 | Accuracy 84.96% | Time 5.95 seconds\n"]}],"source":["class SentimentGRU(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(SentimentGRU, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","        self.perceptron = nn.Linear(hidden_dim, 2)\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, _ = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out\n","    \n","model = SentimentGRU(vocab_size=VOCAB_SIZE+2, embedding_dim=embedding_dim, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.484305 | Accuracy 76.14% | Time 68.29 seconds\n","Validation epoch 1 | Loss 0.400998 | Accuracy 83.17% | Time 6.44 seconds\n","Training epoch 2 | Loss 0.285268 | Accuracy 88.60% | Time 65.15 seconds\n","Validation epoch 2 | Loss 0.355354 | Accuracy 84.63% | Time 5.19 seconds\n","Training epoch 3 | Loss 0.193484 | Accuracy 92.76% | Time 64.63 seconds\n","Validation epoch 3 | Loss 0.402408 | Accuracy 85.44% | Time 6.36 seconds\n","Training epoch 4 | Loss 0.125357 | Accuracy 95.62% | Time 68.43 seconds\n","Validation epoch 4 | Loss 0.451305 | Accuracy 84.93% | Time 7.20 seconds\n","Training epoch 5 | Loss 0.087493 | Accuracy 97.00% | Time 66.13 seconds\n","Validation epoch 5 | Loss 0.525775 | Accuracy 84.97% | Time 7.55 seconds\n","Training epoch 6 | Loss 0.057502 | Accuracy 98.09% | Time 68.11 seconds\n","Validation epoch 6 | Loss 0.600508 | Accuracy 85.26% | Time 6.13 seconds\n","Training epoch 7 | Loss 0.042363 | Accuracy 98.63% | Time 69.91 seconds\n","Validation epoch 7 | Loss 0.688051 | Accuracy 84.93% | Time 6.22 seconds\n","Training epoch 8 | Loss 0.029997 | Accuracy 99.08% | Time 63.46 seconds\n","Validation epoch 8 | Loss 0.704587 | Accuracy 85.17% | Time 5.31 seconds\n","Training epoch 9 | Loss 0.024168 | Accuracy 99.26% | Time 64.29 seconds\n","Validation epoch 9 | Loss 0.808577 | Accuracy 84.59% | Time 6.68 seconds\n","Training epoch 10 | Loss 0.019730 | Accuracy 99.50% | Time 67.97 seconds\n","Validation epoch 10 | Loss 0.782865 | Accuracy 85.22% | Time 7.70 seconds\n"]}],"source":["class SentimentLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(SentimentLSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.perceptron = nn.Linear(hidden_dim, 2)\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, (h, c) = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out\n","    \n","model = SentimentLSTM(vocab_size=VOCAB_SIZE+2, embedding_dim=embedding_dim, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.498269 | Accuracy 76.08% | Time 64.73 seconds\n","Validation epoch 1 | Loss 0.423175 | Accuracy 82.22% | Time 7.69 seconds\n","Training epoch 2 | Loss 0.308496 | Accuracy 87.75% | Time 67.95 seconds\n","Validation epoch 2 | Loss 0.372486 | Accuracy 84.68% | Time 8.17 seconds\n","Training epoch 3 | Loss 0.204193 | Accuracy 92.40% | Time 67.87 seconds\n","Validation epoch 3 | Loss 0.394148 | Accuracy 85.32% | Time 4.92 seconds\n","Training epoch 4 | Loss 0.142069 | Accuracy 94.96% | Time 66.34 seconds\n","Validation epoch 4 | Loss 0.442744 | Accuracy 84.69% | Time 5.64 seconds\n","Training epoch 5 | Loss 0.092446 | Accuracy 96.81% | Time 66.30 seconds\n","Validation epoch 5 | Loss 0.500590 | Accuracy 85.13% | Time 5.08 seconds\n","Training epoch 6 | Loss 0.067785 | Accuracy 97.73% | Time 66.02 seconds\n","Validation epoch 6 | Loss 0.578212 | Accuracy 85.26% | Time 4.82 seconds\n","Training epoch 7 | Loss 0.045564 | Accuracy 98.57% | Time 66.21 seconds\n","Validation epoch 7 | Loss 0.649421 | Accuracy 85.05% | Time 5.06 seconds\n","Training epoch 8 | Loss 0.033689 | Accuracy 98.98% | Time 63.55 seconds\n","Validation epoch 8 | Loss 0.722649 | Accuracy 84.92% | Time 6.37 seconds\n","Training epoch 9 | Loss 0.026875 | Accuracy 99.16% | Time 65.65 seconds\n","Validation epoch 9 | Loss 0.775535 | Accuracy 84.92% | Time 5.83 seconds\n","Training epoch 10 | Loss 0.021693 | Accuracy 99.33% | Time 64.82 seconds\n","Validation epoch 10 | Loss 0.844741 | Accuracy 85.07% | Time 6.53 seconds\n"]}],"source":["class SentimentBiLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n","        super(SentimentBiLSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n","        self.perceptron = nn.Linear(2*hidden_dim, 2)  # Doble tamaño para bidireccional\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, (h, c) = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out\n","    \n","model = SentimentBiLSTM(vocab_size=VOCAB_SIZE+2, embedding_dim=embedding_dim, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SentimentMultiLayerLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n","        super(SentimentMultiLayerLSTM, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n","        self.perceptron = nn.Linear(hidden_dim, 2)\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, (h, c) = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out\n","model = SentimentMultiLayerLSTM(vocab_size=VOCAB_SIZE+2, embedding_dim=embedding_dim, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["import requests\n","import zipfile\n","import os\n","\n","# URL de Word2Vec\n","url = \"http://vectors.nlpl.eu/repository/20/40.zip\"\n","\n","response = requests.get(url, stream=True)\n","filename = \"word2vec.zip\"\n","with open(filename, 'wb') as f:\n","    for chunk in response.iter_content(chunk_size=8192):\n","        f.write(chunk)\n","\n","with zipfile.ZipFile(filename, 'r') as zip_ref:\n","    zip_ref.extractall(\"word2vec_folder\")\n","\n","word2vec_path = os.path.join(\"word2vec_folder\", \"model.bin\")\n","\n","print(f\"Word2Vec file is located at: {word2vec_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#%pip install gensim\n","from gensim.models import KeyedVectors\n","\n","word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n","\n","embedding_matrix = torch.zeros((len(vocab_mapping), word2vec_model.vector_size))\n","for i, word in enumerate(vocab_mapping):\n","    if word in word2vec_model:\n","        embedding_matrix[i] = torch.tensor(word2vec_model[word])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SentimentPretrainedEmbeddings(nn.Module):\n","    def __init__(self, pretrained_embeddings, hidden_dim):\n","        super(SentimentPretrainedEmbeddings, self).__init__()\n","        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n","        self.rnn = nn.LSTM(pretrained_embeddings.shape[1], hidden_dim, batch_first=True)\n","        self.perceptron = nn.Linear(hidden_dim, 2)\n","\n","    def forward(self, x):\n","        out = self.embedding(x)\n","        out, (h, c) = self.rnn(out)\n","        out = self.perceptron(out[:, -1, :])\n","        return out\n","\n","model = SentimentPretrainedEmbeddings(pretrained_embeddings=embedding_matrix, hidden_dim=32).to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","train_model(model,train_dataloader,test_dataloader,loss_function,optimizer,number_epochs = 10)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NLP_02_RNNs_Letra.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
