{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwmbSlbbFuM5"
      },
      "source": [
        "# Traduccion usando modelos Seq2Seq\n",
        "\n",
        "Este notebook está fuertemente basado en el tutorial de PyTorch [*NLP From Scratch: Translation with a Sequence to Sequence Network and Attention*](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) creado por Sean Robertson.\n",
        "\n",
        "Vamos a estar viendo como traducir frases en francés al inglés.\n",
        "\n",
        "    IN: il est en train de peindre un tableau .\n",
        "    TRG: he is painting a picture .\n",
        "    OUT: he is painting a picture .\n",
        "\n",
        "    IN: pourquoi ne pas essayer ce vin delicieux ?\n",
        "    TRG: why not try that delicious wine ?\n",
        "    OUT: why not try that delicious wine ?\n",
        "\n",
        "    IN: elle n est pas poete mais romanciere .\n",
        "    TRG: she is not a poet but a novelist .\n",
        "    OUT: she not not a poet but a novelist .\n",
        "\n",
        "    IN: vous etes trop maigre .\n",
        "    TRG: you re too skinny .\n",
        "    OUT: you re all alone .\n",
        "\n",
        "... con distintos niveles de éxito.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypwInf2vMvW4"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v2KFieVrFuM6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1gKbmYbFuNG"
      },
      "source": [
        "Preparando los Datos\n",
        "==================\n",
        "\n",
        "Los datos para este problema son miles de parejas de sentencias en inglés y francés.\n",
        "\n",
        "    I am cold.    J'ai froid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "74vkAp2HOJ5G"
      },
      "outputs": [],
      "source": [
        "# !wget https://download.pytorch.org/tutorial/data.zip\n",
        "# !unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Maf203LiOjQz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Au feu !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135837</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135838</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135839</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135840</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135841</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135842 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  English  \\\n",
              "0                                                     Go.   \n",
              "1                                                    Run!   \n",
              "2                                                    Run!   \n",
              "3                                                    Wow!   \n",
              "4                                                   Fire!   \n",
              "...                                                   ...   \n",
              "135837  A carbon footprint is the amount of carbon dio...   \n",
              "135838  Death is something that we're often discourage...   \n",
              "135839  Since there are usually multiple websites on a...   \n",
              "135840  If someone who doesn't know your background sa...   \n",
              "135841  It may be impossible to get a completely error...   \n",
              "\n",
              "                                                   French  \n",
              "0                                                    Va !  \n",
              "1                                                 Cours !  \n",
              "2                                                Courez !  \n",
              "3                                              Ça alors !  \n",
              "4                                                Au feu !  \n",
              "...                                                   ...  \n",
              "135837  Une empreinte carbone est la somme de pollutio...  \n",
              "135838  La mort est une chose qu'on nous décourage sou...  \n",
              "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
              "135841  Il est peut-être impossible d'obtenir un Corpu...  \n",
              "\n",
              "[135842 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a peek at the dataset\n",
        "dataset = pd.read_csv(\"data/eng-fra.txt\", sep=\"\\t\", header=None)\n",
        "dataset.columns = [\"English\", \"French\"]\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKz4kryVFuNH"
      },
      "source": [
        "We will represent each word in a language as a one-hot vector (i.e., a giant vector of zeros except for a single one at the index of the word). We will however cheat a bit and trim the data to only use a few thousand words per language.\n",
        "\n",
        "Vamos a representar cada palabra como un one-hot encoded vector (un índice por palabra). Para esto vamos a crear un vocabulario y limitar el número máximo de palabras para solamente usar unas cuántas miles de palabras por lenguaje. \n",
        "\n",
        "\n",
        "![Word encoding](https://drive.google.com/uc?id=1aLm__m9YWaKRZdDmdInE5rT-et0jXTci \"Word encoding\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdE1cMrYFuNJ"
      },
      "source": [
        "Vamos a necesitar un índice por palabra, para esto (y como hemos hecho antes) vamos a crear un vocabulario. En particular en este caso vamos a  hacer uso de una clase auxiliar `Lang` que tiene:\n",
        "  - word → index (``word2index``) \n",
        "  - index → word (``index2word``)\n",
        "  - ``word2count`` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WKLy6SSnFuNL"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "      for word in sentence.split(\" \"):\n",
        "        self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "      if word not in self.word2index:\n",
        "        self.word2index[word] = self.n_words\n",
        "        self.word2count[word] = 1\n",
        "        self.index2word[self.n_words] = word\n",
        "        self.n_words += 1\n",
        "      else:\n",
        "        self.word2count[word] += 1\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJxMTG6xFuNR"
      },
      "source": [
        "Los archivos estan en Unicode, para simplificar los transformamos a ASCII, pasamos todo a minúscula y quitamos la mayor parte de la puntuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HtfSmhwGFuNS"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicode2ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode2ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fLdxTL5FuNZ"
      },
      "source": [
        "Para leer los datos necesitamos leer cada línea a la vez, y luego separar cada línea en las dos sentencias que la componen. Todos los archivos que descargamos están en Inglés → Otro Idioma, por lo que si queremos traducir desde Otro Idioma → Inglés tenemos que usar la flag `reverse` para invertir los pares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "22jUHxw2FuNa"
      },
      "outputs": [],
      "source": [
        "def read_langs(lang1, lang2, reverse=False):\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-PS-XSMFuNh"
      },
      "source": [
        "Como tenemos muchos ejemplos y queremos entrenar algo rápidamente, vamos a recortar los datos a un máximo de 10 palabras y nos quedamos con sentencias que se traducen a la forma \"I am\", \"He is\", etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xpNtFi7mFuNh"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filter_pair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filter_pairs(pairs):\n",
        "    return [pair for pair in pairs if filter_pair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rymw2EPmFuNm"
      },
      "source": [
        "El proceso completo para preparar los datos es:\n",
        "\n",
        "- Leer el archivo, separarlo en líneas y separar cada línea en parejas\n",
        "- Normalizar y filtrar los textos\n",
        "- Crear los vocabularios a partir de los pares\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nkFbqs75FuNn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['je suis heureuse de vous avoir invitee .', 'i m glad i invited you .']\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = read_langs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    pairs = filter_pairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    for pair in pairs:\n",
        "      input_lang.add_sentence(pair[0])\n",
        "      output_lang.add_sentence(pair[1])\n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    \n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Au3B9qFuNs"
      },
      "source": [
        "Modelo\n",
        "=================\n",
        "\n",
        "![Seq2Seq Architecture](https://drive.google.com/uc?id=14XIFBXqpos7Z_spBMtK5gyWbl5MJyMud \"Seq2Seq Architecture\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0UeYlSqFuNs"
      },
      "source": [
        "Encoder\n",
        "-----------\n",
        "\n",
        "![Encoder Network](https://drive.google.com/uc?id=17D4YBVh630jJBo6TVquS2a1R6XmPs3qK \"Encoder Network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PT6ON9nzFuNt"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,embedding_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
        "\n",
        "    def forward(self, input_data, hidden):\n",
        "      # los embeddings son una palabra a la vez, va a ser necesario hacer un .view(1, 1, -1)\n",
        "      embedded = self.embedding(input_data).view(1, 1, -1)\n",
        "      output, hidden = self.gru(embedded, hidden)\n",
        "      return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nti9yrscFuNz"
      },
      "source": [
        "## Decoder Simple\n",
        "\n",
        "![Decoder Network](https://drive.google.com/uc?id=13kddnNWcPFku6SUS4ZbTMnDZLmyB2baD \"Decoder Network\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "CHb4ek-pFuN0"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, embedding_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmT58gbVU6JN"
      },
      "source": [
        "# Funciones Auxiliares\n",
        "\n",
        "### Preparando los datos\n",
        "\n",
        "Vamos a transformar cada pareja de sentencias a una tupla de tensores con índices. Al crearlos, vamos a agregar el token de EOS en ambos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "BVGLn2CEFuOB"
      },
      "outputs": [],
      "source": [
        "def indexes_from_sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
        "\n",
        "\n",
        "def tensor_from_sentence(lang, sentence):\n",
        "    indexes = indexes_from_sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensors_from_pair(pair):\n",
        "    input_tensor = tensor_from_sentence(input_lang, pair[0])\n",
        "    target_tensor = tensor_from_sentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc670q3tFuOE"
      },
      "source": [
        "### Entrenando el modelo\n",
        "------------------\n",
        "\n",
        "Para entrenar el modelo, pasamos la sentencia de entrada (palabra a palabra) a través del encoder y nos quedamos con sus outputs y último hidden state. El decoder luego recibe el token de `<SOS>` como primer input y el hidden state del encoder como su hidden state inicial. \n",
        "\n",
        "\"Teacher Forcing\" es el concepto de usar el target real como inputs nuevos para cada paso, en lugar de usar las predicciones del decoder. Esto ayuda a la convergencia pero puede traer inestabilidad si la red es explotada: [inestabilidad](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "Gracias a la libertad que nos da autograd de PyTorch podemos elegir usar teacher forcing solamente un porcentaje de las veces con un simple if, y nuestros optimizadores funcionan sin alterarse. En particular vamos a usar `teacher_forcing_ratio` de 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "FrDllDWwFuOF"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Reset optimizers\n",
        "    encoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Feed inputs to the encoder one by one ~3 Lines\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "\n",
        "    # Initialize decoder input and hidden state ~2 Lines\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    use_teacher_forcing =  random.random() < teacher_forcing_ratio  # Randomly choose whether to use teacher forcing. \n",
        "    #Teacher forcing is useful when the target output is known beforehand, but it may lead to suboptimal performance during inference time (when we don't know the target output beforehand). \n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        # Feed the decoder inputs one by one, add the loss at each timestep and move forward using the next target as input\n",
        "        # ~3 Lines\n",
        "        for j in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output.squeeze(1), target_tensor[j])\n",
        "            decoder_input = target_tensor[j]\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        # Feed the decoder inputs one by one, find the predicted next token and set it as next input (use .detach() on this tensor)\n",
        "        # Compute the loss at each timestep\n",
        "        # If the decoder generates an EOS, stop.\n",
        "        # ~8 Lines\n",
        "        for j in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output.squeeze(1), target_tensor[j])\n",
        "            \n",
        "            decoder_input = torch.argmax(decoder_output).detach()\n",
        "            if decoder_input == EOS_token:\n",
        "                break\n",
        "    # Backprop! ~3 Lines\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r29fiUAkFuOK"
      },
      "source": [
        "Funciones auxiliares para contabilizar el tiempo y estimar el tiempo restante.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Th1RxXtXFuOL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def as_minutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def time_since(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeaDGFCwFuOP"
      },
      "source": [
        "Todo el proceso de entrenamiento consiste en:\n",
        "\n",
        "-  Comenzar un timer\n",
        "-  Inicializar los optimizadores y el costo. Vamos a usar NLLLoss como costo.\n",
        "-  Crear un set de parejas de entrenamiento\n",
        "-  Inicializar array vacío para los costos\n",
        "\n",
        "Luego llamamos a ``train`` muchas veces y ocasionalmente imprimimos el progreso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "kAF-qTysFuOP"
      },
      "outputs": [],
      "source": [
        "def train_iters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [\n",
        "        tensors_from_pair(random.choice(pairs))\n",
        "        for i in range(n_iters)\n",
        "    ]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(\n",
        "            input_tensor, target_tensor, encoder, decoder,\n",
        "            encoder_optimizer, decoder_optimizer, criterion\n",
        "        )\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (\n",
        "                time_since(start, iter / n_iters),\n",
        "                iter,\n",
        "                iter / n_iters * 100,\n",
        "                print_loss_avg\n",
        "            ))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    show_plot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qT5cU5GFuOS"
      },
      "source": [
        "Mostrando los resultados\n",
        "----------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "yps1cwT1FuOU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def show_plot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLmCrf3YFuOY"
      },
      "source": [
        "Evaluación\n",
        "==========\n",
        "\n",
        "La evaluacion se hace de igual manera que el entrenamiento, pero, al no tener objetivos, usamos las mismas predicciones del decoder como inputs. Hacemos esto hasta que el decorer genere un token de EOS. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "JvMJB8hLFuOZ"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sequence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        # Code to run an evaluation step, without targets for the decoder\n",
        "        # ~21 Lines\n",
        "            # Reset optimizers\n",
        "        input_tensor = tensor_from_sentence(input_lang, sequence)\n",
        "        input_length = input_tensor.size(0)\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "\n",
        "        # Feed inputs to the encoder one by one ~3 Lines\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "\n",
        "        # Initialize decoder input and hidden state ~2 Lines\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        length = 0 \n",
        "        output_indexes = []\n",
        "        \n",
        "        while decoder_input != EOS_token and length < max_length:\n",
        "\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)            \n",
        "            decoder_input = torch.argmax(decoder_output)\n",
        "            length += 1\n",
        "            output_indexes.append(decoder_input)\n",
        "            if decoder_input == EOS_token:\n",
        "                break\n",
        "        \n",
        "        decoded_words = [output_lang.index2word[index] for index in output_indexes]\n",
        "        \n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "pqtl4e09FuOf"
      },
      "outputs": [],
      "source": [
        "def evaluate_randomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('IN:', pair[0])\n",
        "        print('TRG:', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('OUT:', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRJd5QJuFuOi"
      },
      "source": [
        "Entrenando y Evaluando\n",
        "=======================\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "SuMbwnYiFuOi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0m 27s (- 168m 23s) (200 0%) 5.5046\n",
            "0m 32s (- 100m 51s) (400 0%) 20.1626\n",
            "0m 37s (- 78m 5s) (600 0%) 86.2402\n",
            "0m 43s (- 66m 38s) (800 1%) 223.1924\n",
            "0m 48s (- 59m 43s) (1000 1%) 435.3788\n",
            "0m 53s (- 55m 2s) (1200 1%) 691.8427\n",
            "1m 0s (- 53m 2s) (1400 1%) 965.3614\n",
            "1m 13s (- 56m 0s) (1600 2%) 1195.3542\n",
            "1m 24s (- 57m 3s) (1800 2%) 1694.8058\n",
            "1m 32s (- 56m 18s) (2000 2%) 2176.8437\n",
            "1m 42s (- 56m 19s) (2200 2%) 2386.3550\n",
            "1m 47s (- 53m 59s) (2400 3%) 2750.4694\n",
            "1m 52s (- 52m 5s) (2600 3%) 2847.6209\n",
            "1m 56s (- 49m 56s) (2800 3%) 3472.7681\n",
            "2m 0s (- 48m 14s) (3000 4%) 4270.5136\n",
            "2m 4s (- 46m 39s) (3200 4%) 4128.7411\n",
            "2m 8s (- 45m 15s) (3400 4%) 4276.1327\n",
            "2m 14s (- 44m 21s) (3600 4%) 4445.7848\n",
            "2m 18s (- 43m 15s) (3800 5%) 4514.9044\n",
            "2m 22s (- 42m 9s) (4000 5%) 4809.1805\n",
            "2m 26s (- 41m 7s) (4200 5%) 5490.5834\n",
            "2m 30s (- 40m 11s) (4400 5%) 5304.3302\n",
            "2m 34s (- 39m 20s) (4600 6%) 5564.7890\n",
            "2m 38s (- 38m 35s) (4800 6%) 6368.1662\n",
            "2m 43s (- 38m 2s) (5000 6%) 7375.3547\n",
            "2m 48s (- 37m 35s) (5200 6%) 6795.0613\n",
            "2m 52s (- 37m 4s) (5400 7%) 8272.0728\n",
            "2m 56s (- 36m 30s) (5600 7%) 7897.9060\n",
            "3m 1s (- 36m 7s) (5800 7%) 8725.2929\n",
            "3m 6s (- 35m 46s) (6000 8%) 9548.1800\n",
            "3m 11s (- 35m 22s) (6200 8%) 9554.8034\n",
            "3m 16s (- 35m 3s) (6400 8%) 9330.5367\n",
            "3m 21s (- 34m 44s) (6600 8%) 10084.3192\n",
            "3m 26s (- 34m 31s) (6800 9%) 10704.1429\n",
            "3m 31s (- 34m 13s) (7000 9%) 12087.5512\n",
            "3m 36s (- 33m 55s) (7200 9%) 11500.4987\n",
            "3m 40s (- 33m 34s) (7400 9%) 12674.2698\n",
            "3m 46s (- 33m 32s) (7600 10%) 11355.5605\n",
            "3m 51s (- 33m 17s) (7800 10%) 12287.0368\n",
            "3m 56s (- 33m 3s) (8000 10%) 14376.8343\n",
            "4m 2s (- 32m 53s) (8200 10%) 15401.0303\n",
            "4m 7s (- 32m 39s) (8400 11%) 14879.9798\n",
            "4m 12s (- 32m 28s) (8600 11%) 16971.0135\n",
            "4m 16s (- 32m 12s) (8800 11%) 16445.2512\n",
            "4m 21s (- 31m 59s) (9000 12%) 15568.0936\n",
            "4m 26s (- 31m 44s) (9200 12%) 16350.8575\n",
            "4m 30s (- 31m 27s) (9400 12%) 18550.3095\n",
            "4m 34s (- 31m 9s) (9600 12%) 17407.0529\n",
            "4m 38s (- 30m 54s) (9800 13%) 18803.9143\n",
            "4m 43s (- 30m 42s) (10000 13%) 18758.8900\n",
            "4m 47s (- 30m 27s) (10200 13%) 17293.7069\n",
            "4m 51s (- 30m 13s) (10400 13%) 19450.5065\n",
            "4m 56s (- 30m 4s) (10600 14%) 27395.0560\n",
            "5m 2s (- 29m 56s) (10800 14%) 21483.7356\n",
            "5m 6s (- 29m 45s) (11000 14%) 23159.9852\n",
            "5m 10s (- 29m 30s) (11200 14%) 26187.2602\n",
            "5m 15s (- 29m 18s) (11400 15%) 27103.9079\n",
            "5m 19s (- 29m 8s) (11600 15%) 25812.0066\n",
            "5m 25s (- 29m 4s) (11800 15%) 27116.1276\n",
            "5m 31s (- 29m 0s) (12000 16%) 30187.6920\n",
            "5m 37s (- 28m 57s) (12200 16%) 26606.7970\n",
            "5m 43s (- 28m 53s) (12400 16%) 28626.4620\n",
            "5m 48s (- 28m 44s) (12600 16%) 29406.9078\n",
            "5m 52s (- 28m 35s) (12800 17%) 32464.3033\n",
            "5m 57s (- 28m 25s) (13000 17%) 33458.4430\n",
            "6m 1s (- 28m 14s) (13200 17%) 32464.5734\n",
            "6m 6s (- 28m 4s) (13400 17%) 36818.3378\n",
            "6m 11s (- 27m 58s) (13600 18%) 35048.4871\n",
            "6m 18s (- 27m 57s) (13800 18%) 35433.2395\n",
            "6m 23s (- 27m 52s) (14000 18%) 35575.0758\n",
            "6m 28s (- 27m 42s) (14200 18%) 35640.7951\n",
            "6m 33s (- 27m 36s) (14400 19%) 38451.2301\n",
            "6m 38s (- 27m 26s) (14600 19%) 41435.9372\n",
            "6m 42s (- 27m 17s) (14800 19%) 34193.9148\n",
            "6m 47s (- 27m 8s) (15000 20%) 43136.5295\n",
            "6m 51s (- 26m 57s) (15200 20%) 45923.6745\n",
            "6m 56s (- 26m 51s) (15400 20%) 48347.6015\n",
            "7m 1s (- 26m 43s) (15600 20%) 49288.1273\n",
            "7m 5s (- 26m 34s) (15800 21%) 44461.5339\n",
            "7m 10s (- 26m 28s) (16000 21%) 43824.0348\n",
            "7m 15s (- 26m 22s) (16200 21%) 51250.5445\n",
            "7m 21s (- 26m 17s) (16400 21%) 44986.5894\n",
            "7m 26s (- 26m 10s) (16600 22%) 48932.6524\n",
            "7m 31s (- 26m 4s) (16800 22%) 45548.6362\n",
            "7m 36s (- 25m 56s) (17000 22%) 43348.7258\n",
            "7m 40s (- 25m 48s) (17200 22%) 44909.4745\n",
            "7m 44s (- 25m 39s) (17400 23%) 47524.8267\n",
            "7m 49s (- 25m 30s) (17600 23%) 45472.2743\n",
            "7m 54s (- 25m 24s) (17800 23%) 41291.9006\n",
            "7m 59s (- 25m 19s) (18000 24%) 46705.9928\n",
            "8m 5s (- 25m 15s) (18200 24%) 48245.6128\n",
            "8m 11s (- 25m 10s) (18400 24%) 53731.1131\n",
            "8m 16s (- 25m 4s) (18600 24%) 48501.9393\n",
            "8m 21s (- 24m 58s) (18800 25%) 49504.8549\n",
            "8m 25s (- 24m 49s) (19000 25%) 53222.2486\n",
            "8m 30s (- 24m 43s) (19200 25%) 51339.7842\n",
            "8m 35s (- 24m 37s) (19400 25%) 55608.9897\n",
            "8m 40s (- 24m 30s) (19600 26%) 58908.1727\n",
            "8m 44s (- 24m 23s) (19800 26%) 49495.9534\n",
            "8m 49s (- 24m 17s) (20000 26%) 55414.5026\n",
            "8m 55s (- 24m 13s) (20200 26%) 67896.9855\n",
            "9m 1s (- 24m 9s) (20400 27%) 71089.2380\n",
            "9m 6s (- 24m 2s) (20600 27%) 51060.9980\n",
            "9m 11s (- 23m 58s) (20800 27%) 56808.4920\n",
            "9m 17s (- 23m 53s) (21000 28%) 64188.3729\n",
            "9m 22s (- 23m 47s) (21200 28%) 73262.3591\n",
            "9m 27s (- 23m 41s) (21400 28%) 68978.1357\n",
            "9m 31s (- 23m 34s) (21600 28%) 59627.0026\n",
            "9m 37s (- 23m 28s) (21800 29%) 68115.5744\n",
            "9m 41s (- 23m 20s) (22000 29%) 76609.5137\n",
            "9m 46s (- 23m 14s) (22200 29%) 79932.9769\n",
            "9m 51s (- 23m 8s) (22400 29%) 81126.4693\n",
            "9m 56s (- 23m 2s) (22600 30%) 79288.0254\n",
            "10m 1s (- 22m 56s) (22800 30%) 76376.4931\n",
            "10m 5s (- 22m 48s) (23000 30%) 83047.2391\n",
            "10m 10s (- 22m 42s) (23200 30%) 97758.3168\n",
            "10m 15s (- 22m 37s) (23400 31%) 105660.9278\n",
            "10m 20s (- 22m 31s) (23600 31%) 97591.7368\n",
            "10m 25s (- 22m 25s) (23800 31%) 93886.2785\n",
            "10m 31s (- 22m 21s) (24000 32%) 96820.3554\n",
            "10m 36s (- 22m 16s) (24200 32%) 89615.4143\n",
            "10m 41s (- 22m 9s) (24400 32%) 97494.7833\n",
            "10m 47s (- 22m 6s) (24600 32%) 103451.6107\n",
            "10m 52s (- 22m 0s) (24800 33%) 107160.7354\n",
            "10m 57s (- 21m 54s) (25000 33%) 100614.9188\n",
            "11m 1s (- 21m 48s) (25200 33%) 85569.6759\n",
            "11m 7s (- 21m 42s) (25400 33%) 81221.1065\n",
            "11m 12s (- 21m 36s) (25600 34%) 106619.1974\n",
            "11m 17s (- 21m 32s) (25800 34%) 101663.1561\n",
            "11m 22s (- 21m 26s) (26000 34%) 84079.7807\n",
            "11m 28s (- 21m 22s) (26200 34%) 97249.4906\n",
            "11m 35s (- 21m 19s) (26400 35%) 100018.5743\n",
            "11m 40s (- 21m 14s) (26600 35%) 102347.3113\n",
            "11m 45s (- 21m 9s) (26800 35%) 102577.7702\n",
            "11m 51s (- 21m 4s) (27000 36%) 92212.3280\n",
            "11m 58s (- 21m 2s) (27200 36%) 102747.7924\n",
            "12m 3s (- 20m 56s) (27400 36%) 112259.5135\n",
            "12m 8s (- 20m 51s) (27600 36%) 118440.9076\n",
            "12m 15s (- 20m 49s) (27800 37%) 123130.0162\n",
            "12m 22s (- 20m 46s) (28000 37%) 125712.2174\n",
            "12m 28s (- 20m 42s) (28200 37%) 115245.3709\n",
            "12m 32s (- 20m 35s) (28400 37%) 98812.9368\n",
            "12m 37s (- 20m 28s) (28600 38%) 110715.5916\n",
            "12m 42s (- 20m 23s) (28800 38%) 114017.5785\n",
            "12m 48s (- 20m 18s) (29000 38%) 115123.8347\n",
            "12m 53s (- 20m 13s) (29200 38%) 119562.9118\n",
            "12m 59s (- 20m 8s) (29400 39%) 135660.7308\n",
            "13m 4s (- 20m 3s) (29600 39%) 137414.9174\n",
            "13m 9s (- 19m 57s) (29800 39%) 119455.2041\n",
            "13m 14s (- 19m 51s) (30000 40%) 105895.2278\n",
            "13m 20s (- 19m 46s) (30200 40%) 104038.3727\n",
            "13m 25s (- 19m 41s) (30400 40%) 108948.8171\n",
            "13m 31s (- 19m 38s) (30600 40%) 92078.1815\n",
            "13m 41s (- 19m 39s) (30800 41%) 87285.7482\n",
            "13m 50s (- 19m 38s) (31000 41%) 115971.7891\n",
            "13m 55s (- 19m 33s) (31200 41%) 132181.3464\n",
            "14m 0s (- 19m 26s) (31400 41%) 138601.3223\n",
            "14m 5s (- 19m 20s) (31600 42%) 121936.2231\n",
            "14m 10s (- 19m 15s) (31800 42%) 121838.3263\n",
            "14m 15s (- 19m 9s) (32000 42%) 128975.4715\n",
            "14m 19s (- 19m 3s) (32200 42%) 113777.9948\n",
            "14m 24s (- 18m 56s) (32400 43%) 128178.3347\n",
            "14m 28s (- 18m 49s) (32600 43%) 135484.3582\n",
            "14m 33s (- 18m 43s) (32800 43%) 130015.1242\n",
            "14m 37s (- 18m 36s) (33000 44%) 121560.5390\n",
            "14m 42s (- 18m 30s) (33200 44%) 108058.7229\n",
            "14m 47s (- 18m 25s) (33400 44%) 151631.1252\n",
            "14m 53s (- 18m 21s) (33600 44%) 151415.5589\n",
            "14m 58s (- 18m 15s) (33800 45%) 161777.3455\n",
            "15m 3s (- 18m 9s) (34000 45%) 132240.5019\n",
            "15m 8s (- 18m 3s) (34200 45%) 111264.1194\n",
            "15m 13s (- 17m 58s) (34400 45%) 148483.3345\n",
            "15m 17s (- 17m 51s) (34600 46%) 161805.2585\n",
            "15m 22s (- 17m 45s) (34800 46%) 166833.7815\n",
            "15m 27s (- 17m 40s) (35000 46%) 159596.0902\n",
            "15m 32s (- 17m 34s) (35200 46%) 153923.8726\n",
            "15m 36s (- 17m 27s) (35400 47%) 165509.3911\n",
            "15m 40s (- 17m 21s) (35600 47%) 174228.4715\n",
            "15m 44s (- 17m 14s) (35800 47%) 158745.2299\n",
            "15m 48s (- 17m 8s) (36000 48%) 181884.0224\n",
            "15m 53s (- 17m 2s) (36200 48%) 175866.4667\n",
            "15m 58s (- 16m 56s) (36400 48%) 182463.6152\n",
            "16m 3s (- 16m 50s) (36600 48%) 176818.6021\n",
            "16m 7s (- 16m 44s) (36800 49%) 182136.0222\n",
            "16m 13s (- 16m 39s) (37000 49%) 186126.3775\n",
            "16m 18s (- 16m 33s) (37200 49%) 199256.4718\n",
            "16m 22s (- 16m 27s) (37400 49%) 202241.1681\n",
            "16m 26s (- 16m 21s) (37600 50%) 188923.2919\n",
            "16m 31s (- 16m 15s) (37800 50%) 153006.5644\n",
            "16m 34s (- 16m 8s) (38000 50%) 178144.4446\n",
            "16m 38s (- 16m 2s) (38200 50%) 213393.3136\n",
            "16m 43s (- 15m 56s) (38400 51%) 211361.4655\n",
            "16m 47s (- 15m 50s) (38600 51%) 179004.9909\n",
            "16m 51s (- 15m 43s) (38800 51%) 165703.4945\n",
            "16m 55s (- 15m 37s) (39000 52%) 179621.1481\n",
            "16m 59s (- 15m 31s) (39200 52%) 194477.2779\n",
            "17m 3s (- 15m 24s) (39400 52%) 165557.7851\n",
            "17m 7s (- 15m 18s) (39600 52%) 173013.5458\n",
            "17m 11s (- 15m 12s) (39800 53%) 198188.1285\n",
            "17m 15s (- 15m 6s) (40000 53%) 193806.9714\n",
            "17m 19s (- 15m 0s) (40200 53%) 201281.5863\n",
            "17m 24s (- 14m 54s) (40400 53%) 254626.8296\n",
            "17m 28s (- 14m 48s) (40600 54%) 242191.9185\n",
            "17m 32s (- 14m 42s) (40800 54%) 273483.2367\n",
            "17m 36s (- 14m 36s) (41000 54%) 225394.5537\n",
            "17m 40s (- 14m 29s) (41200 54%) 191166.6678\n",
            "17m 44s (- 14m 23s) (41400 55%) 203414.3492\n",
            "17m 48s (- 14m 17s) (41600 55%) 217820.4375\n",
            "17m 52s (- 14m 11s) (41800 55%) 216343.9817\n",
            "17m 56s (- 14m 5s) (42000 56%) 248308.0148\n",
            "18m 0s (- 13m 59s) (42200 56%) 254950.0321\n",
            "18m 5s (- 13m 54s) (42400 56%) 262912.3456\n",
            "18m 9s (- 13m 48s) (42600 56%) 250219.7867\n",
            "18m 13s (- 13m 42s) (42800 57%) 216499.9640\n",
            "18m 16s (- 13m 36s) (43000 57%) 178081.7215\n",
            "18m 20s (- 13m 30s) (43200 57%) 250084.4235\n",
            "18m 24s (- 13m 24s) (43400 57%) 243266.7082\n",
            "18m 29s (- 13m 18s) (43600 58%) 272903.0133\n",
            "18m 33s (- 13m 13s) (43800 58%) 283039.7191\n",
            "18m 37s (- 13m 7s) (44000 58%) 270168.2455\n",
            "18m 41s (- 13m 1s) (44200 58%) 240824.8454\n",
            "18m 45s (- 12m 55s) (44400 59%) 285925.0412\n",
            "18m 49s (- 12m 49s) (44600 59%) 267814.0824\n",
            "18m 53s (- 12m 44s) (44800 59%) 293433.4974\n",
            "18m 58s (- 12m 38s) (45000 60%) 283689.6289\n",
            "19m 2s (- 12m 33s) (45200 60%) 263462.2235\n",
            "19m 7s (- 12m 27s) (45400 60%) 296909.7776\n",
            "19m 11s (- 12m 22s) (45600 60%) 291969.6832\n",
            "19m 17s (- 12m 17s) (45800 61%) 269500.1994\n",
            "19m 22s (- 12m 12s) (46000 61%) 307573.8150\n",
            "19m 26s (- 12m 7s) (46200 61%) 313167.3179\n",
            "19m 31s (- 12m 1s) (46400 61%) 280006.2627\n",
            "19m 35s (- 11m 56s) (46600 62%) 287526.7917\n",
            "19m 39s (- 11m 50s) (46800 62%) 289959.0273\n",
            "19m 43s (- 11m 45s) (47000 62%) 310176.5879\n",
            "19m 47s (- 11m 39s) (47200 62%) 284727.5995\n",
            "19m 51s (- 11m 33s) (47400 63%) 294770.2482\n",
            "19m 55s (- 11m 28s) (47600 63%) 272057.3155\n",
            "20m 0s (- 11m 22s) (47800 63%) 292820.3232\n",
            "20m 4s (- 11m 17s) (48000 64%) 305533.4741\n",
            "20m 8s (- 11m 11s) (48200 64%) 302663.3225\n",
            "20m 12s (- 11m 6s) (48400 64%) 287453.6404\n",
            "20m 16s (- 11m 0s) (48600 64%) 240242.5518\n",
            "20m 19s (- 10m 54s) (48800 65%) 248390.7007\n",
            "20m 23s (- 10m 49s) (49000 65%) 295741.7782\n",
            "20m 27s (- 10m 43s) (49200 65%) 272366.1805\n",
            "20m 31s (- 10m 38s) (49400 65%) 309427.2822\n",
            "20m 35s (- 10m 32s) (49600 66%) 309422.5929\n",
            "20m 40s (- 10m 27s) (49800 66%) 315785.7292\n",
            "20m 44s (- 10m 22s) (50000 66%) 285030.9417\n",
            "20m 48s (- 10m 16s) (50200 66%) 243083.3955\n",
            "20m 52s (- 10m 11s) (50400 67%) 263842.9183\n",
            "20m 55s (- 10m 5s) (50600 67%) 252409.8899\n",
            "20m 59s (- 10m 0s) (50800 67%) 278499.3877\n",
            "21m 3s (- 9m 54s) (51000 68%) 313623.4388\n",
            "21m 7s (- 9m 49s) (51200 68%) 343069.0657\n",
            "21m 12s (- 9m 44s) (51400 68%) 329011.5205\n",
            "21m 16s (- 9m 38s) (51600 68%) 358461.7228\n",
            "21m 20s (- 9m 33s) (51800 69%) 329780.3497\n",
            "21m 24s (- 9m 28s) (52000 69%) 299289.4806\n",
            "21m 28s (- 9m 22s) (52200 69%) 302586.3855\n",
            "21m 32s (- 9m 17s) (52400 69%) 292990.3844\n",
            "21m 36s (- 9m 12s) (52600 70%) 301945.0509\n",
            "21m 41s (- 9m 7s) (52800 70%) 276672.6266\n",
            "21m 46s (- 9m 2s) (53000 70%) 300583.8729\n",
            "21m 50s (- 8m 56s) (53200 70%) 303543.8612\n",
            "21m 54s (- 8m 51s) (53400 71%) 288654.3533\n",
            "21m 58s (- 8m 46s) (53600 71%) 251084.2568\n",
            "22m 2s (- 8m 41s) (53800 71%) 329608.3766\n",
            "22m 6s (- 8m 35s) (54000 72%) 294736.1260\n",
            "22m 10s (- 8m 30s) (54200 72%) 321718.4981\n",
            "22m 14s (- 8m 25s) (54400 72%) 298639.6638\n",
            "22m 18s (- 8m 19s) (54600 72%) 308678.4018\n",
            "22m 22s (- 8m 14s) (54800 73%) 321969.4212\n",
            "22m 26s (- 8m 9s) (55000 73%) 328320.2088\n",
            "22m 30s (- 8m 4s) (55200 73%) 321533.7517\n",
            "22m 34s (- 7m 59s) (55400 73%) 292386.9141\n",
            "22m 38s (- 7m 54s) (55600 74%) 291015.7019\n",
            "22m 42s (- 7m 48s) (55800 74%) 276452.0870\n",
            "22m 46s (- 7m 43s) (56000 74%) 269254.8786\n",
            "22m 50s (- 7m 38s) (56200 74%) 310589.8900\n",
            "22m 54s (- 7m 33s) (56400 75%) 326577.3041\n",
            "22m 58s (- 7m 28s) (56600 75%) 334940.9233\n",
            "23m 2s (- 7m 23s) (56800 75%) 357122.9584\n",
            "23m 6s (- 7m 17s) (57000 76%) 312619.3280\n",
            "23m 10s (- 7m 12s) (57200 76%) 319079.5922\n",
            "23m 14s (- 7m 7s) (57400 76%) 290703.5224\n",
            "23m 18s (- 7m 2s) (57600 76%) 336172.1456\n",
            "23m 22s (- 6m 57s) (57800 77%) 336937.6192\n",
            "23m 26s (- 6m 52s) (58000 77%) 349073.8798\n",
            "23m 30s (- 6m 47s) (58200 77%) 367494.3516\n",
            "23m 34s (- 6m 42s) (58400 77%) 350743.7088\n",
            "23m 38s (- 6m 37s) (58600 78%) 359901.3199\n",
            "23m 42s (- 6m 32s) (58800 78%) 357120.2830\n",
            "23m 47s (- 6m 27s) (59000 78%) 357770.4660\n",
            "23m 51s (- 6m 22s) (59200 78%) 371515.3397\n",
            "23m 55s (- 6m 16s) (59400 79%) 319210.0126\n",
            "23m 59s (- 6m 11s) (59600 79%) 321887.1531\n",
            "24m 3s (- 6m 6s) (59800 79%) 345734.6077\n",
            "24m 7s (- 6m 1s) (60000 80%) 347384.8538\n",
            "24m 11s (- 5m 56s) (60200 80%) 348832.4922\n",
            "24m 15s (- 5m 51s) (60400 80%) 340090.6886\n",
            "24m 19s (- 5m 46s) (60600 80%) 344930.6217\n",
            "24m 23s (- 5m 41s) (60800 81%) 313009.0620\n",
            "24m 27s (- 5m 36s) (61000 81%) 303494.1873\n",
            "24m 30s (- 5m 31s) (61200 81%) 324711.8727\n",
            "24m 35s (- 5m 26s) (61400 81%) 378980.9750\n",
            "24m 39s (- 5m 21s) (61600 82%) 459502.4684\n",
            "24m 43s (- 5m 16s) (61800 82%) 438946.9339\n",
            "24m 47s (- 5m 11s) (62000 82%) 423022.3155\n",
            "24m 51s (- 5m 6s) (62200 82%) 460626.5887\n",
            "24m 55s (- 5m 2s) (62400 83%) 430196.7156\n",
            "24m 59s (- 4m 57s) (62600 83%) 402215.7103\n",
            "25m 3s (- 4m 52s) (62800 83%) 363166.3362\n",
            "25m 7s (- 4m 47s) (63000 84%) 391408.9523\n",
            "25m 11s (- 4m 42s) (63200 84%) 384377.0127\n",
            "25m 15s (- 4m 37s) (63400 84%) 394715.7449\n",
            "25m 19s (- 4m 32s) (63600 84%) 360279.1757\n",
            "25m 23s (- 4m 27s) (63800 85%) 423734.2555\n",
            "25m 27s (- 4m 22s) (64000 85%) 433692.1686\n",
            "25m 31s (- 4m 17s) (64200 85%) 410671.7983\n",
            "25m 35s (- 4m 12s) (64400 85%) 431399.8985\n",
            "25m 39s (- 4m 7s) (64600 86%) 448549.5694\n",
            "25m 43s (- 4m 3s) (64800 86%) 471243.8148\n",
            "25m 48s (- 3m 58s) (65000 86%) 449652.0630\n",
            "25m 52s (- 3m 53s) (65200 86%) 425302.0478\n",
            "25m 55s (- 3m 48s) (65400 87%) 432537.8648\n",
            "25m 59s (- 3m 43s) (65600 87%) 420896.4135\n",
            "26m 3s (- 3m 38s) (65800 87%) 474163.0634\n",
            "26m 7s (- 3m 33s) (66000 88%) 424295.8244\n",
            "26m 11s (- 3m 28s) (66200 88%) 454726.1360\n",
            "26m 15s (- 3m 24s) (66400 88%) 441027.0405\n",
            "26m 20s (- 3m 19s) (66600 88%) 452664.0554\n",
            "26m 24s (- 3m 14s) (66800 89%) 540596.3256\n",
            "26m 28s (- 3m 9s) (67000 89%) 543112.7417\n",
            "26m 32s (- 3m 4s) (67200 89%) 524885.6816\n",
            "26m 36s (- 3m 0s) (67400 89%) 493780.6150\n",
            "26m 41s (- 2m 55s) (67600 90%) 520500.8484\n",
            "26m 46s (- 2m 50s) (67800 90%) 521402.6881\n",
            "26m 50s (- 2m 45s) (68000 90%) 526683.2942\n",
            "26m 54s (- 2m 40s) (68200 90%) 445088.9427\n",
            "26m 58s (- 2m 36s) (68400 91%) 513872.2987\n",
            "27m 2s (- 2m 31s) (68600 91%) 489145.6233\n",
            "27m 6s (- 2m 26s) (68800 91%) 497263.8030\n",
            "27m 10s (- 2m 21s) (69000 92%) 504288.9113\n",
            "27m 14s (- 2m 17s) (69200 92%) 512060.9777\n",
            "27m 18s (- 2m 12s) (69400 92%) 528142.7454\n",
            "27m 22s (- 2m 7s) (69600 92%) 503178.6123\n",
            "27m 27s (- 2m 2s) (69800 93%) 502373.4248\n",
            "27m 31s (- 1m 57s) (70000 93%) 513852.9065\n",
            "27m 35s (- 1m 53s) (70200 93%) 503336.7154\n",
            "27m 39s (- 1m 48s) (70400 93%) 542050.8181\n",
            "27m 43s (- 1m 43s) (70600 94%) 514712.4826\n",
            "27m 47s (- 1m 38s) (70800 94%) 456012.4514\n",
            "27m 51s (- 1m 34s) (71000 94%) 413883.2548\n",
            "27m 54s (- 1m 29s) (71200 94%) 434887.3953\n",
            "27m 58s (- 1m 24s) (71400 95%) 428376.0976\n",
            "28m 2s (- 1m 19s) (71600 95%) 466595.3188\n",
            "28m 6s (- 1m 15s) (71800 95%) 438854.6909\n",
            "28m 10s (- 1m 10s) (72000 96%) 457999.6116\n",
            "28m 14s (- 1m 5s) (72200 96%) 510632.7744\n",
            "28m 18s (- 1m 1s) (72400 96%) 515983.4029\n",
            "28m 23s (- 0m 56s) (72600 96%) 476826.2141\n",
            "28m 27s (- 0m 51s) (72800 97%) 518533.8346\n",
            "28m 31s (- 0m 46s) (73000 97%) 512926.9868\n",
            "28m 35s (- 0m 42s) (73200 97%) 546387.8669\n",
            "28m 40s (- 0m 37s) (73400 97%) 498131.4091\n",
            "28m 44s (- 0m 32s) (73600 98%) 553076.4282\n",
            "28m 47s (- 0m 28s) (73800 98%) 511083.7449\n",
            "28m 51s (- 0m 23s) (74000 98%) 468623.8428\n",
            "28m 55s (- 0m 18s) (74200 98%) 489216.7911\n",
            "28m 59s (- 0m 14s) (74400 99%) 505602.6937\n",
            "29m 3s (- 0m 9s) (74600 99%) 449323.3134\n",
            "29m 7s (- 0m 4s) (74800 99%) 452315.3479\n",
            "29m 11s (- 0m 0s) (75000 100%) 484753.5867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Locator attempting to generate 3206823 ticks ([-29147.800000000003, ..., 612216.6]), which exceeds Locator.MAXTICKS (1000).\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "embedding_size = 10\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size,embedding_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words,embedding_size=embedding_size).to(device)\n",
        "\n",
        "train_iters(encoder, decoder, 75000, print_every=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Falta corregir mirar el video de la clase (algo menor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxfrex2nFuOm"
      },
      "outputs": [],
      "source": [
        "evaluate_randomly(encoder, decoder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab09_Seq2Seq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
