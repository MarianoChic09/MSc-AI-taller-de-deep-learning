{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kM-aVQsV0Ie"
   },
   "source": [
    "# Imports globales y funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NpqMPo4nV4UB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YGyynDexV60_"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_transf, test_transf, batch_size):\n",
    "    train_dataset = CIFAR10(\"data\", train=True, download=True, transform=train_transf)\n",
    "    test_dataset = CIFAR10(\"data\", train=False, download=True, transform=test_transf)\n",
    "\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "    train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hZyH1P8Velv"
   },
   "source": [
    "# Image Augmentation\n",
    "\n",
    "La primera parte de este laboratorio consiste en expandir un poco el modelo de LeNet para tener más parámetros y luego explorar algunas técnicas de Image Augmentation (https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "El modelo a implementar es el siguiente:\n",
    "\n",
    "\n",
    "![Image](https://i.ibb.co/WxGgbmL/Capture.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "chgl8-GKTyfV"
   },
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "  def __init__(self, in_channels, number_classes):\n",
    "    # in_channels: int, cantidad de canales de la imagen original\n",
    "    super(CustomCNN, self).__init__()\n",
    "    # Su implementacion\n",
    "    self.conv1 = nn.Conv2d(in_channels, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "    self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 1)\n",
    "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "    self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 120, kernel_size = 3, padding = 1)\n",
    "    \n",
    "    self.linear1 = nn.Linear(in_features = 120*4*4, out_features = 512)\n",
    "    self.linear2 = nn.Linear(in_features = 512, out_features = number_classes)\n",
    "    \n",
    "    self.max_pooling = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Su implementacion\n",
    "    out = F.relu(self.conv1(x))\n",
    "    out = F.relu(self.conv2(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = F.relu(self.conv3(out))\n",
    "    out = F.relu(self.conv4(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = F.relu(self.conv5(out))\n",
    "    out = self.max_pooling(out)\n",
    "    \n",
    "    out = self.dropout(out.flatten(1))\n",
    "    \n",
    "    out = F.relu(self.linear1(out))\n",
    "    out = self.dropout(out)\n",
    "    out = self.linear2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGisRfZ8bYXW"
   },
   "source": [
    "## Funciones genericas para entrenar nuestros modelos\n",
    "\n",
    "Vamos a utilizar las mismas funciones que implementamos en los laboratorios anteriores para entrenar y testear nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6Gp496cWTyh-"
   },
   "outputs": [],
   "source": [
    "def train_epoch(training_model, loader, criterion, optim):\n",
    "    training_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "      all_labels.extend(labels.numpy())  \n",
    "\n",
    "      optim.zero_grad()\n",
    "\n",
    "      predictions = training_model(images.to(device))\n",
    "      all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "\n",
    "      loss = criterion(predictions, labels.to(device))\n",
    "      \n",
    "      loss.backward()\n",
    "      optim.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n",
    "\n",
    "\n",
    "def validation_epoch(val_model, loader, criterion):\n",
    "    val_model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for images, labels in loader:\n",
    "        all_labels.extend(labels.numpy())  \n",
    "\n",
    "        predictions = val_model(images.to(device))\n",
    "        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "\n",
    "        loss = criterion(predictions, labels.to(device))\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n",
    "  \n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optim, number_epochs):\n",
    "  train_history = []\n",
    "  test_history = []\n",
    "  accuracy_history = []\n",
    "\n",
    "  for epoch in range(number_epochs):\n",
    "      start_time = time.time()\n",
    "\n",
    "      train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "      train_history.append(train_loss)\n",
    "      print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
    "            .format(epoch + 1, train_loss, train_acc, time.time() - start_time))\n",
    "\n",
    "      start_time = time.time()\n",
    "      test_loss, acc = validation_epoch(model, test_loader, criterion)\n",
    "      test_history.append(test_loss)\n",
    "      accuracy_history.append(acc)\n",
    "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
    "            .format(epoch + 1, test_loss, acc, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrGeplg5bmKm"
   },
   "source": [
    "## Entrenando modelos \n",
    "\n",
    "Comenzamos definiendo una seccion de código con valores por defecto de hiperparámetros que vamos a utilizar y luego entrenamos un modelo de la CNN definida anteriormente sin usar augmentation en los datos y otro haciendo uso del mismo.\n",
    "\n",
    "https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rj_T5Fza6efw"
   },
   "outputs": [],
   "source": [
    "# Global models config\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "LR = 0.001\n",
    "NUMBER_EPOCHS = 15\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "137kQNukTyoI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-363b085382e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Entrenamos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo_sin_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUMBER_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-5ed533f7ae43>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optim, number_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m       \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
      "\u001b[0;32m<ipython-input-8-5ed533f7ae43>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(training_model, loader, criterion, optim)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fijamos las semillas siempre para poder comparar.\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los dataloaders\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Definimos el modelo y el optimizador\n",
    "modelo_sin_aug = CustomCNN(3,10).to(device)\n",
    "optimizer = torch.optim.Adam(modelo_sin_aug.parameters(), lr=LR)\n",
    "\n",
    "# Entrenamos\n",
    "train_model(modelo_sin_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_c-x46dYUyk"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los datasets\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Definir transormaciones que vamos a aplicar al set de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.2), \n",
    "    transforms.RandomVerticalFlip(p=0.5), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Crear el modelo, optimizador y entrenarlo\n",
    "modelo_con_aug = CustomCNN(3,10).to(device)\n",
    "optimizer = torch.optim.Adam(modelo_con_aug.parameters(), lr=LR)\n",
    "\n",
    "# Entrenamos\n",
    "train_model(modelo_con_aug, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pduauAlXcqZt"
   },
   "source": [
    "## Evaluando los modelos en los datos de test\n",
    "\n",
    "Vamos a comenzar evaluando en los datos de test normales y luego vamos a aplicar distintas transformaciones (para simular entornos más reales de datos) y vamos a ver la performance y robustez de los modelos que entrenamos anteriormente.\n",
    "\n",
    "Primero agregar horizontal flip y luego vertical flip, qué pasa con los modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNp0-FmEFH16"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8XEXFoo8jfG"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  # Flip Horizontal y volver a testear\n",
    "  transforms.RandomHorizontalFlip(p=1), \n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3DMvkFf9EQg"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.RandomVerticalFlip(p=1), \n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "# Testear usando las funciones definidas anteriormente\n",
    "loss, acc = validation_epoch(modelo_con_aug, test_loader, criterion)\n",
    "print('Test Loss:', loss, '- Test Acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OPa2WNqgXyy"
   },
   "outputs": [],
   "source": [
    "# Otros tests que quieran probar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsQVBuQKwOvX"
   },
   "source": [
    "# DenseNet\n",
    "\n",
    "\n",
    "![Image](https://miro.medium.com/max/5164/1*_Y7-f9GpV7F93siM1js0cg.jpeg)\n",
    "\n",
    "Link al paper original: [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
    "\n",
    "Algunas consideraciones del paper a tener en cuenta:\n",
    "\n",
    "1. Batch normalization en los inputs de los bloques densos y las capas de transición.\n",
    "2. ReLU en todos lados como funcion de activación.\n",
    "3. El MLP al final de la red cuenta con una capa oculta de 512 neuronas\n",
    "4. Las activaciones luego del tercer bloque denso tienen tamaño 4*4 (ejercicio, calcular a mano!)\n",
    "\n",
    "\n",
    "Implementamos DenseNet para resolver el problema de CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_same_padding(input_shape, strides, kernel_size):\n",
    "    padding_total = (input_shape*strides-input_shape-strides+kernel_size)/2\n",
    "    return math.ceil(padding_total/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeFunction(nn.Module):  \n",
    "    #BatchNorm + Relu + Conv\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, input_shape, strides = 1):\n",
    "        super(CompositeFunction, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(num_features = in_channels)\n",
    "        P = compute_same_padding(input_shape, strides, kernel_size)\n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, padding = P)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.bn(x)\n",
    "        out = self.conv(F.relu(out))\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZeyVzE9bLUTA"
   },
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "  #out_channels = in_channels + k * reps\n",
    "  #bottleneck = 4*k\n",
    "  def __init__(self, in_channels, reps, k, input_shape):\n",
    "    super(DenseBlock, self).__init__()\n",
    "    # Su implementacion\n",
    "    self.reps = reps\n",
    "    self.convs = []\n",
    "    for i in range(reps):\n",
    "        self.convs.append(CompositeFunction(in_channels+k*i, 4*k, 1, input_shape))\n",
    "        self.convs.append(CompositeFunction(4*k, k, 3, input_shape))\n",
    "    \n",
    "    self.convs = nn.ModuleList(self.convs)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i in range(self.reps):\n",
    "        x1 = self.convs[2*i](x)        \n",
    "        x2 = self.convs[2*i+1](x1)\n",
    "        x = torch.cat([x,x2],1)    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pTjRTakNLVGm"
   },
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, input_shape):\n",
    "    super(TransitionLayer, self).__init__()\n",
    "    self.comp = CompositeFunction(in_channels, out_channels, 1, input_shape)\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.comp(x)\n",
    "    out = self.pool(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I0rglwp_wWEF"
   },
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    #DenseNet 121\n",
    "    def __init__(self, n_classes, input_shape, k):\n",
    "        super(DenseNet, self).__init__()    \n",
    "        self.input_conv = CompositeFunction(in_channels = 3, out_channels = 2*k ,kernel_size = 7, input_shape = input_shape, strides = 2)\n",
    "        self.input_max_pooling = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.dense_block1 = DenseBlock(2*k, 6, k, int(input_shape/2))\n",
    "        self.transitionLayer1 = TransitionLayer(in_channels=(6+2)*k, out_channels=4*k,  input_shape = int(input_shape/2))\n",
    "\n",
    "        self.dense_block2 = DenseBlock(4*k, 12, k, int(input_shape/4))\n",
    "        self.transitionLayer2 = TransitionLayer(in_channels=(12+4)*k, out_channels=8*k, input_shape =int(input_shape/4))\n",
    "\n",
    "        self.dense_block3 = DenseBlock(8*k, 24, k, int(input_shape/8))\n",
    "        self.transitionLayer3 = TransitionLayer(in_channels=(24+8)*k, out_channels=16*k, input_shape =int(input_shape/8))\n",
    "\n",
    "        self.dense_block4 = DenseBlock(16*k, 16, k, input_shape =int(input_shape/16))\n",
    "        last_number_of_filters = 16*k+16*k\n",
    "        # Classifier\n",
    "        h = int(input_shape/16)\n",
    "        w = h\n",
    "        self.fully_connected_1 = nn.Linear(last_number_of_filters*w*h, 512)\n",
    "        self.output = nn.Linear(512, n_classes)        \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.input_conv(x)         \n",
    "        out = self.input_max_pooling(out)        \n",
    "        out = self.dense_block1(out)\n",
    "        out = self.transitionLayer1(out)\n",
    "        out = self.dense_block2(out)\n",
    "        out = self.transitionLayer2(out)\n",
    "        out = self.dense_block3(out)  \n",
    "        out = self.transitionLayer3(out)\n",
    "        out = self.dense_block4(out)        \n",
    "        out = out.flatten(1)  \n",
    "        out = F.relu(self.fully_connected_1(out))\n",
    "        out = self.output(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7vhkbNiwWIU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training epoch 1 | Loss 1.673456 | Accuracy 38.65% | Time 446.34 seconds\n",
      "Validation epoch 1 | Loss 1.364092 | Accuracy 50.71% | Time 15.28 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Creamos los datasets\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "densenet = DenseNet(10, 32, 4).to(device)\n",
    "optimizer = torch.optim.Adam(densenet.parameters(), lr=LR)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "NUMBER_EPOCHS = 10\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(train_transform, test_transform, BATCH_SIZE)\n",
    "\n",
    "train_model(densenet, train_loader, valid_loader, criterion, optimizer, NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7G9PbgeDdD_s"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor()                              \n",
    "])\n",
    "\n",
    "_, _, test_loader = get_dataloaders(None, test_transform, BATCH_SIZE)\n",
    "\n",
    "test_loss, accuracy = validation_epoch(densenet, test_loader, criterion)\n",
    "print(f\"DenseNet Test set: {test_loss:.6f} Loss. Accuracy {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNNs_2_Letra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
