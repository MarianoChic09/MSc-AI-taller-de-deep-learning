{"cells":[{"cell_type":"markdown","metadata":{"id":"7VMtkNDwxZ0m"},"source":["# Datos\n","\n","Vamos a usar el dataset de IMDB para clasificación de reseñas de películas, el objetivo del mismo es detectar si una reseña tiene sentimiento **positivo** o **negativo**.\n","\n","Descarguen el dataset de este [link](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n","\n","Y word2vec de este [link](https://drive.google.com/file/d/1XusPRjsCVcIdCQ2hQDDWcH_wayfn4nWb/view?usp=sharing).\n","\n","-> Para correr esta notebook en colab suban los archivos a una carpeta **data** en la raiz de su drive personal.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37098,"status":"ok","timestamp":1632863784197,"user":{"displayName":"Matias Sorozabal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04842478827197692237"},"user_tz":180},"id":"zh7A9mjs3cfU","outputId":"b235382f-0109-4101-849a-d91c44fbac9b"},"outputs":[{"name":"stderr","output_type":"stream","text":["'cp' is not recognized as an internal or external command,\n","operable program or batch file.\n","'unzip' is not recognized as an internal or external command,\n","operable program or batch file.\n","'rm' is not recognized as an internal or external command,\n","operable program or batch file.\n","'ls' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["# from google.colab import drive\n","# drive.mount(\"/content/drive\")\n","\n","! cp \"/content/drive/My Drive/data/IMDB_Dataset.zip\" .\n","! unzip -q IMDB_Dataset.zip\n","! rm IMDB_Dataset.zip\n","! ls"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BBaFc6ZZzp2T"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['review', 'sentiment'], dtype='object')\n"]}],"source":["import pandas as pd\n","imdb_data = pd.read_csv(\"IMDB Dataset.csv\")\n","\n","#sentiment count\n","print(imdb_data.columns)\n","imdb_data['sentiment'].value_counts()\n","\n","# Convert positive and negative into binary classes (1-0)\n","from sklearn.preprocessing import LabelBinarizer\n","lb = LabelBinarizer()\n","\n","sentiment_data = lb.fit_transform(imdb_data[\"sentiment\"])\n","imdb_data['sentiment'] = sentiment_data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rQFZbEtC1T94"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Probably my all-time favorite movie, a story o...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I sure would like to see a resurrection of a u...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>This show was an amazing, fresh &amp; innovative i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Encouraged by the positive comments about this...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>If you like original gut wrenching laughter yo...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  One of the other reviewers has mentioned that ...          1\n","1  A wonderful little production. <br /><br />The...          1\n","2  I thought this was a wonderful way to spend ti...          1\n","3  Basically there's a family where a little boy ...          0\n","4  Petter Mattei's \"Love in the Time of Money\" is...          1\n","5  Probably my all-time favorite movie, a story o...          1\n","6  I sure would like to see a resurrection of a u...          1\n","7  This show was an amazing, fresh & innovative i...          0\n","8  Encouraged by the positive comments about this...          0\n","9  If you like original gut wrenching laughter yo...          1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["imdb_data.head(10)"]},{"cell_type":"markdown","metadata":{"id":"rhdlJtOo2YC-"},"source":["# Imports\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\maria\\anaconda3\\envs\\mario_env_windows\\lib\\site-packages (3.8.1)\n","Requirement already satisfied: click in c:\\users\\maria\\anaconda3\\envs\\mario_env_windows\\lib\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\maria\\anaconda3\\envs\\mario_env_windows\\lib\\site-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\maria\\anaconda3\\envs\\mario_env_windows\\lib\\site-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in c:\\users\\maria\\anaconda3\\envs\\mario_env_windows\\lib\\site-packages (from nltk) (4.65.0)\n","Requirement already satisfied: colorama in c:\\users\\maria\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install nltk\n","#,bs4"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YaxC7dfq2aKT"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import re\n","from bs4 import BeautifulSoup\n","\n","import nltk\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"markdown","metadata":{"id":"Lkr7Vz950IeY"},"source":["# Preprocesamiento Inicial\n","\n","Como toda tarea de NLP tenemos que comenzar preprocesando los datos, eliminando palabras que no nos sirve, caracteres especiales, etc.\n","\n","En particular hay tres tareas a ser realizadas basadas en un análisis inicial del dataset (mirando ejemplos al azar del mismo)\n","\n","\n","\n","1.   Eliminar tags html (vamos a utilizar BeautifulSoup para esto)\n","2.   Eliminar texto entre parentesis rectos (Usando la siguiente expresion regular: ```\\[[^]]*\\]``` )\n","3. Eliminar caracteres especiales, usando una regex quitar todos los caracteres que no son ni letras ni números (```[^a-zA-z0-9\\s] ``` )\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image.png)"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-1.png)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SIiaBeGOwIOQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\1373846029.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  soup = BeautifulSoup(text,\"html.parser\")\n"]}],"source":["def strip_html(text):\n","  soup = BeautifulSoup(text,\"html.parser\")\n","  return soup.get_text().strip()\n","\n","def remove_between_square_brackets(text):\n","  p = re.compile('\\[[^]]*\\]')\n","  return p.sub(' ', text)\n","\n","def remove_special_characters(text):\n","  p = re.compile('[^a-zA-Z0-9 ]')\n","  return p.sub(' ', text)\n","\n","def low_level_preproc(text):\n","  return remove_special_characters(remove_between_square_brackets(strip_html(text)))\n","\n","#Apply function on review column\n","imdb_data['review'] = imdb_data['review'].apply(low_level_preproc)"]},{"cell_type":"markdown","metadata":{"id":"gGJUuc0O16iv"},"source":["# Preprocesamiento de alto nivel\n","\n","Una vez tenemos el texto limpio y trabajable volvemos a hacer otro pasaje de preprocesamiento de más alto nivel, ahora vamos a querer:\n","\n","\n","\n","1.   Transformar todo el texto a minúscula\n","2.   Quitar stop words (usando nltk)\n","3.   Lemmatizar usando nltk WordNetLemmatizer\n","\n","Para todo esto vamos a necesitar trabajar con **tokens** palabras individuales, en este caso vamos a separar por **whitespace**, pero se podrían usar mejores estrategias.\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KeKNTxvzwISR"},"outputs":[],"source":["all_stopwords = set(stopwords.words(\"english\"))\n","\n","def remove_stop_words(full_text_line):\n","  tokens = full_text_line.split(\" \")\n","  valid_tokens = [word for word in tokens if word not in all_stopwords]\n","  return valid_tokens\n","\n","def lemmatize(tokens):\n","  lemmatizer = WordNetLemmatizer()\n","  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","  return lemmatized_tokens\n","\n","def high_level_preproc(text):\n","  return \" \".join(lemmatize(remove_stop_words(text)))\n","\n","#Apply function on review column\n","imdb_data['review'] = imdb_data['review'].str.lower()\n","imdb_data['review'] = imdb_data['review'].apply(high_level_preproc)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9k3wz_XUql1d"},"outputs":[{"data":{"text/plain":["0    one reviewer mentioned watching 1 oz episode h...\n","1    wonderful little production  filming technique...\n","2    thought wonderful way spend time hot summer we...\n","3    basically family little boy  jake  think zombi...\n","4    petter mattei  love time money  visually stunn...\n","5    probably time favorite movie  story selflessne...\n","6    sure would like see resurrection dated seahunt...\n","7    show amazing  fresh   innovative idea 70 first...\n","8    encouraged positive comment film looking forwa...\n","9    like original gut wrenching laughter like movi...\n","Name: review, dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["imdb_data['review'].head(10)"]},{"cell_type":"markdown","metadata":{"id":"MAynpGKc3dYn"},"source":["# Modelando\n","\n","Para modelar vamos a comenzar separando el dataset."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"OFZn34Q63lLE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set: (40000,) (40000,)\n","Test set: (10000,) (10000,)\n"]}],"source":["#split the dataset  \n","#train dataset\n","train_reviews = imdb_data.review[:40000]\n","train_sentiments = imdb_data.sentiment[:40000]\n","\n","#test dataset\n","test_reviews = imdb_data.review[40000:]\n","test_sentiments = imdb_data.sentiment[40000:]\n","\n","\n","print(\"Train set:\", train_reviews.shape, train_sentiments.shape)\n","print(\"Test set:\", test_reviews.shape, test_sentiments.shape)"]},{"cell_type":"markdown","metadata":{"id":"U16zBbGzAb5z"},"source":["Vamos a generar vectores para las reseñas usando TF-IDF (sklearn). Vamos a hacer uso del parametro ```max_features``` que nos permite controlar cuántas palabras considerar para generar los vectores (en orden de frecuencia). Luego usamos esa representacion vectorial para entrenar y testear un regresor logístico (LogisticRegressor). En particular vamos a empezar con 300 features, más adelante veremos por qué.\n","\n","\n","Vamos a entrenar el modelo por 500 iteraciones como máximo y usamos l2 como regularizador."]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-3.png)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"9RVouRZ_ql3I"},"outputs":[{"data":{"text/plain":["array(['00', '000', '10', ..., 'zero', 'zombie', 'zone'], dtype=object)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Su código para vectorizar\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer(max_features=6000,max_df=0.9)\n","vectorizer.fit(train_reviews)\n","X_train = vectorizer.transform(train_reviews)\n","vectorizer.get_feature_names_out()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["X_train = vectorizer.transform(train_reviews)\n","X_test = vectorizer.transform(test_reviews)"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-4.png)"]},{"cell_type":"markdown","metadata":{},"source":["![Alt text](image-5.png)"]},{"cell_type":"markdown","metadata":{},"source":["### Su código para el modelo\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"SCOsCtrEAaJj"},"outputs":[],"source":["clf = LogisticRegression(random_state=0).fit(X_train, train_sentiments)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["0.8883"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["y_hat = clf.predict(X_test)\n","accuracy_score(test_sentiments, y_hat)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["array(['00', '000', '10', ..., 'zero', 'zombie', 'zone'], dtype=object)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{"id":"btnSQOb2JwIL"},"source":["# Vectores pre entrenados\n","Ahora vamos a ver si podemos superar la performance del modelo haciendo uso de deep learning.  Primero vamos a entrenar el mismo modelo usando los embeddings preentrenados de Word2Vec (usando gensim). \n","\n","Luego vamos a darle esos embeddings a un MLP y ver si logramos superar la performance anterior."]},{"cell_type":"markdown","metadata":{},"source":["*Un embedding es una representación vectorial de nuestras palabras. Vamos a tener un vector asociado a una palabra.*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install gensim"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"qYqJ0uJ1XH6Y"},"outputs":[],"source":["import gensim"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"a7oiP209Jvs1"},"outputs":[],"source":["w2v = gensim.models.KeyedVectors.load_word2vec_format(\"word2vec.txt\", binary=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Ap22Pw93U586"},"outputs":[],"source":["mean_vector = np.mean(w2v.vectors, axis=0)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"ZVwCEMusJvw0"},"outputs":[],"source":["def get_sentence_embedding(text):\n","  tokens = text.split(\" \")\n","  embeddings = [w2v[token] if token in w2v else mean_vector for token in tokens]\n","  return np.mean(np.array(embeddings), axis=0)\n","\n","\n","train_vectors = [get_sentence_embedding(sent) for sent in train_reviews]\n","test_vectors = [get_sentence_embedding(sent) for sent in test_reviews]"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 1.99898e-02,  1.32136e-02,  7.41993e-02, -3.01541e-02,\n","       -5.62424e-02, -1.00288e-01, -8.43636e-02,  5.88682e-03,\n","        5.96305e-02, -2.96458e-02,  5.86141e-02, -5.35319e-02,\n","       -9.75772e-02,  5.14991e-02,  2.89682e-02,  8.67353e-02,\n","        1.43655e-01,  1.33830e-02,  3.50668e-02,  1.08419e-01,\n","       -1.55508e-04, -1.15873e-01,  8.47024e-02, -3.81161e-02,\n","        7.72486e-02, -1.87192e-02,  1.99898e-02, -2.65966e-02,\n","       -9.55443e-02,  1.69405e-02,  9.68996e-02,  1.90580e-02,\n","        7.86038e-02, -3.84549e-02,  3.42198e-02, -2.50719e-02,\n","        7.92815e-02,  2.02439e-02,  1.10960e-02, -1.73471e-01,\n","        2.40555e-02,  2.81212e-02,  5.96305e-02,  2.49025e-02,\n","       -9.21562e-02, -6.56444e-03,  2.45637e-02,  5.01438e-02,\n","        4.91274e-02,  6.50515e-02, -6.13246e-02,  6.64067e-02,\n","       -2.25308e-02, -1.05709e-01,  2.64272e-02,  1.19939e-01,\n","       -6.94560e-03, -2.52413e-02, -2.47331e-02,  1.62629e-02,\n","       -4.87886e-02,  2.50719e-02, -8.50412e-02, -6.13246e-02,\n","        1.19261e-01, -3.26951e-02, -3.70997e-02, -1.11807e-01,\n","        3.50668e-02, -3.62103e-03, -2.52413e-02,  4.11654e-02,\n","        6.09857e-02,  4.51040e-03, -4.23512e-02,  6.53903e-02,\n","       -1.96510e-02, -2.11756e-02, -6.70843e-02,  3.06623e-02,\n","       -5.38707e-02, -9.69843e-03,  2.91376e-02, -7.38605e-02,\n","       -2.96458e-02, -1.22649e-01, -6.67455e-02,  2.49025e-02,\n","       -1.83169e-03, -1.12485e-01,  9.23256e-03, -3.42198e-02,\n","       -7.35217e-02,  6.50515e-02, -1.19939e-01,  6.90325e-03,\n","        7.69098e-02,  2.13450e-02,  6.70843e-02, -6.70843e-02,\n","       -1.43655e-01, -3.82855e-02, -5.48872e-02,  6.05622e-03,\n","        2.62577e-02,  3.72691e-02, -2.54107e-02, -1.18583e-01,\n","       -6.06469e-02,  1.03676e-01,  6.91172e-02, -7.66557e-03,\n","        4.87886e-02, -6.26798e-02, -8.30084e-02,  9.08010e-02,\n","       -4.30288e-02, -6.74231e-02,  9.82548e-02,  2.85871e-03,\n","        1.21971e-02, -3.45586e-02, -9.21562e-02,  1.27901e-02,\n","       -2.40555e-02, -7.62322e-02, -7.18277e-02,  4.91274e-02,\n","       -3.62526e-02,  1.71946e-02, -1.45011e-01, -4.74334e-02,\n","       -2.09215e-02,  1.42300e-02,  4.06572e-02,  4.67557e-02,\n","       -1.08419e-01, -1.10960e-02,  1.32983e-02,  1.16042e-02,\n","       -4.94662e-02, -1.88039e-02, -3.64220e-02,  8.74129e-02,\n","        3.26951e-02,  9.57137e-03, -3.38810e-02, -3.76079e-02,\n","       -8.04673e-03,  7.86038e-02,  2.00745e-02,  1.21124e-02,\n","       -6.64067e-02,  4.33676e-02, -2.73165e-03,  2.67660e-02,\n","       -2.03286e-03, -1.01219e-02,  4.28594e-02, -2.43943e-02,\n","        5.59036e-02,  2.42249e-02, -4.21818e-02,  1.63476e-02,\n","       -9.48667e-02, -9.14786e-02, -2.28697e-02,  7.69098e-02,\n","        1.42300e-01,  5.86141e-02,  1.00796e-02, -5.25155e-02,\n","       -3.37116e-02, -8.47024e-02, -5.89529e-02,  9.82548e-03,\n","       -1.40606e-02,  7.19971e-03,  5.01438e-02,  7.45381e-02,\n","       -3.72691e-02,  1.18583e-02,  4.54005e-02,  5.86141e-02,\n","        1.06302e-02, -8.53800e-02,  6.43738e-03, -2.54107e-02,\n","        4.60781e-02, -6.06469e-02, -4.70945e-02, -8.42789e-03,\n","        1.15195e-01, -1.25360e-02, -1.93122e-02, -2.65966e-02,\n","        5.28543e-02, -1.28070e-01, -1.18583e-01,  5.63271e-03,\n","        2.00745e-02,  4.94662e-02, -7.41993e-02,  2.79518e-02,\n","        2.09215e-02, -7.41993e-02,  9.52902e-03, -2.10062e-02,\n","       -1.21294e-01, -7.72486e-02,  1.90580e-02,  9.95253e-04,\n","       -9.21562e-02,  3.77773e-02, -2.38861e-02,  9.01234e-02,\n","       -1.36371e-02, -2.79518e-02, -1.14518e-01,  3.48974e-02,\n","        3.89631e-03,  1.12654e-02,  1.80416e-02, -6.16634e-02,\n","       -1.33830e-02, -7.14888e-02, -3.06623e-02,  1.06386e-01,\n","       -4.80686e-03,  5.92917e-02, -3.55750e-02,  1.69405e-02,\n","        8.85140e-03, -1.31289e-02, -1.96510e-02,  2.69354e-02,\n","       -2.04980e-02,  5.86141e-02,  1.16889e-02,  8.36860e-02,\n","       -6.13246e-02, -1.14518e-01,  5.75976e-02,  4.23512e-03,\n","       -6.36962e-02, -1.87192e-02,  3.21869e-02, -4.64169e-02,\n","       -1.16042e-02,  1.93969e-02,  7.62322e-02, -1.61464e-04,\n","        8.34319e-03, -3.26951e-02, -3.77773e-02,  1.00372e-02,\n","       -2.04980e-02, -5.79365e-02, -4.81110e-02, -9.44432e-03,\n","        1.13819e-04,  3.11705e-02, -3.01541e-02, -8.94458e-02,\n","        3.69303e-02,  2.52413e-02, -9.01234e-02,  1.76181e-02,\n","        4.37065e-02, -1.35656e-04, -9.62219e-02, -1.42300e-02,\n","       -4.34100e-03,  2.67660e-02, -1.05031e-02, -9.35962e-03,\n","       -1.13840e-01, -2.09215e-02, -3.25257e-02,  5.96305e-02,\n","       -1.26037e-01,  2.77824e-02,  3.10011e-02, -7.79262e-03,\n","       -3.67609e-02, -5.25155e-02, -6.77619e-03,  1.90580e-02,\n","       -4.43841e-02, -9.08010e-02, -6.77619e-03, -6.64067e-02,\n","       -2.55801e-02, -1.85498e-02,  5.86141e-02,  1.74487e-02,\n","       -1.71099e-02, -1.24004e-01, -1.64323e-02,  3.69303e-02],\n","      dtype=float32)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["w2v['Mariano']"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["0.71181965"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["from numpy import dot\n","from numpy.linalg import norm\n","\n","a = w2v['king'] - w2v['man'] + w2v['woman']\n","b = w2v['queen'] \n","\n","distancia = dot(a,b/norm(a)*norm(b))\n","\n","distancia"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('queen', 0.5957394242286682)]\n","[('queen', 0.7118193507194519)]\n"]}],"source":["result1 = w2v.most_similar(positive=['woman',\"king\"],negative='men',topn=1)\n","result2 = w2v.most_similar(positive=['woman',\"king\"],negative='man',topn=1)\n","\n","print(result1)\n","print(result2)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"884gkcqLVvyL"},"outputs":[{"data":{"text/plain":["0.8326"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["clf = LogisticRegression(random_state=0).fit(train_vectors, train_sentiments)\n","y_hat = clf.predict(test_vectors)\n","accuracy_score(test_sentiments, y_hat)"]},{"cell_type":"markdown","metadata":{"id":"-2GvqL87Yipe"},"source":["# Deep Learning\n"]},{"cell_type":"markdown","metadata":{"id":"5oxjMLJAW8qr"},"source":["MLP: vamos a crear un MLP para atacar ese mismo problema, el diseño corre por su cuenta pero deberían ser capaces de obetener mejor performance en test que los modelos anteriores.\n"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"SqH91xLsYlQr"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# Imports\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(DEVICE)\n","\n","torch.manual_seed(42)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"EUuaAbANZscl"},"outputs":[],"source":["def train_epoch(training_model, loader, criterion, optim):\n","    training_model.train()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    for data, labels in loader:\n","      all_labels.extend(labels.numpy())  \n","\n","      optim.zero_grad()\n","\n","      predictions = training_model(data.to(DEVICE))\n","      all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","      loss = criterion(predictions, labels.to(DEVICE))\n","      \n","      loss.backward()\n","      optim.step()\n","\n","      epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","\n","\n","def validation_epoch(val_model, loader, criterion):\n","    val_model.eval()\n","    epoch_loss = 0.0\n","    all_labels = []\n","    all_predictions = []\n","    \n","    with torch.no_grad():\n","      for data, labels in loader:\n","        all_labels.extend(labels.numpy())  \n","\n","        predictions = val_model(data.to(DEVICE))\n","        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n","\n","        loss = criterion(predictions, labels.to(DEVICE))\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(loader), accuracy_score(all_labels, all_predictions) * 100\n","  \n","\n","def train_model(model, train_loader, test_loader, criterion, optim, number_epochs):\n","  train_history = []\n","  test_history = []\n","  accuracy_history = []\n","\n","  for epoch in range(number_epochs):\n","      start_time = time.time()\n","\n","      train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n","      train_history.append(train_loss)\n","      print(\"Training epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, train_loss, train_acc, time.time() - start_time))\n","\n","      start_time = time.time()\n","      test_loss, acc = validation_epoch(model, test_loader, criterion)\n","      test_history.append(test_loss)\n","      accuracy_history.append(acc)\n","      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n","            .format(epoch + 1, test_loss, acc, time.time() - start_time))"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["40000"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["len(train_sentiments)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"M46rdl18JvzG"},"outputs":[],"source":["class MLP(nn.Module):\n","\n","  def __init__(self, in_features):\n","    super(MLP, self).__init__()\n","    self.linear1 = nn.Linear(in_features, 256)\n","    self.linear2 = nn.Linear(256, 128)\n","    self.linear3 = nn.Linear(128, 64)\n","    self.linear4 = nn.Linear(64, 2)\n","    \n","    # Su implementacion\n","\n","  def forward(self, new_input):\n","    x = self.linear1(new_input)\n","    x = F.relu(x)\n","    x = self.linear2(x)\n","    x = F.relu(x)\n","    x = self.linear3(x)\n","    x = F.relu(x)\n","    x = self.linear4(x)\n","    x = F.softmax(x)\n","    return x\n","  "]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 256]          77,056\n","            Linear-2                  [-1, 128]          32,896\n","            Linear-3                   [-1, 64]           8,256\n","            Linear-4                    [-1, 2]             130\n","================================================================\n","Total params: 118,338\n","Trainable params: 118,338\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.45\n","Estimated Total Size (MB): 0.46\n","----------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]}],"source":["modelo = MLP(in_features=300).to(DEVICE)\n","from torchsummary import summary\n","summary(modelo,input_size=(300,))"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["loss_function = nn.CrossEntropyLoss().to(DEVICE)\n","optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"jCauiKoIX5CJ"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\3848891621.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n","  train_dataset = TensorDataset(torch.Tensor(train_vectors), train_targets)\n"]}],"source":["# Dataloaders\n","train_vectors = [get_sentence_embedding(sent) for sent in train_reviews]\n","test_vectors = [get_sentence_embedding(sent) for sent in test_reviews]\n","\n","train_targets = torch.Tensor(train_sentiments.to_numpy()).long()\n","train_dataset = TensorDataset(torch.Tensor(train_vectors), train_targets) \n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)\n","\n","test_targets = torch.Tensor(test_sentiments.to_numpy()).long()\n","test_dataset = TensorDataset(torch.Tensor(test_vectors), test_targets) \n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, pin_memory=True, num_workers=2)"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"rDqPZnJgZWDi"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.502030 | Accuracy 80.05% | Time 10.81 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 1 | Loss 0.463419 | Accuracy 84.13% | Time 4.80 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 2 | Loss 0.467858 | Accuracy 83.76% | Time 9.55 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 2 | Loss 0.457293 | Accuracy 85.04% | Time 6.03 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 3 | Loss 0.463534 | Accuracy 84.22% | Time 16.24 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 3 | Loss 0.455353 | Accuracy 85.30% | Time 4.41 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 4 | Loss 0.460398 | Accuracy 84.66% | Time 10.74 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 4 | Loss 0.454226 | Accuracy 85.36% | Time 5.21 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 5 | Loss 0.459233 | Accuracy 84.78% | Time 10.51 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 5 | Loss 0.455182 | Accuracy 85.17% | Time 4.91 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 6 | Loss 0.458877 | Accuracy 84.79% | Time 11.69 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 6 | Loss 0.454190 | Accuracy 85.34% | Time 5.24 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 7 | Loss 0.457351 | Accuracy 84.98% | Time 11.83 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 7 | Loss 0.453391 | Accuracy 85.28% | Time 4.73 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 8 | Loss 0.456364 | Accuracy 85.08% | Time 9.35 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 8 | Loss 0.453176 | Accuracy 85.31% | Time 4.03 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 9 | Loss 0.455276 | Accuracy 85.20% | Time 8.73 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 9 | Loss 0.453261 | Accuracy 85.33% | Time 3.98 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 10 | Loss 0.454850 | Accuracy 85.26% | Time 8.42 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 10 | Loss 0.452747 | Accuracy 85.49% | Time 3.89 seconds\n"]}],"source":["train_model(modelo, train_dataloader, test_dataloader, loss_function, optimizer, 10)"]},{"cell_type":"markdown","metadata":{"id":"zBfOKG3iMt9Q"},"source":["# Exploración\n","\n","Exploren otras técnicas de preprocesamiento, tokenizacion, vectorizacion, etc. para ver si puede lograr superar los modelos presentados en clase.\n"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"T09IUvPVJv06"},"outputs":[],"source":["class MLPRegularizada(nn.Module):\n","    def __init__(self, in_features):\n","        super(MLP, self).__init__()\n","        self.linear1 = nn.Linear(in_features, 256)\n","        self.batch_norm1 = nn.BatchNorm1d(256)\n","        self.dropout1 = nn.Dropout(p=0.5)\n","        self.linear2 = nn.Linear(256, 128)\n","        self.batch_norm2 = nn.BatchNorm1d(128)\n","        self.dropout2 = nn.Dropout(p=0.5)\n","        self.linear3 = nn.Linear(128, 64)\n","        self.batch_norm3 = nn.BatchNorm1d(64)\n","        self.dropout3 = nn.Dropout(p=0.5)\n","        self.linear4 = nn.Linear(64, 2)\n","\n","    def forward(self, x):\n","        x = self.dropout1(F.leaky_relu(self.batch_norm1(self.linear1(x))))\n","        x = self.dropout2(F.leaky_relu(self.batch_norm2(self.linear2(x))))\n","        x = self.dropout3(F.leaky_relu(self.batch_norm3(self.linear3(x))))\n","        x = F.softmax(self.linear4(x), dim=1)\n","        return x\n","\n","modelo = MLP(in_features=300).to(DEVICE)\n","optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001, weight_decay=1e-5) \n"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["loss_function = nn.CrossEntropyLoss().to(DEVICE)\n","optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 1 | Loss 0.502825 | Accuracy 79.95% | Time 8.52 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 1 | Loss 0.464235 | Accuracy 84.07% | Time 4.11 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 2 | Loss 0.467938 | Accuracy 83.83% | Time 9.27 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 2 | Loss 0.456960 | Accuracy 85.07% | Time 4.50 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 3 | Loss 0.463606 | Accuracy 84.19% | Time 10.24 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 3 | Loss 0.455397 | Accuracy 85.22% | Time 5.23 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 4 | Loss 0.460731 | Accuracy 84.55% | Time 11.95 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 4 | Loss 0.454225 | Accuracy 85.44% | Time 5.45 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 5 | Loss 0.459785 | Accuracy 84.69% | Time 8.57 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 5 | Loss 0.454379 | Accuracy 85.31% | Time 3.82 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 6 | Loss 0.459118 | Accuracy 84.82% | Time 8.40 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 6 | Loss 0.455029 | Accuracy 85.21% | Time 3.87 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 7 | Loss 0.458407 | Accuracy 84.86% | Time 8.40 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 7 | Loss 0.454169 | Accuracy 85.44% | Time 3.82 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 8 | Loss 0.456813 | Accuracy 85.05% | Time 8.27 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 8 | Loss 0.453916 | Accuracy 85.39% | Time 3.92 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 9 | Loss 0.455625 | Accuracy 85.13% | Time 8.30 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 9 | Loss 0.453582 | Accuracy 85.40% | Time 3.80 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Training epoch 10 | Loss 0.455128 | Accuracy 85.22% | Time 8.33 seconds\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_12168\\2959396290.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.softmax(x)\n"]},{"name":"stdout","output_type":"stream","text":["Validation epoch 10 | Loss 0.453530 | Accuracy 85.36% | Time 3.78 seconds\n"]}],"source":["train_model(modelo, train_dataloader, test_dataloader, loss_function, optimizer, 10)"]},{"cell_type":"markdown","metadata":{},"source":["### CNN"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["class TextCNN(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_classes, kernel_sizes, num_filters):\n","        super(TextCNN, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.convs = nn.ModuleList(\n","            [nn.Conv2d(1, num_filters, (k, embed_dim)) for k in kernel_sizes]\n","        )\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n","\n","    def forward(self, x):\n","        x = x.long()\n","        x = self.embedding(x).unsqueeze(1)  # Agrega un canal\n","        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n","        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n","        x = torch.cat(x, 1)\n","        x = self.dropout(x)\n","        return self.fc(x)\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'TextCNN' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mk:\\OneDrive\\Master en Big Data - Universidad ORT\\3er Semestre\\Deep Learning\\MSc-AI-taller-de-deep-learning\\Clase 5 - NLP\\NLP_01_Letra.ipynb Cell 54\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/k%3A/OneDrive/Master%20en%20Big%20Data%20-%20Universidad%20ORT/3er%20Semestre/Deep%20Learning/MSc-AI-taller-de-deep-learning/Clase%205%20-%20NLP/NLP_01_Letra.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m modelo \u001b[39m=\u001b[39m TextCNN(vocab_size\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, embed_dim\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, kernel_sizes\u001b[39m=\u001b[39m [\u001b[39m4\u001b[39m], num_filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/k%3A/OneDrive/Master%20en%20Big%20Data%20-%20Universidad%20ORT/3er%20Semestre/Deep%20Learning/MSc-AI-taller-de-deep-learning/Clase%205%20-%20NLP/NLP_01_Letra.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_function \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/k%3A/OneDrive/Master%20en%20Big%20Data%20-%20Universidad%20ORT/3er%20Semestre/Deep%20Learning/MSc-AI-taller-de-deep-learning/Clase%205%20-%20NLP/NLP_01_Letra.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(modelo\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'TextCNN' is not defined"]}],"source":["modelo = TextCNN(vocab_size=300, embed_dim=300, kernel_sizes= [4], num_filters=64, num_classes=2).to(DEVICE)\n","loss_function = nn.CrossEntropyLoss().to(DEVICE)\n","optimizer = torch.optim.Adam(modelo.parameters(), lr=0.001)\n","BATCH_SIZE = 16"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["train_model(modelo, train_dataloader, test_dataloader, loss_function, optimizer, 10)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["zBfOKG3iMt9Q"],"name":"NLP_01_Letra.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
