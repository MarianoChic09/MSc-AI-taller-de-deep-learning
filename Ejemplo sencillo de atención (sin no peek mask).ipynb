{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mecanismo de atencion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attention diagram](https://miro.medium.com/max/336/1*15E9qKg9bKnWdSRWCyY2iA.png)\n",
    "![Attention equation](https://miro.medium.com/max/1068/1*evdACdTOBT5j1g1nXialBg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignorando la noción de multihead attention y el batch size (por ahora) podemos imaginar un dato de dimensiones (seq_len, d_model)\n",
    "\n",
    "Dicho dato, es procesado por 3 perceptrones independientes que llamaremos pQ, pK y pV, con dimensión de entrada y salida d_model, a efectos de simplificar el ejemplo asumiremos que son la función identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
      "         0.0900],\n",
      "        [0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700, 0.1800,\n",
      "         0.1900],\n",
      "        [0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600, 0.2700, 0.2800,\n",
      "         0.2900],\n",
      "        [0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500, 0.3600, 0.3700, 0.3800,\n",
      "         0.3900],\n",
      "        [0.4000, 0.4100, 0.4200, 0.4300, 0.4400, 0.4500, 0.4600, 0.4700, 0.4800,\n",
      "         0.4900]])\n",
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 5\n",
    "d_model = 10\n",
    "dato = torch.tensor(range(d_model*seq_len), dtype=torch.float32).view(seq_len, d_model)/100\n",
    "print(dato)\n",
    "print(dato.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = K = V = dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso de la atención es multiplicar Q por K transpuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0285, 0.0735, 0.1185, 0.1635, 0.2085],\n",
       "        [0.0735, 0.2185, 0.3635, 0.5085, 0.6535],\n",
       "        [0.1185, 0.3635, 0.6085, 0.8535, 1.0985],\n",
       "        [0.1635, 0.5085, 0.8535, 1.1985, 1.5435],\n",
       "        [0.2085, 0.6535, 1.0985, 1.5435, 1.9885]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QKt = torch.matmul(Q, K.transpose(-2, -1))\n",
    "QKt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si pensamos como marco de referencia nuestro dato, e interpretamos su ultimo valor como el encoding asociado al símbolo de padding sería deseable que la posición 5 del valor retornado por la atención no tenga aporte.\n",
    "\n",
    "Para ello podemos crear una máscara de padding con un 0 en la posición 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([1,1,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar la máscara en este caso es sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8500e-02,  7.3500e-02,  1.1850e-01,  1.6350e-01, -1.0000e+09],\n",
       "        [ 7.3500e-02,  2.1850e-01,  3.6350e-01,  5.0850e-01, -1.0000e+09],\n",
       "        [ 1.1850e-01,  3.6350e-01,  6.0850e-01,  8.5350e-01, -1.0000e+09],\n",
       "        [ 1.6350e-01,  5.0850e-01,  8.5350e-01,  1.1985e+00, -1.0000e+09],\n",
       "        [ 2.0850e-01,  6.5350e-01,  1.0985e+00,  1.5435e+00, -1.0000e+09]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_mask_applied = QKt.masked_fill(mask == 0, -1e9)\n",
    "pad_mask_applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el tensor resultante, las filas (i) representan palabras, y las columnas (j) también, donde se expresa que para cada i hay una relación con j, donde para el caso j = 4 este debe ser ignorado por los i pues este elemento corresponde al padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso siguiente es ponderar estos resultados en un valor entre 0 y 1, pudiendo interpretarse dicho valor como la importancia de la palbra j para la palabra i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2334, 0.2441, 0.2554, 0.2671, 0.0000],\n",
       "        [0.1985, 0.2295, 0.2653, 0.3067, 0.0000],\n",
       "        [0.1668, 0.2131, 0.2723, 0.3478, 0.0000],\n",
       "        [0.1385, 0.1955, 0.2761, 0.3899, 0.0000],\n",
       "        [0.1137, 0.1774, 0.2769, 0.4320, 0.0000]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = F.softmax(pad_mask_applied)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente matriz nos dice por ejemplo que el aporte al valor final para la palabra 2 dado por la palabra 3 es aproximadamente 35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 24, 26, 27,  0],\n",
       "       [20, 23, 27, 31,  0],\n",
       "       [17, 21, 27, 35,  0],\n",
       "       [14, 20, 28, 39,  0],\n",
       "       [11, 18, 28, 43,  0]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(np.round(importances, decimals = 2)*100, dtype = \"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente debemos obtener un resultado para cada palabra de entrada, esto es, un vector que resulta de operar V, con la matriz de importancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1556, 0.1656, 0.1756, 0.1856, 0.1956, 0.2056, 0.2156, 0.2256, 0.2356,\n",
       "         0.2456],\n",
       "        [0.1680, 0.1780, 0.1880, 0.1980, 0.2080, 0.2180, 0.2280, 0.2380, 0.2480,\n",
       "         0.2580],\n",
       "        [0.1801, 0.1901, 0.2001, 0.2101, 0.2201, 0.2301, 0.2401, 0.2501, 0.2601,\n",
       "         0.2701],\n",
       "        [0.1917, 0.2017, 0.2117, 0.2217, 0.2317, 0.2417, 0.2517, 0.2617, 0.2717,\n",
       "         0.2817],\n",
       "        [0.2027, 0.2127, 0.2227, 0.2327, 0.2427, 0.2527, 0.2627, 0.2727, 0.2827,\n",
       "         0.2927]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.matmul(importances, V)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente tenemos una salida del mismo tamaño que la entrada. Todas estas operaciones se pueden realizar a la misma vez para un batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
